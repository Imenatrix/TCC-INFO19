{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imenatrix/TCC-INFO19/blob/feature-dqfd/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jQ0equmGYKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk"
      ],
      "metadata": {
        "id": "YRB8g4TMYMC_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install minerl"
      ],
      "metadata": {
        "id": "kDkezv40YO5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "-zuJdSSzX9yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from itertools import product\n",
        "from collections import OrderedDict\n",
        "from google.cloud import storage\n",
        "\n",
        "import minerl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import *\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "FLc3fue_X9TE",
        "outputId": "797085a7-d22a-48c6-cde7-6cf3204e2e71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()"
      ],
      "metadata": {
        "id": "XJ4KnwlO2VA8",
        "outputId": "052062ea-3150-49dc-cfc6-17c835a6410b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.219.218:8470\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.51.219.218:8470\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFFwJOuYGUe"
      },
      "source": [
        "# Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrappers = {}\n",
        "\n",
        "def register_wrapper(name, wrapper):\n",
        "    wrappers[name] = wrapper"
      ],
      "metadata": {
        "id": "MVMjGEEkgSl7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTI-JMK6YGUf"
      },
      "source": [
        "## Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ANVPcDTdYGUf"
      },
      "outputs": [],
      "source": [
        "class ActionManager:\n",
        "    \"\"\"Main minecraft action wrapper. Simplifies action space to 130 discrete actions\"\"\"\n",
        "\n",
        "    def __init__(self, c_action_magnitude=22.5):\n",
        "        self.c_action_magnitude = c_action_magnitude\n",
        "\n",
        "        self.zero_action = OrderedDict([('attack', 0),\n",
        "                                        ('back', 0),\n",
        "                                        ('camera', np.array([0., 0.])),\n",
        "                                        ('forward', 0),\n",
        "                                        ('jump', 0),\n",
        "                                        ('left', 0),\n",
        "                                        ('right', 0),\n",
        "                                        ('sneak', 0),\n",
        "                                        ('sprint', 0)])\n",
        "\n",
        "        # camera discretization:\n",
        "        self.camera_dict = OrderedDict([\n",
        "            ('turn_up', np.array([-c_action_magnitude, 0.])),\n",
        "            ('turn_down', np.array([c_action_magnitude, 0.])),\n",
        "            ('turn_left', np.array([0., -c_action_magnitude])),\n",
        "            ('turn_right', np.array([0., c_action_magnitude]))\n",
        "        ])\n",
        "\n",
        "        self.fully_connected_no_camera = ['attack', 'back', 'forward', 'jump', 'left', 'right', 'sprint']\n",
        "        self.camera_actions = ['turn_up', 'turn_down', 'turn_left', 'turn_right']\n",
        "        self.fully_connected = self.fully_connected_no_camera + self.camera_actions\n",
        "\n",
        "        # following action combinations are excluded:\n",
        "        self.exclude = [('forward', 'back'), ('left', 'right'), ('attack', 'jump'),\n",
        "                        ('turn_up', 'turn_down', 'turn_left', 'turn_right')]\n",
        "\n",
        "        # sprint only allowed when forward is used:\n",
        "        self.only_if = [('sprint', 'forward')]\n",
        "\n",
        "        # Maximal allowed mount of actions within one action:\n",
        "        self.remove_size = 3\n",
        "\n",
        "        # if more than 3 actions are present, actions are removed using this list until only 3 actions remain:\n",
        "        self.remove_first_list = ['sprint', 'left', 'right', 'back',\n",
        "                                  'turn_up', 'turn_down', 'turn_left', 'turn_right',\n",
        "                                  'attack', 'jump', 'forward']\n",
        "\n",
        "        self.fully_connected_list = list(product(range(2), repeat=len(self.fully_connected)))\n",
        "\n",
        "        remove = []\n",
        "        for el in self.fully_connected_list:\n",
        "            for tuple_ in self.exclude:\n",
        "                if sum([el[self.fully_connected.index(a)] for a in tuple_]) > 1:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            for a, b in self.only_if:\n",
        "                if el[self.fully_connected.index(a)] == 1 and el[self.fully_connected.index(b)] == 0:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            if sum(el) > self.remove_size:\n",
        "                if el not in remove:\n",
        "                    remove.append(el)\n",
        "\n",
        "        for r in remove:\n",
        "            self.fully_connected_list.remove(r)\n",
        "\n",
        "        self.action_list = []\n",
        "        for el in self.fully_connected_list:\n",
        "            new_action = copy.deepcopy(self.zero_action)\n",
        "            for key, value in zip(self.fully_connected, el):\n",
        "                if key in self.camera_actions:\n",
        "                    if value:\n",
        "                        new_action['camera'] = self.camera_dict[key]\n",
        "                else:\n",
        "                    new_action[key] = value\n",
        "            self.action_list.append(new_action)\n",
        "\n",
        "        self.num_action_ids_list = [len(self.action_list)]\n",
        "        self.act_continuous_size = 0\n",
        "\n",
        "    def get_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        a['camera'] += np.random.normal(0., 0.5, 2)\n",
        "        return a\n",
        "\n",
        "    def print_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        out = \"\"\n",
        "        for k, v in a.items():\n",
        "            if k != 'camera':\n",
        "                if v != 0:\n",
        "                    out += f'{k} '\n",
        "            else:\n",
        "                if (v != np.zeros(2)).any():\n",
        "                    out += k\n",
        "\n",
        "        print(out)\n",
        "\n",
        "    def get_id(self, action, batch_size):\n",
        "\n",
        "        coiso = np.zeros((batch_size,), dtype=int)\n",
        "        action = copy.deepcopy(action)\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            # discretize 'camera':\n",
        "            camera = action['camera'][i]\n",
        "            camera_action_amount = 0\n",
        "            if - self.c_action_magnitude / 2. < camera[0] < self.c_action_magnitude / 2.:\n",
        "                action['camera'][i][0] = 0.\n",
        "                if - self.c_action_magnitude / 2. < camera[1] < self.c_action_magnitude / 2.:\n",
        "                    action['camera'][i][1] = 0.\n",
        "                else:\n",
        "                    camera_action_amount = 1\n",
        "                    action['camera'][i][1] = self.c_action_magnitude * np.sign(camera[1])\n",
        "            else:\n",
        "                camera_action_amount = 1\n",
        "                action['camera'][i][0] = self.c_action_magnitude * np.sign(camera[0])\n",
        "\n",
        "                action['camera'][i][1] = 0.\n",
        "\n",
        "            # simplify action:\n",
        "            for tuple_ in self.exclude:\n",
        "                if len(tuple_) == 2:\n",
        "                    a, b = tuple_\n",
        "                    if action[a][i] and action[b][i]:\n",
        "                        action[b][i] = 0\n",
        "            for a, b in self.only_if:\n",
        "                if not action[b][i]:\n",
        "                    if action[a][i]:\n",
        "                        action[a][i] = 0\n",
        "            for a in self.remove_first_list:\n",
        "                if sum([action[key][i] for key in self.fully_connected_no_camera]) > \\\n",
        "                        (self.remove_size - camera_action_amount):\n",
        "                    if a in self.camera_actions:\n",
        "                        action['camera'][i] = np.array([0., 0.])\n",
        "                        camera_action_amount = 0\n",
        "                    else:\n",
        "                        action[a][i] = 0\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # set one_hot camera keys:\n",
        "            for key in self.camera_actions:\n",
        "                action[key] = [0 for x in range(batch_size)]\n",
        "            for key, val in self.camera_dict.items():\n",
        "                if (action['camera'][i] == val).all():\n",
        "                    action[key][i] = 1\n",
        "                    break\n",
        "\n",
        "            non_separate_values = tuple(action[key][i] for key in self.fully_connected)\n",
        "\n",
        "            coiso[i] = self.fully_connected_list.index(non_separate_values)\n",
        "        return coiso\n",
        "\n",
        "    def get_left_right_reversed_mapping(self):\n",
        "        action_mapping = []\n",
        "        for action in self.action_list:\n",
        "            reversed_action = copy.deepcopy(action)\n",
        "            if action['left'] == 1:\n",
        "                reversed_action['left'] = 0\n",
        "                reversed_action['right'] = 1\n",
        "                assert action['right'] == 0\n",
        "            if action['right'] == 1:\n",
        "                reversed_action['right'] = 0\n",
        "                reversed_action['left'] = 1\n",
        "                assert action['left'] == 0\n",
        "            if (action['camera'] == [0, -22.5]).all():\n",
        "                reversed_action['camera'][1] = 22.5\n",
        "            if (action['camera'] == [0, 22.5]).all():\n",
        "                reversed_action['camera'][1] = -22.5\n",
        "\n",
        "            rev_action_id = self.get_id(reversed_action)\n",
        "            action_mapping.append(rev_action_id)\n",
        "\n",
        "        return action_mapping\n",
        "\n",
        "manager = ActionManager()\n",
        "register_wrapper('amiranas', manager.get_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5tdiaUYGUi"
      },
      "source": [
        "## Baseline Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8dNacU-hYGUl"
      },
      "outputs": [],
      "source": [
        "def dataset_action_batch_to_actions(dataset_actions, batch_size, camera_margin=3):\n",
        "    \"\"\"\n",
        "    Turn a batch of actions from dataset (`batch_iter`) to a numpy\n",
        "    array that corresponds to batch of actions of ActionShaping wrapper (_actions).\n",
        "\n",
        "    Camera margin sets the threshold what is considered \"moving camera\".\n",
        "\n",
        "    Note: Hardcoded to work for actions in ActionShaping._actions, with \"intuitive\"\n",
        "        ordering of actions.\n",
        "        If you change ActionShaping._actions, remember to change this!\n",
        "\n",
        "    Array elements are integers corresponding to actions, or \"-1\"\n",
        "    for actions that did not have any corresponding discrete match.\n",
        "    \"\"\"\n",
        "    # There are dummy dimensions of shape one\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Moving camera is most important (horizontal first)\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 7\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 3\n",
        "            else:\n",
        "                actions[i] = 2\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 1\n",
        "        else:\n",
        "            # No reasonable mapping (would be no-op)\n",
        "            actions[i] = 0\n",
        "    return actions\n",
        "\n",
        "register_wrapper('baseline_notebook', dataset_action_batch_to_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "WhuJkgDYJLmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MINERL_DATA_ROOT=/home/minerl\n",
        "%env GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json"
      ],
      "metadata": {
        "id": "zwnzpW4IYRa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d70df5-5d85-49c5-8a67-9cb87764ead6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: MINERL_DATA_ROOT=/home/minerl\n",
            "env: GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m minerl.data.download --environment \"MineRLTreechop-v0\""
      ],
      "metadata": {
        "id": "GrbLl57EYS3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd73fe8-f664-4f94-eb62-8cfff9970eae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl.data.download' found in sys.modules after import of package 'minerl.data', but prior to execution of 'minerl.data.download'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "\u001b[32m2022-07-23 23:31:53\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34m__main__[3751]\u001b[0m \u001b[1;30mINFO\u001b[0m Downloading dataset for MineRLTreechop-v0 to /home/minerl\n",
            "\u001b[32m2022-07-23 23:31:53\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34m__main__[3751]\u001b[0m \u001b[1;30mINFO\u001b[0m Starting download ...\n",
            "\u001b[32m2022-07-23 23:31:53\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mChoosing mirror ...\u001b[0m\n",
            "\u001b[32m2022-07-23 23:31:54\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mPicked https://minerl.s3.amazonaws.com/v4/MineRLTreechop-v0.tar ping=185.388ms\u001b[0m\n",
            "\u001b[32m2022-07-23 23:31:54\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting download at 0.0MB\u001b[0m\n",
            "\u001b[32m2022-07-23 23:31:54\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mFile size is 1510.7MB\u001b[0m\n",
            "Download: https://minerl.s3.amazonaws.com/v4/MineRLTreechop-v0.tar: 100% 1511.0/1510.73792 [00:18<00:00, 82.98MB/s]\n",
            "\u001b[32m2022-07-23 23:32:12\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - downloaded /home/minerl/download/v4/MineRLTreechop-v0.tar\n",
            "\u001b[32m2022-07-23 23:32:12\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mINFO\u001b[0m Extracting downloaded files - this may take some time\n",
            "\u001b[32m2022-07-23 23:32:19\u001b[0m \u001b[35m07049bda15e0\u001b[0m \u001b[34mroot[3751]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - extracted files to /home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "    # The path to your file to upload\n",
        "    # source_file_name = \"local/path/to/file\"\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n"
      ],
      "metadata": {
        "id": "O-eBZe1Ofo-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "metadata": {
        "id": "MoCWq5GvJRmV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_example(state, action, reward, state_next, done):\n",
        "  feature = {\n",
        "      'state' : bytes_feature(tf.io.serialize_tensor(state)),\n",
        "      'action' : int64_feature(action),\n",
        "      'reward' : float_feature(reward),\n",
        "      'state_next' : bytes_feature(tf.io.serialize_tensor(state_next)),\n",
        "      'done' : int64_feature(done)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def decode_example(example):\n",
        "  feature_description = {\n",
        "    'state': tf.io.FixedLenFeature([], tf.string),\n",
        "    'action': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'reward' : tf.io.FixedLenFeature([], tf.float32),\n",
        "    'state_next' : tf.io.FixedLenFeature([], tf.string),\n",
        "    'done' : tf.io.FixedLenFeature([], tf.int64)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "  state = tf.io.parse_tensor(example['state'], out_type=tf.float32)\n",
        "  state = tf.reshape(state, (64, 64, 3))\n",
        "\n",
        "  state_next = tf.io.parse_tensor(example['state_next'], out_type=tf.float32)\n",
        "  state_next = tf.reshape(state, (64, 64, 3))\n",
        "\n",
        "  return state, example['action'], example['reward'], state_next, example['done']"
      ],
      "metadata": {
        "id": "jRKdNnHjRBjU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_expert_data(wrapper, examples_per_file, dataset_dir):\n",
        "    wrap = wrappers[wrapper]\n",
        "\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = minerl.data.BufferedBatchIter(data, 30000)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(dataset_dir)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    i = 0\n",
        "    for state, action, reward, state_next, done in iterator.buffered_batch_iter(examples_per_file, num_epochs=1):\n",
        "        state = state['pov'].squeeze().astype(np.float32) / 255\n",
        "        state_next = state_next['pov'].squeeze().astype(np.float32) / 255\n",
        "        action = wrap(action, examples_per_file).squeeze()\n",
        "        \n",
        "        filename = f'{i}.tfrecord'\n",
        "        filepath = f'{dataset_dir}/{filename}'\n",
        "        blobpath = f'tfrecords_complete/{filename}'\n",
        "        \n",
        "        with tf.io.TFRecordWriter(filepath) as writer:\n",
        "            for x in range(examples_per_file):\n",
        "                example = encode_example(state[x], action[x], reward[x], state_next[x], done[x])\n",
        "                writer.write(example.SerializeToString())\n",
        "        upload_blob('minerl_data_records', filepath, blobpath)\n",
        "        os.remove(filepath)\n",
        "\n",
        "        i += 1\n"
      ],
      "metadata": {
        "id": "bFqbXyB8M6jh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listdir(dir):\n",
        "    return list(map(\n",
        "        lambda file: dir + '/' + file,\n",
        "        os.listdir(dir)\n",
        "    ))"
      ],
      "metadata": {
        "id": "ROT5pG0rSL9M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            .repeat()\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )\n",
        "\n",
        "def create_val_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )"
      ],
      "metadata": {
        "id": "Kv80oX7LSMgQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfAkWunYGUZ"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loop"
      ],
      "metadata": {
        "id": "A2piAVS4fTFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from collections import namedtuple\n",
        "\n",
        "def fit(model, loss_fn, optimizer, dataset, epochs, steps):\n",
        "\n",
        "    History = namedtuple('History', 'history')\n",
        "    history = History(history={\n",
        "        'loss': [],\n",
        "        'val_loss': []\n",
        "    })\n",
        "\n",
        "\n",
        "    epoch = 0\n",
        "\n",
        "    with tqdm(total=epochs) as ebar:\n",
        "        with tqdm(total=steps) as pbar:\n",
        "            for step, (x, y) in enumerate(dataset):\n",
        "\n",
        "                train_loss = 0\n",
        "\n",
        "                with tf.GradientTape() as tape:\n",
        "                    y_pred = model(x)\n",
        "                    loss = loss_fn(y, y_pred)\n",
        "                grads = tape.gradient(loss, model.trainable_weights)\n",
        "                optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "                train_loss += loss\n",
        "\n",
        "                if step % steps == 0:\n",
        "\n",
        "                    history.history['loss'].append(train_loss)\n",
        "                    train_loss = 0\n",
        "\n",
        "                    epoch += 1\n",
        "                    ebar.update(1)\n",
        "                    pbar.reset()\n",
        "                if epoch == epochs:\n",
        "                    break\n",
        "                pbar.update(1)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "fxsyDC1tfWiH"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWBZqHjZYGUb"
      },
      "source": [
        "## DQN Epsilon Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ESpX6wnwYGUc"
      },
      "outputs": [],
      "source": [
        "def train(model, model_target, env):\n",
        "\n",
        "    num_actions = 4\n",
        "\n",
        "    seed = 42\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    epsilon_min = 0.1\n",
        "    epsilon_max = 1.0\n",
        "    epsilon_interval = (\n",
        "        epsilon_max - epsilon_min\n",
        "    )\n",
        "    batch_size = 32\n",
        "    max_steps_per_episode = 10000\n",
        "\n",
        "    env.seed(seed)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "    loss_function = keras.losses.Huber()\n",
        "\n",
        "    action_history = []\n",
        "    state_history = []\n",
        "    state_next_history = []\n",
        "    rewards_history = []\n",
        "    done_history = []\n",
        "    episode_reward_history = []\n",
        "\n",
        "    frame_sample = []\n",
        "\n",
        "    running_reward = 0\n",
        "    episode_count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    epsilon_random_frames = 50000\n",
        "    epsilon_greedy_frames = 10000000\n",
        "\n",
        "    max_memory_length = 100000\n",
        "\n",
        "    update_after_actions = 4\n",
        "    update_target_network = 1000\n",
        "\n",
        "    while True:\n",
        "        state = np.array(env.reset())\n",
        "        episode_reward = 0\n",
        "\n",
        "        start = time.time()\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            end = time.time()\n",
        "            frame_sample.append(end - start)\n",
        "            if len(frame_sample) == 60 * 5:\n",
        "                coiso = np.mean(frame_sample)\n",
        "                print(f'FPS: {1 / coiso}')\n",
        "                frame_sample = []\n",
        "            start = time.time()\n",
        "\n",
        "            #env.render()\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
        "                action = np.random.choice(num_actions)\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "            \n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            state_next, reward, done, _ = env.step(action)\n",
        "            state_next = np.array(state_next)\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            action_history.append(action)\n",
        "            state_history.append(state)\n",
        "            state_next_history.append(state_next)\n",
        "            done_history.append(done)\n",
        "            rewards_history.append(reward)\n",
        "            state = state_next\n",
        "\n",
        "            if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "                \n",
        "                indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "                state_sample = np.array([state_history[i] for i in indices])\n",
        "                state_next_sample = np.array([state_next_history[i] for i in indices])\n",
        "                rewards_sample = np.array([rewards_history[i] for i in indices])\n",
        "                action_sample = np.array([action_history[i] for i in indices])\n",
        "                done_sample = tf.convert_to_tensor(\n",
        "                    [float(done_history[i]) for i in indices]\n",
        "                )\n",
        "\n",
        "                future_rewards = predict_target(model_target, state_next_sample)\n",
        "                updated_q_values = rewards_sample + gamma * tf.reduce_max (\n",
        "                    future_rewards, axis=1\n",
        "                )\n",
        "                updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "                masks = tf.one_hot(action_sample, num_actions)\n",
        "\n",
        "                backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks)\n",
        "\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "                template = 'running reward: {:.2f} at episode {}, frame count {}'\n",
        "                print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "            if len(rewards_history) > max_memory_length:\n",
        "                del rewards_history[:1]\n",
        "                del state_history[:1]\n",
        "                del state_next_history[:1]\n",
        "                del action_history[:1]\n",
        "                del done_history[:1]\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if len(episode_reward_history) > 100:\n",
        "                del episode_reward_history[:1]\n",
        "            running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "            episode_count += 1\n",
        "\n",
        "            if running_reward > 40:\n",
        "                print('Solved at episode {}!'.format(episode_count))\n",
        "                break\n",
        "\n",
        "@tf.function\n",
        "def predict_target(model_target, state_next_sample):\n",
        "    future_rewards = model_target(state_next_sample)\n",
        "    return future_rewards\n",
        "\n",
        "@tf.function\n",
        "def backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state_sample)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "        loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjH-s9ZYGUU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "def register_model(name, model):\n",
        "    models[name] = model"
      ],
      "metadata": {
        "id": "mrjqzbYOc9Q5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjlYz3CYGUW"
      },
      "source": [
        "## Deepmind Atari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EagSZZ1jYGUW"
      },
      "outputs": [],
      "source": [
        "def deepmind_atari(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(inputs)\n",
        "    x = Conv2D(64, 4, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    output = Dense(nb_outputs, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output)\n",
        "\n",
        "register_model('deepmind_atari', deepmind_atari)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtTS3OdYGUX"
      },
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "88KAQJ-jYGUY"
      },
      "outputs": [],
      "source": [
        "def xception(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = Rescaling(1.0 / 255)(inputs)\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    outputs = Dense(nb_outputs, activation='linear')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "register_model('xception', xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A26gdzdYGUl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WRAPPER = 'amiranas'\n",
        "MODEL = 'deepmind_atari'\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "EXAMPLES_PER_FILE = 2048\n",
        "\n",
        "CHECKPOINT = '/content/drive/MyDrive/weights/checkpoint'\n",
        "DATASET_DIR = '/home/minerl/tfrecords'"
      ],
      "metadata": {
        "id": "1rIDGfeUOyxV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYOyClORkVBM",
        "outputId": "405d6a8e-a2bf-4378-8a62-5b278a61b7ba"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "preprocess_expert_data(WRAPPER, EXAMPLES_PER_FILE, DATASET_DIR)"
      ],
      "metadata": {
        "id": "dMeoVc0POveU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_pattern = 'gs://minerl_data_records/tfrecords_complete/*.tfrecord'\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "validation_split = 0.1\n",
        "split = len(filenames) - int(len(filenames) * validation_split)\n",
        "train_fns = filenames[:split]\n",
        "validation_fns = filenames[split:]\n",
        "\n",
        "dataset = create_dataset(train_fns, BATCH_SIZE)\n",
        "val_dataset = create_val_dataset(validation_fns, BATCH_SIZE)\n",
        "\n",
        "dataset = dataset.map(lambda state, action, reward, state_next, done: (state, action))\n",
        "val_dataset = val_dataset.map(lambda state, action, reward, state_next, done: (state, action))"
      ],
      "metadata": {
        "id": "M8x0I3mCQ1mc"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = models[MODEL]((64, 64, 3), 112)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer, loss_fn, metrics=[val_acc_metric])"
      ],
      "metadata": {
        "id": "J_GyEeck31hx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[MODEL]((64, 64, 3), 112)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "qA2UkaYWgcTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(CHECKPOINT)"
      ],
      "metadata": {
        "id": "nGPLAxsatOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT, save_weights_only=True, save_best_only=True)"
      ],
      "metadata": {
        "id": "1rNJwmVVjOIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "history = fit(model, loss_fn, optimizer, dataset, EPOCHS, steps_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "ec949e195d5d4ccc9f5c885ef8542da7",
            "61947d2e1c3f443f91cf78885b1765ab",
            "f15d677744b14aa8a110a63c73ae24d9",
            "f4ecdfc1867348b08b805c8350c1bcce",
            "af433baa4d0a45258fbcf0f39d7e84b5",
            "7066414a1e134dbd906121ed700189ac",
            "c76fa94bbdd94c65a6ce26615f2bb26b",
            "3db8014e8762448a95e1f7b8fd958414",
            "89eeb76f72c44a7bb8a3e9304cd25ee3",
            "de86056e4c8d49459feaa5be8d9302c3",
            "19201352c54b4cec8057df47d36d01f4",
            "77d9d560cb564ba0ad81675d1db54b1e",
            "e6617d39fbf84f43820b4e92007ef29b",
            "f69b4ef5e59241a393a1a2bedd5676bb",
            "02b63508db1c4564ab818b3a2e14784e",
            "964ff05861df43a1a8222c8c64c4f701",
            "52ddcba4664b4189b513c8350458609d",
            "218a0d04b64148678f8a3d513be8cc9f",
            "9566dfdd456d45bc8db6cf91e21a4080",
            "0b3ef678c9d446acb468a7166431a249",
            "9ba58da9d89e43a49a3d782c0ad7475d",
            "a34086a0bf4344a294dd01e428584a64"
          ]
        },
        "id": "UtyBsx4igJmG",
        "outputId": "ef2a362b-0d79-4569-e795-88ae06fd79c6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec949e195d5d4ccc9f5c885ef8542da7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/296.0 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77d9d560cb564ba0ad81675d1db54b1e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "validation_steps = len(validation_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "\n",
        "history = model.fit(dataset, validation_data=val_dataset, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, epochs=EPOCHS, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "BzhhDNxs38Mm",
        "outputId": "482101b0-c5dd-4fbd-fb3d-1a64f55bed7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "296/296 [==============================] - 16s 37ms/step - loss: 1.7052 - sparse_categorical_accuracy: 0.5865 - val_loss: 1.4789 - val_sparse_categorical_accuracy: 0.6160\n",
            "Epoch 2/50\n",
            "296/296 [==============================] - 15s 52ms/step - loss: 1.3577 - sparse_categorical_accuracy: 0.6370 - val_loss: 1.3664 - val_sparse_categorical_accuracy: 0.6414\n",
            "Epoch 3/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 1.2694 - sparse_categorical_accuracy: 0.6605 - val_loss: 1.3101 - val_sparse_categorical_accuracy: 0.6566\n",
            "Epoch 4/50\n",
            "296/296 [==============================] - 10s 34ms/step - loss: 1.2131 - sparse_categorical_accuracy: 0.6725 - val_loss: 1.2828 - val_sparse_categorical_accuracy: 0.6617\n",
            "Epoch 5/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 1.1752 - sparse_categorical_accuracy: 0.6818 - val_loss: 1.2641 - val_sparse_categorical_accuracy: 0.6599\n",
            "Epoch 6/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 1.1434 - sparse_categorical_accuracy: 0.6879 - val_loss: 1.2613 - val_sparse_categorical_accuracy: 0.6605\n",
            "Epoch 7/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 1.1161 - sparse_categorical_accuracy: 0.6936 - val_loss: 1.2363 - val_sparse_categorical_accuracy: 0.6623\n",
            "Epoch 8/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 1.0883 - sparse_categorical_accuracy: 0.7001 - val_loss: 1.2331 - val_sparse_categorical_accuracy: 0.6655\n",
            "Epoch 9/50\n",
            "296/296 [==============================] - 10s 34ms/step - loss: 1.0689 - sparse_categorical_accuracy: 0.7043 - val_loss: 1.2227 - val_sparse_categorical_accuracy: 0.6677\n",
            "Epoch 10/50\n",
            "296/296 [==============================] - 10s 32ms/step - loss: 1.0463 - sparse_categorical_accuracy: 0.7097 - val_loss: 1.2198 - val_sparse_categorical_accuracy: 0.6703\n",
            "Epoch 11/50\n",
            "296/296 [==============================] - 16s 53ms/step - loss: 1.0269 - sparse_categorical_accuracy: 0.7137 - val_loss: 1.2231 - val_sparse_categorical_accuracy: 0.6692\n",
            "Epoch 12/50\n",
            "296/296 [==============================] - 19s 65ms/step - loss: 1.0144 - sparse_categorical_accuracy: 0.7162 - val_loss: 1.2168 - val_sparse_categorical_accuracy: 0.6722\n",
            "Epoch 13/50\n",
            "296/296 [==============================] - 18s 60ms/step - loss: 0.9876 - sparse_categorical_accuracy: 0.7227 - val_loss: 1.2147 - val_sparse_categorical_accuracy: 0.6729\n",
            "Epoch 14/50\n",
            "296/296 [==============================] - 8s 28ms/step - loss: 0.9720 - sparse_categorical_accuracy: 0.7262 - val_loss: 1.2251 - val_sparse_categorical_accuracy: 0.6716\n",
            "Epoch 15/50\n",
            "296/296 [==============================] - 8s 29ms/step - loss: 0.9548 - sparse_categorical_accuracy: 0.7297 - val_loss: 1.2299 - val_sparse_categorical_accuracy: 0.6732\n",
            "Epoch 16/50\n",
            "296/296 [==============================] - 9s 31ms/step - loss: 0.9397 - sparse_categorical_accuracy: 0.7333 - val_loss: 1.2280 - val_sparse_categorical_accuracy: 0.6770\n",
            "Epoch 17/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.9266 - sparse_categorical_accuracy: 0.7351 - val_loss: 1.2209 - val_sparse_categorical_accuracy: 0.6768\n",
            "Epoch 18/50\n",
            "296/296 [==============================] - 8s 29ms/step - loss: 0.9085 - sparse_categorical_accuracy: 0.7397 - val_loss: 1.2517 - val_sparse_categorical_accuracy: 0.6711\n",
            "Epoch 19/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.8964 - sparse_categorical_accuracy: 0.7425 - val_loss: 1.2455 - val_sparse_categorical_accuracy: 0.6747\n",
            "Epoch 20/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.8785 - sparse_categorical_accuracy: 0.7468 - val_loss: 1.2514 - val_sparse_categorical_accuracy: 0.6755\n",
            "Epoch 21/50\n",
            "296/296 [==============================] - 10s 35ms/step - loss: 0.8657 - sparse_categorical_accuracy: 0.7506 - val_loss: 1.2589 - val_sparse_categorical_accuracy: 0.6745\n",
            "Epoch 22/50\n",
            "296/296 [==============================] - 9s 31ms/step - loss: 0.8572 - sparse_categorical_accuracy: 0.7510 - val_loss: 1.2448 - val_sparse_categorical_accuracy: 0.6760\n",
            "Epoch 23/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.8455 - sparse_categorical_accuracy: 0.7541 - val_loss: 1.2543 - val_sparse_categorical_accuracy: 0.6718\n",
            "Epoch 24/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.8321 - sparse_categorical_accuracy: 0.7568 - val_loss: 1.2585 - val_sparse_categorical_accuracy: 0.6747\n",
            "Epoch 25/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.8199 - sparse_categorical_accuracy: 0.7599 - val_loss: 1.2826 - val_sparse_categorical_accuracy: 0.6675\n",
            "Epoch 26/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.8109 - sparse_categorical_accuracy: 0.7616 - val_loss: 1.2881 - val_sparse_categorical_accuracy: 0.6669\n",
            "Epoch 27/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.7983 - sparse_categorical_accuracy: 0.7645 - val_loss: 1.2870 - val_sparse_categorical_accuracy: 0.6751\n",
            "Epoch 28/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.7885 - sparse_categorical_accuracy: 0.7667 - val_loss: 1.3131 - val_sparse_categorical_accuracy: 0.6694\n",
            "Epoch 29/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7772 - sparse_categorical_accuracy: 0.7697 - val_loss: 1.3241 - val_sparse_categorical_accuracy: 0.6694\n",
            "Epoch 30/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7680 - sparse_categorical_accuracy: 0.7719 - val_loss: 1.3267 - val_sparse_categorical_accuracy: 0.6693\n",
            "Epoch 31/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7582 - sparse_categorical_accuracy: 0.7735 - val_loss: 1.3250 - val_sparse_categorical_accuracy: 0.6699\n",
            "Epoch 32/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7499 - sparse_categorical_accuracy: 0.7756 - val_loss: 1.3402 - val_sparse_categorical_accuracy: 0.6725\n",
            "Epoch 33/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.7409 - sparse_categorical_accuracy: 0.7781 - val_loss: 1.3621 - val_sparse_categorical_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.7316 - sparse_categorical_accuracy: 0.7805 - val_loss: 1.3861 - val_sparse_categorical_accuracy: 0.6588\n",
            "Epoch 35/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.7268 - sparse_categorical_accuracy: 0.7811 - val_loss: 1.3830 - val_sparse_categorical_accuracy: 0.6670\n",
            "Epoch 36/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7182 - sparse_categorical_accuracy: 0.7835 - val_loss: 1.3854 - val_sparse_categorical_accuracy: 0.6686\n",
            "Epoch 37/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7100 - sparse_categorical_accuracy: 0.7856 - val_loss: 1.3970 - val_sparse_categorical_accuracy: 0.6714\n",
            "Epoch 38/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.7013 - sparse_categorical_accuracy: 0.7872 - val_loss: 1.4013 - val_sparse_categorical_accuracy: 0.6710\n",
            "Epoch 39/50\n",
            "296/296 [==============================] - 8s 29ms/step - loss: 0.7037 - sparse_categorical_accuracy: 0.7860 - val_loss: 1.4012 - val_sparse_categorical_accuracy: 0.6708\n",
            "Epoch 40/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.7891 - val_loss: 1.4373 - val_sparse_categorical_accuracy: 0.6625\n",
            "Epoch 41/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.7874 - val_loss: 1.4366 - val_sparse_categorical_accuracy: 0.6663\n",
            "Epoch 42/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.6752 - sparse_categorical_accuracy: 0.7925 - val_loss: 1.4491 - val_sparse_categorical_accuracy: 0.6655\n",
            "Epoch 43/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.6654 - sparse_categorical_accuracy: 0.7958 - val_loss: 1.4628 - val_sparse_categorical_accuracy: 0.6677\n",
            "Epoch 44/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.6601 - sparse_categorical_accuracy: 0.7968 - val_loss: 1.4674 - val_sparse_categorical_accuracy: 0.6661\n",
            "Epoch 45/50\n",
            "296/296 [==============================] - 8s 29ms/step - loss: 0.6540 - sparse_categorical_accuracy: 0.7981 - val_loss: 1.4806 - val_sparse_categorical_accuracy: 0.6636\n",
            "Epoch 46/50\n",
            "296/296 [==============================] - 10s 33ms/step - loss: 0.6480 - sparse_categorical_accuracy: 0.7997 - val_loss: 1.4836 - val_sparse_categorical_accuracy: 0.6661\n",
            "Epoch 47/50\n",
            "296/296 [==============================] - 8s 29ms/step - loss: 0.6512 - sparse_categorical_accuracy: 0.7974 - val_loss: 1.5021 - val_sparse_categorical_accuracy: 0.6625\n",
            "Epoch 48/50\n",
            "296/296 [==============================] - 9s 29ms/step - loss: 0.6393 - sparse_categorical_accuracy: 0.8020 - val_loss: 1.5198 - val_sparse_categorical_accuracy: 0.6671\n",
            "Epoch 49/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.6309 - sparse_categorical_accuracy: 0.8033 - val_loss: 1.5311 - val_sparse_categorical_accuracy: 0.6682\n",
            "Epoch 50/50\n",
            "296/296 [==============================] - 9s 30ms/step - loss: 0.6208 - sparse_categorical_accuracy: 0.8067 - val_loss: 1.5488 - val_sparse_categorical_accuracy: 0.6624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "#display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], [], 'loss', 212)"
      ],
      "metadata": {
        "id": "mgSV7L5yBDPE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "2ec918f7-f62a-4441-b31d-a65e322f423b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec949e195d5d4ccc9f5c885ef8542da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_61947d2e1c3f443f91cf78885b1765ab",
              "IPY_MODEL_f15d677744b14aa8a110a63c73ae24d9",
              "IPY_MODEL_f4ecdfc1867348b08b805c8350c1bcce"
            ],
            "layout": "IPY_MODEL_af433baa4d0a45258fbcf0f39d7e84b5"
          }
        },
        "61947d2e1c3f443f91cf78885b1765ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7066414a1e134dbd906121ed700189ac",
            "placeholder": "",
            "style": "IPY_MODEL_c76fa94bbdd94c65a6ce26615f2bb26b",
            "value": "100%"
          }
        },
        "f15d677744b14aa8a110a63c73ae24d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db8014e8762448a95e1f7b8fd958414",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89eeb76f72c44a7bb8a3e9304cd25ee3",
            "value": 10
          }
        },
        "f4ecdfc1867348b08b805c8350c1bcce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de86056e4c8d49459feaa5be8d9302c3",
            "placeholder": "",
            "style": "IPY_MODEL_19201352c54b4cec8057df47d36d01f4",
            "value": " 10/10 [07:49&lt;00:00, 50.92s/it]"
          }
        },
        "af433baa4d0a45258fbcf0f39d7e84b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7066414a1e134dbd906121ed700189ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76fa94bbdd94c65a6ce26615f2bb26b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3db8014e8762448a95e1f7b8fd958414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89eeb76f72c44a7bb8a3e9304cd25ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de86056e4c8d49459feaa5be8d9302c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19201352c54b4cec8057df47d36d01f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77d9d560cb564ba0ad81675d1db54b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6617d39fbf84f43820b4e92007ef29b",
              "IPY_MODEL_f69b4ef5e59241a393a1a2bedd5676bb",
              "IPY_MODEL_02b63508db1c4564ab818b3a2e14784e"
            ],
            "layout": "IPY_MODEL_964ff05861df43a1a8222c8c64c4f701"
          }
        },
        "e6617d39fbf84f43820b4e92007ef29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ddcba4664b4189b513c8350458609d",
            "placeholder": "",
            "style": "IPY_MODEL_218a0d04b64148678f8a3d513be8cc9f",
            "value": "  0%"
          }
        },
        "f69b4ef5e59241a393a1a2bedd5676bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9566dfdd456d45bc8db6cf91e21a4080",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b3ef678c9d446acb468a7166431a249",
            "value": 0
          }
        },
        "02b63508db1c4564ab818b3a2e14784e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba58da9d89e43a49a3d782c0ad7475d",
            "placeholder": "",
            "style": "IPY_MODEL_a34086a0bf4344a294dd01e428584a64",
            "value": " 0/296.0 [00:00&lt;?, ?it/s]"
          }
        },
        "964ff05861df43a1a8222c8c64c4f701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ddcba4664b4189b513c8350458609d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "218a0d04b64148678f8a3d513be8cc9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9566dfdd456d45bc8db6cf91e21a4080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3ef678c9d446acb468a7166431a249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba58da9d89e43a49a3d782c0ad7475d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a34086a0bf4344a294dd01e428584a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}