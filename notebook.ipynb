{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imenatrix/TCC-INFO19/blob/feature-parametrization/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jQ0equmGYKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk"
      ],
      "metadata": {
        "id": "YRB8g4TMYMC_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install minerl"
      ],
      "metadata": {
        "id": "kDkezv40YO5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "WhuJkgDYJLmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MINERL_DATA_ROOT=/home/minerl"
      ],
      "metadata": {
        "id": "zwnzpW4IYRa2",
        "outputId": "d8e91a79-61ce-4087-8ba1-09a8d2120fda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MINERL_DATA_ROOT=/home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m minerl.data.download --environment \"MineRLTreechop-v0\""
      ],
      "metadata": {
        "id": "GrbLl57EYS3u",
        "outputId": "0e754100-a431-4e00-9c25-9e6182264bd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl.data.download' found in sys.modules after import of package 'minerl.data', but prior to execution of 'minerl.data.download'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "\u001b[32m2022-06-12 14:57:26\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34m__main__[3715]\u001b[0m \u001b[1;30mINFO\u001b[0m Downloading dataset for MineRLTreechop-v0 to /home/minerl\n",
            "\u001b[32m2022-06-12 14:57:26\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34m__main__[3715]\u001b[0m \u001b[1;30mINFO\u001b[0m Starting download ...\n",
            "\u001b[32m2022-06-12 14:57:26\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mChoosing mirror ...\u001b[0m\n",
            "\u001b[32m2022-06-12 14:57:27\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mPicked https://minerl.s3.amazonaws.com/v4/MineRLTreechop-v0.tar ping=162.673ms\u001b[0m\n",
            "\u001b[32m2022-06-12 14:57:27\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting download at 0.0MB\u001b[0m\n",
            "\u001b[32m2022-06-12 14:57:27\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mFile size is 1510.7MB\u001b[0m\n",
            "Download: https://minerl.s3.amazonaws.com/v4/MineRLTreechop-v0.tar: 100% 1511.0/1510.73792 [00:18<00:00, 81.38MB/s]\n",
            "\u001b[32m2022-06-12 14:57:45\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - downloaded /home/minerl/download/v4/MineRLTreechop-v0.tar\n",
            "\u001b[32m2022-06-12 14:57:45\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mINFO\u001b[0m Extracting downloaded files - this may take some time\n",
            "\u001b[32m2022-06-12 14:57:51\u001b[0m \u001b[35mbbab410a51be\u001b[0m \u001b[34mroot[3715]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - extracted files to /home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "metadata": {
        "id": "MoCWq5GvJRmV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sample(obs, action_id):\n",
        "  feature = {\n",
        "      'obs' : bytes_feature(tf.io.serialize_tensor(obs)),\n",
        "      'action_id' : int64_list_feature(action_id)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def decode_sample(sample):\n",
        "  feature_description = {\n",
        "    \"obs\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"action_id\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
        "  }\n",
        "  sample = tf.io.parse_single_example(sample, feature_description)\n",
        "  return tf.io.parse_tensor(sample['obs'], out_type=tf.float32), sample['action_id']"
      ],
      "metadata": {
        "id": "jRKdNnHjRBjU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import minerl\n",
        "from minerl.data import BufferedBatchIter\n",
        "\n",
        "manager = ActionManager()\n",
        "\n",
        "data = minerl.data.make('MineRLTreechop-v0')\n",
        "iterator = BufferedBatchIter(data, 30000)\n",
        "\n",
        "try:\n",
        "  os.makedirs('/home/minerl/tfrecords')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "i = 0\n",
        "for current_state, action, reward, next_state, done in iterator.buffered_batch_iter(32, num_epochs=1):\n",
        "    obs = current_state[\"pov\"].squeeze().astype(np.float32) / 255\n",
        "    action_id = manager.get_id(action, 32).squeeze()\n",
        "    \n",
        "    sample = encode_sample(obs, action_id)\n",
        "    with tf.io.TFRecordWriter(f'/home/minerl/tfrecords/{i}.tfrecord') as writer:\n",
        "      writer.write(sample.SerializeToString())\n",
        "\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "bFqbXyB8M6jh",
        "outputId": "c746b731-6918-41d7-ea9a-bf58771362f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "100%|██████████| 1867/1867 [00:00<00:00, 95747.02it/s]\n",
            "100%|██████████| 1766/1766 [00:00<00:00, 94645.43it/s]\n",
            "100%|██████████| 1528/1528 [00:00<00:00, 80893.85it/s]\n",
            "100%|██████████| 1417/1417 [00:00<00:00, 65124.52it/s]\n",
            "100%|██████████| 2281/2281 [00:00<00:00, 81703.96it/s]\n",
            "100%|██████████| 1967/1967 [00:00<00:00, 8636.19it/s]\n",
            "100%|██████████| 2159/2159 [00:00<00:00, 84775.85it/s]\n",
            "100%|██████████| 3139/3139 [00:00<00:00, 85011.62it/s]\n",
            "100%|██████████| 1803/1803 [00:00<00:00, 76985.17it/s]\n",
            "100%|██████████| 1697/1697 [00:00<00:00, 69910.56it/s]\n",
            "100%|██████████| 2851/2851 [00:00<00:00, 86008.69it/s]\n",
            "100%|██████████| 2194/2194 [00:00<00:00, 79367.14it/s]\n",
            "100%|██████████| 1568/1568 [00:00<00:00, 88039.90it/s]\n",
            "100%|██████████| 2582/2582 [00:00<00:00, 87594.78it/s]\n",
            "100%|██████████| 1603/1603 [00:00<00:00, 80295.57it/s]\n",
            "100%|██████████| 1452/1452 [00:00<00:00, 58073.69it/s]\n",
            "100%|██████████| 1677/1677 [00:00<00:00, 59434.10it/s]\n",
            "100%|██████████| 2063/2063 [00:00<00:00, 65298.61it/s]\n",
            "100%|██████████| 1565/1565 [00:00<00:00, 7868.13it/s]\n",
            "100%|██████████| 1844/1844 [00:00<00:00, 61581.25it/s]\n",
            "100%|██████████| 1761/1761 [00:00<00:00, 65244.23it/s]\n",
            "100%|██████████| 1845/1845 [00:00<00:00, 58787.04it/s]\n",
            "100%|██████████| 1624/1624 [00:00<00:00, 67353.73it/s]\n",
            "100%|██████████| 1581/1581 [00:00<00:00, 57347.40it/s]\n",
            "100%|██████████| 1608/1608 [00:00<00:00, 52573.48it/s]\n",
            "100%|██████████| 1949/1949 [00:00<00:00, 59171.77it/s]\n",
            "100%|██████████| 2216/2216 [00:00<00:00, 65405.49it/s]\n",
            "100%|██████████| 1941/1941 [00:00<00:00, 62243.54it/s]\n",
            "100%|██████████| 1795/1795 [00:00<00:00, 59872.88it/s]\n",
            "100%|██████████| 2144/2144 [00:00<00:00, 68693.43it/s]\n",
            "100%|██████████| 1615/1615 [00:00<00:00, 68941.03it/s]\n",
            "100%|██████████| 2845/2845 [00:00<00:00, 62233.60it/s]\n",
            "100%|██████████| 2669/2669 [00:00<00:00, 65447.88it/s]\n",
            "100%|██████████| 4135/4135 [00:00<00:00, 15238.85it/s]\n",
            "100%|██████████| 3250/3250 [00:00<00:00, 71586.81it/s]\n",
            "100%|██████████| 3017/3017 [00:00<00:00, 62290.62it/s]\n",
            "100%|██████████| 1830/1830 [00:00<00:00, 57383.20it/s]\n",
            "100%|██████████| 3509/3509 [00:00<00:00, 72555.87it/s]\n",
            "100%|██████████| 1939/1939 [00:00<00:00, 63871.48it/s]\n",
            "100%|██████████| 2750/2750 [00:00<00:00, 61708.66it/s]\n",
            "100%|██████████| 1384/1384 [00:00<00:00, 62580.63it/s]\n",
            "100%|██████████| 2255/2255 [00:00<00:00, 58094.99it/s]\n",
            "100%|██████████| 2661/2661 [00:00<00:00, 69763.49it/s]\n",
            "100%|██████████| 1951/1951 [00:00<00:00, 49052.81it/s]\n",
            "100%|██████████| 2898/2898 [00:00<00:00, 64279.67it/s]\n",
            "100%|██████████| 2122/2122 [00:00<00:00, 7792.85it/s]\n",
            "100%|██████████| 1787/1787 [00:00<00:00, 80540.95it/s]\n",
            "100%|██████████| 2525/2525 [00:00<00:00, 52790.23it/s]\n",
            "100%|██████████| 1519/1519 [00:00<00:00, 58880.35it/s]\n",
            "100%|██████████| 1494/1494 [00:00<00:00, 55066.96it/s]\n",
            "100%|██████████| 1909/1909 [00:00<00:00, 57216.03it/s]\n",
            "100%|██████████| 2433/2433 [00:00<00:00, 60181.89it/s]\n",
            "100%|██████████| 2717/2717 [00:00<00:00, 62547.61it/s]\n",
            "100%|██████████| 1465/1465 [00:00<00:00, 61993.33it/s]\n",
            "100%|██████████| 1520/1520 [00:00<00:00, 62027.81it/s]\n",
            "100%|██████████| 4578/4578 [00:00<00:00, 67268.26it/s]\n",
            "100%|██████████| 2014/2014 [00:00<00:00, 60046.83it/s]\n",
            "100%|██████████| 1818/1818 [00:00<00:00, 60991.22it/s]\n",
            "100%|██████████| 4383/4383 [00:00<00:00, 68377.00it/s]\n",
            "100%|██████████| 2050/2050 [00:00<00:00, 62164.79it/s]\n",
            "100%|██████████| 2115/2115 [00:00<00:00, 8042.95it/s]\n",
            "100%|██████████| 1945/1945 [00:00<00:00, 58273.36it/s]\n",
            "100%|██████████| 1746/1746 [00:00<00:00, 58674.28it/s]\n",
            "100%|██████████| 2195/2195 [00:00<00:00, 69370.43it/s]\n",
            "100%|██████████| 1918/1918 [00:00<00:00, 42016.43it/s]\n",
            "100%|██████████| 5678/5678 [00:00<00:00, 65135.21it/s]\n",
            "100%|██████████| 2523/2523 [00:00<00:00, 65818.07it/s]\n",
            "100%|██████████| 1877/1877 [00:00<00:00, 60428.21it/s]\n",
            "100%|██████████| 1668/1668 [00:00<00:00, 71162.21it/s]\n",
            "100%|██████████| 1674/1674 [00:00<00:00, 62234.77it/s]\n",
            "100%|██████████| 3396/3396 [00:00<00:00, 63111.36it/s]\n",
            "100%|██████████| 1963/1963 [00:00<00:00, 57865.28it/s]\n",
            "100%|██████████| 1949/1949 [00:00<00:00, 43027.67it/s]\n",
            "100%|██████████| 2729/2729 [00:00<00:00, 10356.75it/s]\n",
            "100%|██████████| 1964/1964 [00:00<00:00, 53378.69it/s]\n",
            "100%|██████████| 1570/1570 [00:00<00:00, 60228.26it/s]\n",
            "100%|██████████| 2168/2168 [00:00<00:00, 56301.82it/s]\n",
            "100%|██████████| 2761/2761 [00:00<00:00, 58916.92it/s]\n",
            "100%|██████████| 3017/3017 [00:00<00:00, 65011.77it/s]\n",
            "100%|██████████| 1926/1926 [00:00<00:00, 55483.87it/s]\n",
            "100%|██████████| 1985/1985 [00:00<00:00, 57353.71it/s]\n",
            "100%|██████████| 1635/1635 [00:00<00:00, 58678.41it/s]\n",
            "100%|██████████| 1889/1889 [00:00<00:00, 65101.44it/s]\n",
            "100%|██████████| 1639/1639 [00:00<00:00, 61021.19it/s]\n",
            "100%|██████████| 2557/2557 [00:00<00:00, 62544.60it/s]\n",
            "100%|██████████| 2413/2413 [00:00<00:00, 54843.40it/s]\n",
            "100%|██████████| 2700/2700 [00:00<00:00, 9306.29it/s]\n",
            "100%|██████████| 2495/2495 [00:00<00:00, 59692.03it/s]\n",
            "100%|██████████| 2460/2460 [00:00<00:00, 61174.81it/s]\n",
            "100%|██████████| 2389/2389 [00:00<00:00, 60468.61it/s]\n",
            "100%|██████████| 1718/1718 [00:00<00:00, 54991.52it/s]\n",
            "100%|██████████| 1703/1703 [00:00<00:00, 53998.33it/s]\n",
            "100%|██████████| 2651/2651 [00:00<00:00, 63946.97it/s]\n",
            "100%|██████████| 2580/2580 [00:00<00:00, 48980.47it/s]\n",
            "100%|██████████| 2215/2215 [00:00<00:00, 57698.15it/s]\n",
            "100%|██████████| 1630/1630 [00:00<00:00, 50365.51it/s]\n",
            "100%|██████████| 2438/2438 [00:00<00:00, 63134.94it/s]\n",
            "100%|██████████| 1574/1574 [00:00<00:00, 61243.78it/s]\n",
            "100%|██████████| 2014/2014 [00:00<00:00, 58591.20it/s]\n",
            "100%|██████████| 1583/1583 [00:00<00:00, 58023.61it/s]\n",
            "100%|██████████| 2632/2632 [00:00<00:00, 56174.48it/s]\n",
            "100%|██████████| 1529/1529 [00:00<00:00, 5944.80it/s]\n",
            "100%|██████████| 2457/2457 [00:00<00:00, 55592.20it/s]\n",
            "100%|██████████| 1751/1751 [00:00<00:00, 51798.70it/s]\n",
            "100%|██████████| 1963/1963 [00:00<00:00, 64884.22it/s]\n",
            "100%|██████████| 1669/1669 [00:00<00:00, 49424.19it/s]\n",
            "100%|██████████| 2886/2886 [00:00<00:00, 66424.64it/s]\n",
            "100%|██████████| 2468/2468 [00:00<00:00, 62503.27it/s]\n",
            "100%|██████████| 1784/1784 [00:00<00:00, 53469.95it/s]\n",
            "100%|██████████| 2184/2184 [00:00<00:00, 55939.42it/s]\n",
            "100%|██████████| 1767/1767 [00:00<00:00, 55626.87it/s]\n",
            "100%|██████████| 2144/2144 [00:00<00:00, 55816.45it/s]\n",
            "100%|██████████| 1930/1930 [00:00<00:00, 60829.50it/s]\n",
            "100%|██████████| 2531/2531 [00:00<00:00, 69636.35it/s]\n",
            "100%|██████████| 3615/3615 [00:00<00:00, 63123.84it/s]\n",
            "100%|██████████| 2441/2441 [00:00<00:00, 8240.38it/s]\n",
            "100%|██████████| 2152/2152 [00:00<00:00, 38939.52it/s]\n",
            "100%|██████████| 1821/1821 [00:00<00:00, 55265.28it/s]\n",
            "100%|██████████| 1885/1885 [00:00<00:00, 35467.30it/s]\n",
            "100%|██████████| 2984/2984 [00:00<00:00, 65658.05it/s]\n",
            "100%|██████████| 2230/2230 [00:00<00:00, 60757.40it/s]\n",
            "100%|██████████| 2631/2631 [00:00<00:00, 65246.55it/s]\n",
            "100%|██████████| 2686/2686 [00:00<00:00, 62795.56it/s]\n",
            "100%|██████████| 1824/1824 [00:00<00:00, 63773.08it/s]\n",
            "100%|██████████| 1669/1669 [00:00<00:00, 55777.45it/s]\n",
            "100%|██████████| 1843/1843 [00:00<00:00, 53947.63it/s]\n",
            "100%|██████████| 2853/2853 [00:00<00:00, 60261.71it/s]\n",
            "100%|██████████| 1840/1840 [00:00<00:00, 57904.56it/s]\n",
            "100%|██████████| 2038/2038 [00:00<00:00, 58935.00it/s]\n",
            "100%|██████████| 1979/1979 [00:00<00:00, 56543.10it/s]\n",
            "100%|██████████| 3577/3577 [00:00<00:00, 12392.34it/s]\n",
            "100%|██████████| 2586/2586 [00:00<00:00, 54010.91it/s]\n",
            "100%|██████████| 1975/1975 [00:00<00:00, 58978.39it/s]\n",
            "100%|██████████| 1854/1854 [00:00<00:00, 63934.09it/s]\n",
            "100%|██████████| 3097/3097 [00:00<00:00, 64624.70it/s]\n",
            "100%|██████████| 1670/1670 [00:00<00:00, 62392.44it/s]\n",
            "100%|██████████| 2175/2175 [00:00<00:00, 57172.11it/s]\n",
            "100%|██████████| 1806/1806 [00:00<00:00, 63110.60it/s]\n",
            "100%|██████████| 1505/1505 [00:00<00:00, 52160.20it/s]\n",
            "100%|██████████| 2461/2461 [00:00<00:00, 60548.47it/s]\n",
            "100%|██████████| 1593/1593 [00:00<00:00, 61922.75it/s]\n",
            "100%|██████████| 1779/1779 [00:00<00:00, 53487.50it/s]\n",
            "100%|██████████| 3531/3531 [00:00<00:00, 62290.33it/s]\n",
            "100%|██████████| 1961/1961 [00:00<00:00, 67563.93it/s]\n",
            "100%|██████████| 1900/1900 [00:00<00:00, 56577.17it/s]\n",
            "100%|██████████| 3257/3257 [00:00<00:00, 7610.66it/s]\n",
            "100%|██████████| 2381/2381 [00:00<00:00, 57234.28it/s]\n",
            "100%|██████████| 2122/2122 [00:00<00:00, 56025.79it/s]\n",
            "100%|██████████| 2131/2131 [00:00<00:00, 59199.91it/s]\n",
            "100%|██████████| 1888/1888 [00:00<00:00, 57434.55it/s]\n",
            "100%|██████████| 1535/1535 [00:00<00:00, 64636.59it/s]\n",
            "100%|██████████| 1655/1655 [00:00<00:00, 50770.70it/s]\n",
            "100%|██████████| 1761/1761 [00:00<00:00, 54855.80it/s]\n",
            "100%|██████████| 1872/1872 [00:00<00:00, 60944.60it/s]\n",
            "100%|██████████| 1680/1680 [00:00<00:00, 55746.20it/s]\n",
            "100%|██████████| 1538/1538 [00:00<00:00, 72506.60it/s]\n",
            "100%|██████████| 2146/2146 [00:00<00:00, 54306.83it/s]\n",
            "100%|██████████| 2460/2460 [00:00<00:00, 62920.31it/s]\n",
            "100%|██████████| 1384/1384 [00:00<00:00, 50518.39it/s]\n",
            "100%|██████████| 1872/1872 [00:00<00:00, 56570.34it/s]\n",
            "100%|██████████| 2149/2149 [00:00<00:00, 8022.59it/s]\n",
            "100%|██████████| 1549/1549 [00:00<00:00, 41246.46it/s]\n",
            "100%|██████████| 1944/1944 [00:00<00:00, 57266.56it/s]\n",
            "100%|██████████| 1628/1628 [00:00<00:00, 63076.32it/s]\n",
            "100%|██████████| 2084/2084 [00:00<00:00, 55129.39it/s]\n",
            "100%|██████████| 1675/1675 [00:00<00:00, 53399.15it/s]\n",
            "100%|██████████| 1792/1792 [00:00<00:00, 52899.64it/s]\n",
            "100%|██████████| 2013/2013 [00:00<00:00, 57582.79it/s]\n",
            "100%|██████████| 2193/2193 [00:00<00:00, 60651.14it/s]\n",
            "100%|██████████| 1573/1573 [00:00<00:00, 56171.16it/s]\n",
            "100%|██████████| 1528/1528 [00:00<00:00, 60873.04it/s]\n",
            "100%|██████████| 1762/1762 [00:00<00:00, 54695.63it/s]\n",
            "100%|██████████| 2556/2556 [00:00<00:00, 62646.18it/s]\n",
            "100%|██████████| 2231/2231 [00:00<00:00, 59060.16it/s]\n",
            "100%|██████████| 2050/2050 [00:00<00:00, 57154.88it/s]\n",
            "100%|██████████| 1739/1739 [00:00<00:00, 52840.14it/s]\n",
            "100%|██████████| 2544/2544 [00:00<00:00, 9189.41it/s]\n",
            "100%|██████████| 1853/1853 [00:00<00:00, 47886.02it/s]\n",
            "100%|██████████| 1599/1599 [00:00<00:00, 51948.79it/s]\n",
            "100%|██████████| 1717/1717 [00:00<00:00, 65979.72it/s]\n",
            "100%|██████████| 2794/2794 [00:00<00:00, 55676.43it/s]\n",
            "100%|██████████| 3228/3228 [00:00<00:00, 60179.10it/s]\n",
            "100%|██████████| 1674/1674 [00:00<00:00, 55451.91it/s]\n",
            "100%|██████████| 2792/2792 [00:00<00:00, 60232.05it/s]\n",
            "100%|██████████| 1537/1537 [00:00<00:00, 45790.71it/s]\n",
            "100%|██████████| 2139/2139 [00:00<00:00, 57441.50it/s]\n",
            "100%|██████████| 2075/2075 [00:00<00:00, 57767.41it/s]\n",
            "100%|██████████| 1774/1774 [00:00<00:00, 54164.18it/s]\n",
            "100%|██████████| 1863/1863 [00:00<00:00, 55265.10it/s]\n",
            "100%|██████████| 1950/1950 [00:00<00:00, 65297.93it/s]\n",
            "100%|██████████| 1790/1790 [00:00<00:00, 70778.93it/s]\n",
            "100%|██████████| 4390/4390 [00:00<00:00, 14654.53it/s]\n",
            "100%|██████████| 1751/1751 [00:00<00:00, 58283.81it/s]\n",
            "100%|██████████| 1513/1513 [00:00<00:00, 52311.68it/s]\n",
            "100%|██████████| 1950/1950 [00:00<00:00, 62115.66it/s]\n",
            "100%|██████████| 2094/2094 [00:00<00:00, 59416.40it/s]\n",
            "100%|██████████| 2176/2176 [00:00<00:00, 60087.07it/s]\n",
            "100%|██████████| 2931/2931 [00:00<00:00, 63496.56it/s]\n",
            "100%|██████████| 1606/1606 [00:00<00:00, 51847.69it/s]\n",
            "100%|██████████| 1672/1672 [00:00<00:00, 52460.57it/s]\n",
            "100%|██████████| 1909/1909 [00:00<00:00, 58003.97it/s]\n",
            "100%|██████████| 2477/2477 [00:00<00:00, 59769.71it/s]\n",
            "100%|██████████| 2001/2001 [00:00<00:00, 58317.37it/s]\n",
            "100%|██████████| 1654/1654 [00:00<00:00, 59408.59it/s]\n",
            "100%|██████████| 3037/3037 [00:00<00:00, 10558.92it/s]\n",
            "100%|██████████| 2153/2153 [00:00<00:00, 55433.49it/s]\n",
            "100%|██████████| 1528/1528 [00:00<00:00, 59154.86it/s]\n",
            "100%|██████████| 2776/2776 [00:00<00:00, 56815.58it/s]\n",
            "100%|██████████| 1379/1379 [00:00<00:00, 58462.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjH-s9ZYGUU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "def register_model(name, model):\n",
        "    models[name] = model"
      ],
      "metadata": {
        "id": "mrjqzbYOc9Q5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjlYz3CYGUW"
      },
      "source": [
        "## Deepmind Atari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EagSZZ1jYGUW"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense\n",
        "\n",
        "def deepmind_atari(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(inputs)\n",
        "    x = Conv2D(64, 4, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    output = Dense(nb_outputs, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output)\n",
        "\n",
        "register_model('deepmind_atari', deepmind_atari)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtTS3OdYGUX"
      },
      "source": [
        "## Modified Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "88KAQJ-jYGUY"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, Rescaling, BatchNormalization, Activation, SeparableConv2D, Dropout, MaxPooling2D, add\n",
        "\n",
        "def modified_xception(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = Rescaling(1.0 / 255)(inputs)\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    \n",
        "    outputs = Dense(nb_outputs, activation='linear')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "register_model('modified_xception', modified_xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFFwJOuYGUe"
      },
      "source": [
        "# Wrappers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcmUv53GYGUf"
      },
      "source": [
        "## Minerl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTI-JMK6YGUf"
      },
      "source": [
        "### Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ANVPcDTdYGUf"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "class ActionManager:\n",
        "    \"\"\"Main minecraft action wrapper. Simplifies action space to 130 discrete actions\"\"\"\n",
        "\n",
        "    def __init__(self, c_action_magnitude=22.5):\n",
        "        self.c_action_magnitude = c_action_magnitude\n",
        "\n",
        "        self.zero_action = OrderedDict([('attack', 0),\n",
        "                                        ('back', 0),\n",
        "                                        ('camera', np.array([0., 0.])),\n",
        "                                        ('forward', 0),\n",
        "                                        ('jump', 0),\n",
        "                                        ('left', 0),\n",
        "                                        ('right', 0),\n",
        "                                        ('sneak', 0),\n",
        "                                        ('sprint', 0)])\n",
        "\n",
        "        # camera discretization:\n",
        "        self.camera_dict = OrderedDict([\n",
        "            ('turn_up', np.array([-c_action_magnitude, 0.])),\n",
        "            ('turn_down', np.array([c_action_magnitude, 0.])),\n",
        "            ('turn_left', np.array([0., -c_action_magnitude])),\n",
        "            ('turn_right', np.array([0., c_action_magnitude]))\n",
        "        ])\n",
        "\n",
        "        self.fully_connected_no_camera = ['attack', 'back', 'forward', 'jump', 'left', 'right', 'sprint']\n",
        "        self.camera_actions = ['turn_up', 'turn_down', 'turn_left', 'turn_right']\n",
        "        self.fully_connected = self.fully_connected_no_camera + self.camera_actions\n",
        "\n",
        "        # following action combinations are excluded:\n",
        "        self.exclude = [('forward', 'back'), ('left', 'right'), ('attack', 'jump'),\n",
        "                        ('turn_up', 'turn_down', 'turn_left', 'turn_right')]\n",
        "\n",
        "        # sprint only allowed when forward is used:\n",
        "        self.only_if = [('sprint', 'forward')]\n",
        "\n",
        "        # Maximal allowed mount of actions within one action:\n",
        "        self.remove_size = 3\n",
        "\n",
        "        # if more than 3 actions are present, actions are removed using this list until only 3 actions remain:\n",
        "        self.remove_first_list = ['sprint', 'left', 'right', 'back',\n",
        "                                  'turn_up', 'turn_down', 'turn_left', 'turn_right',\n",
        "                                  'attack', 'jump', 'forward']\n",
        "\n",
        "        self.fully_connected_list = list(product(range(2), repeat=len(self.fully_connected)))\n",
        "\n",
        "        remove = []\n",
        "        for el in self.fully_connected_list:\n",
        "            for tuple_ in self.exclude:\n",
        "                if sum([el[self.fully_connected.index(a)] for a in tuple_]) > 1:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            for a, b in self.only_if:\n",
        "                if el[self.fully_connected.index(a)] == 1 and el[self.fully_connected.index(b)] == 0:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            if sum(el) > self.remove_size:\n",
        "                if el not in remove:\n",
        "                    remove.append(el)\n",
        "\n",
        "        for r in remove:\n",
        "            self.fully_connected_list.remove(r)\n",
        "\n",
        "        self.action_list = []\n",
        "        for el in self.fully_connected_list:\n",
        "            new_action = copy.deepcopy(self.zero_action)\n",
        "            for key, value in zip(self.fully_connected, el):\n",
        "                if key in self.camera_actions:\n",
        "                    if value:\n",
        "                        new_action['camera'] = self.camera_dict[key]\n",
        "                else:\n",
        "                    new_action[key] = value\n",
        "            self.action_list.append(new_action)\n",
        "\n",
        "        self.num_action_ids_list = [len(self.action_list)]\n",
        "        self.act_continuous_size = 0\n",
        "\n",
        "    def get_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        a['camera'] += np.random.normal(0., 0.5, 2)\n",
        "        return a\n",
        "\n",
        "    def print_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        out = \"\"\n",
        "        for k, v in a.items():\n",
        "            if k != 'camera':\n",
        "                if v != 0:\n",
        "                    out += f'{k} '\n",
        "            else:\n",
        "                if (v != np.zeros(2)).any():\n",
        "                    out += k\n",
        "\n",
        "        print(out)\n",
        "\n",
        "    def get_id(self, action, batch_size):\n",
        "\n",
        "        coiso = np.zeros((batch_size,), dtype=int)\n",
        "        for i in range(batch_size):\n",
        "            action = copy.deepcopy(action)\n",
        "\n",
        "            # discretize 'camera':\n",
        "            camera = action['camera'][i]\n",
        "            camera_action_amount = 0\n",
        "            if - self.c_action_magnitude / 2. < camera[0] < self.c_action_magnitude / 2.:\n",
        "                action['camera'][i][0] = 0.\n",
        "                if - self.c_action_magnitude / 2. < camera[1] < self.c_action_magnitude / 2.:\n",
        "                    action['camera'][i][1] = 0.\n",
        "                else:\n",
        "                    camera_action_amount = 1\n",
        "                    action['camera'][i][1] = self.c_action_magnitude * np.sign(camera[1])\n",
        "            else:\n",
        "                camera_action_amount = 1\n",
        "                action['camera'][i][0] = self.c_action_magnitude * np.sign(camera[0])\n",
        "\n",
        "                action['camera'][i][1] = 0.\n",
        "\n",
        "            # simplify action:\n",
        "            for tuple_ in self.exclude:\n",
        "                if len(tuple_) == 2:\n",
        "                    a, b = tuple_\n",
        "                    if action[a][i] and action[b][i]:\n",
        "                        action[b][i] = 0\n",
        "            for a, b in self.only_if:\n",
        "                if not action[b][i]:\n",
        "                    if action[a][i]:\n",
        "                        action[a][i] = 0\n",
        "            for a in self.remove_first_list:\n",
        "                if sum([action[key][i] for key in self.fully_connected_no_camera]) > \\\n",
        "                        (self.remove_size - camera_action_amount):\n",
        "                    if a in self.camera_actions:\n",
        "                        action['camera'][i] = np.array([0., 0.])\n",
        "                        camera_action_amount = 0\n",
        "                    else:\n",
        "                        action[a][i] = 0\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # set one_hot camera keys:\n",
        "            for key in self.camera_actions:\n",
        "                action[key] = [0 for x in range(batch_size)]\n",
        "            for key, val in self.camera_dict.items():\n",
        "                if (action['camera'][i] == val).all():\n",
        "                    action[key][i] = 1\n",
        "                    break\n",
        "\n",
        "            non_separate_values = tuple(action[key][i] for key in self.fully_connected)\n",
        "\n",
        "            coiso[i] = self.fully_connected_list.index(non_separate_values)\n",
        "        return coiso\n",
        "\n",
        "    def get_left_right_reversed_mapping(self):\n",
        "        action_mapping = []\n",
        "        for action in self.action_list:\n",
        "            reversed_action = copy.deepcopy(action)\n",
        "            if action['left'] == 1:\n",
        "                reversed_action['left'] = 0\n",
        "                reversed_action['right'] = 1\n",
        "                assert action['right'] == 0\n",
        "            if action['right'] == 1:\n",
        "                reversed_action['right'] = 0\n",
        "                reversed_action['left'] = 1\n",
        "                assert action['left'] == 0\n",
        "            if (action['camera'] == [0, -22.5]).all():\n",
        "                reversed_action['camera'][1] = 22.5\n",
        "            if (action['camera'] == [0, 22.5]).all():\n",
        "                reversed_action['camera'][1] = -22.5\n",
        "\n",
        "            rev_action_id = self.get_id(reversed_action)\n",
        "            action_mapping.append(rev_action_id)\n",
        "\n",
        "        return action_mapping\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5tdiaUYGUi"
      },
      "source": [
        "### Baseline Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dNacU-hYGUl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dataset_action_batch_to_actions(dataset_actions, camera_margin=3):\n",
        "    \"\"\"\n",
        "    Turn a batch of actions from dataset (`batch_iter`) to a numpy\n",
        "    array that corresponds to batch of actions of ActionShaping wrapper (_actions).\n",
        "\n",
        "    Camera margin sets the threshold what is considered \"moving camera\".\n",
        "\n",
        "    Note: Hardcoded to work for actions in ActionShaping._actions, with \"intuitive\"\n",
        "        ordering of actions.\n",
        "        If you change ActionShaping._actions, remember to change this!\n",
        "\n",
        "    Array elements are integers corresponding to actions, or \"-1\"\n",
        "    for actions that did not have any corresponding discrete match.\n",
        "    \"\"\"\n",
        "    # There are dummy dimensions of shape one\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    batch_size = len(camera_actions)\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(len(camera_actions)):\n",
        "        # Moving camera is most important (horizontal first)\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 7\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 3\n",
        "            else:\n",
        "                actions[i] = 2\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 1\n",
        "        else:\n",
        "            # No reasonable mapping (would be no-op)\n",
        "            actions[i] = 0\n",
        "    return actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfAkWunYGUZ"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5mwQ__vYGUZ"
      },
      "source": [
        "## Minerl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK9RJ2Q4YGUZ"
      },
      "source": [
        "### Treechop Expert Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my1cNQd1YGUa"
      },
      "outputs": [],
      "source": [
        "import minerl\n",
        "import numpy as np\n",
        "from minerl.data import BufferedBatchIter\n",
        "import tensorflow as tf\n",
        "\n",
        "def train(model):\n",
        "    manager = ActionManager()\n",
        "\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = BufferedBatchIter(data, 32000)\n",
        "\n",
        "    def coiso(batch_size=32, num_epochs=1):\n",
        "        for current_state, action, reward, next_state, done in iterator.buffered_batch_iter(batch_size, num_epochs):\n",
        "            x = current_state[\"pov\"].squeeze().astype(np.float32)\n",
        "            x = x / 255\n",
        "            y = manager.get_id(action, batch_size)\n",
        "            yield (x, y)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer, loss_fn, metrics=[val_acc_metric])\n",
        "\n",
        "    batch_size = 32\n",
        "    num_epochs = 50\n",
        "\n",
        "    model.fit(coiso(batch_size, num_epochs), verbose=1)\n",
        "    model.save_weights('treechop')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH9X5YtIYGUa"
      },
      "source": [
        "### Treechop Expert Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4EWnqKDYGUb"
      },
      "outputs": [],
      "source": [
        "import minerl\n",
        "import numpy as np\n",
        "from minerl.data import BufferedBatchIter\n",
        "import tensorflow as tf\n",
        "\n",
        "def train(model):\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = BufferedBatchIter(data, 32000)\n",
        "\n",
        "    def coiso(batch_size=32, num_epochs=1):\n",
        "        for current_state, action, reward, next_state, done in iterator.buffered_batch_iter(batch_size, num_epochs):\n",
        "            x = current_state[\"pov\"].squeeze().astype(np.float32)\n",
        "            y = dataset_action_batch_to_actions(action)\n",
        "            yield (x, y)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer, loss_fn, metrics=[val_acc_metric])\n",
        "\n",
        "    batch_size = 32\n",
        "    num_epochs = 50\n",
        "\n",
        "    model.fit(coiso(batch_size, num_epochs), verbose=1)\n",
        "    model.save_weights('treechop-fixup')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWBZqHjZYGUb"
      },
      "source": [
        "## DQN Epsilon Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESpX6wnwYGUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import time\n",
        "\n",
        "def train(model, model_target, env):\n",
        "\n",
        "    num_actions = 4\n",
        "\n",
        "    seed = 42\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    epsilon_min = 0.1\n",
        "    epsilon_max = 1.0\n",
        "    epsilon_interval = (\n",
        "        epsilon_max - epsilon_min\n",
        "    )\n",
        "    batch_size = 32\n",
        "    max_steps_per_episode = 10000\n",
        "\n",
        "    env.seed(seed)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "    loss_function = keras.losses.Huber()\n",
        "\n",
        "    action_history = []\n",
        "    state_history = []\n",
        "    state_next_history = []\n",
        "    rewards_history = []\n",
        "    done_history = []\n",
        "    episode_reward_history = []\n",
        "\n",
        "    frame_sample = []\n",
        "\n",
        "    running_reward = 0\n",
        "    episode_count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    epsilon_random_frames = 50000\n",
        "    epsilon_greedy_frames = 10000000\n",
        "\n",
        "    max_memory_length = 100000\n",
        "\n",
        "    update_after_actions = 4\n",
        "    update_target_network = 1000\n",
        "\n",
        "    while True:\n",
        "        state = np.array(env.reset())\n",
        "        episode_reward = 0\n",
        "\n",
        "        start = time.time()\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            end = time.time()\n",
        "            frame_sample.append(end - start)\n",
        "            if len(frame_sample) == 60 * 5:\n",
        "                coiso = np.mean(frame_sample)\n",
        "                print(f'FPS: {1 / coiso}')\n",
        "                frame_sample = []\n",
        "            start = time.time()\n",
        "\n",
        "            #env.render()\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
        "                action = np.random.choice(num_actions)\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "            \n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            state_next, reward, done, _ = env.step(action)\n",
        "            state_next = np.array(state_next)\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            action_history.append(action)\n",
        "            state_history.append(state)\n",
        "            state_next_history.append(state_next)\n",
        "            done_history.append(done)\n",
        "            rewards_history.append(reward)\n",
        "            state = state_next\n",
        "\n",
        "            if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "                \n",
        "                indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "                state_sample = np.array([state_history[i] for i in indices])\n",
        "                state_next_sample = np.array([state_next_history[i] for i in indices])\n",
        "                rewards_sample = np.array([rewards_history[i] for i in indices])\n",
        "                action_sample = np.array([action_history[i] for i in indices])\n",
        "                done_sample = tf.convert_to_tensor(\n",
        "                    [float(done_history[i]) for i in indices]\n",
        "                )\n",
        "\n",
        "                future_rewards = predict_target(model_target, state_next_sample)\n",
        "                updated_q_values = rewards_sample + gamma * tf.reduce_max (\n",
        "                    future_rewards, axis=1\n",
        "                )\n",
        "                updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "                masks = tf.one_hot(action_sample, num_actions)\n",
        "\n",
        "                backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks)\n",
        "\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "                template = 'running reward: {:.2f} at episode {}, frame count {}'\n",
        "                print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "            if len(rewards_history) > max_memory_length:\n",
        "                del rewards_history[:1]\n",
        "                del state_history[:1]\n",
        "                del state_next_history[:1]\n",
        "                del action_history[:1]\n",
        "                del done_history[:1]\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if len(episode_reward_history) > 100:\n",
        "                del episode_reward_history[:1]\n",
        "            running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "            episode_count += 1\n",
        "\n",
        "            if running_reward > 40:\n",
        "                print('Solved at episode {}!'.format(episode_count))\n",
        "                break\n",
        "\n",
        "@tf.function\n",
        "def predict_target(model_target, state_next_sample):\n",
        "    future_rewards = model_target(state_next_sample)\n",
        "    return future_rewards\n",
        "\n",
        "@tf.function\n",
        "def backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state_sample)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "        loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A26gdzdYGUl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dir = '/home/minerl/tfrecords'\n",
        "filenames = os.listdir(dir)\n",
        "filepaths = list(map(lambda x: dir + '/' + x, filenames))"
      ],
      "metadata": {
        "id": "-uGjsbB82m4O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ignore_order = tf.data.Options()\n",
        "ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "dataset = dataset.with_options(\n",
        "    ignore_order\n",
        ")  # uses data as soon as it streams in, rather than in its original order\n",
        "dataset = dataset.map(decode_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#dataset = dataset.batch(32, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "#dataset = dataset.repeat()\n",
        "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n"
      ],
      "metadata": {
        "id": "uD3yvvD82Trn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "MODEL = 'modified_xception'\n",
        "\n",
        "model = models[MODEL]((64, 64, 3), 112)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer, loss_fn, metrics=[val_acc_metric])"
      ],
      "metadata": {
        "id": "J_GyEeck31hx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/weights/treechop')"
      ],
      "metadata": {
        "id": "nGPLAxsatOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, steps_per_epoch=len(filepaths), epochs=10)\n",
        "model.save_weights('/home/weights/treechop')"
      ],
      "metadata": {
        "id": "BzhhDNxs38Mm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}