{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imenatrix/TCC-INFO19/blob/feature-dqfd/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jQ0equmGYKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk"
      ],
      "metadata": {
        "id": "YRB8g4TMYMC_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install minerl"
      ],
      "metadata": {
        "id": "kDkezv40YO5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "-zuJdSSzX9yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from itertools import product\n",
        "from collections import OrderedDict\n",
        "from google.cloud import storage\n",
        "from google.colab import drive\n",
        "\n",
        "import minerl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import *\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "FLc3fue_X9TE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac815e0-925e-4c45-d404-f864af86eef5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()"
      ],
      "metadata": {
        "id": "XJ4KnwlO2VA8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFFwJOuYGUe"
      },
      "source": [
        "# Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrappers = {}\n",
        "\n",
        "def register_wrapper(name, wrapper):\n",
        "    wrappers[name] = wrapper"
      ],
      "metadata": {
        "id": "MVMjGEEkgSl7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTI-JMK6YGUf"
      },
      "source": [
        "## Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ANVPcDTdYGUf"
      },
      "outputs": [],
      "source": [
        "class ActionManager:\n",
        "    \"\"\"Main minecraft action wrapper. Simplifies action space to 130 discrete actions\"\"\"\n",
        "\n",
        "    def __init__(self, c_action_magnitude=22.5):\n",
        "        self.c_action_magnitude = c_action_magnitude\n",
        "\n",
        "        self.zero_action = OrderedDict([('attack', 0),\n",
        "                                        ('back', 0),\n",
        "                                        ('camera', np.array([0., 0.])),\n",
        "                                        ('forward', 0),\n",
        "                                        ('jump', 0),\n",
        "                                        ('left', 0),\n",
        "                                        ('right', 0),\n",
        "                                        ('sneak', 0),\n",
        "                                        ('sprint', 0)])\n",
        "\n",
        "        # camera discretization:\n",
        "        self.camera_dict = OrderedDict([\n",
        "            ('turn_up', np.array([-c_action_magnitude, 0.])),\n",
        "            ('turn_down', np.array([c_action_magnitude, 0.])),\n",
        "            ('turn_left', np.array([0., -c_action_magnitude])),\n",
        "            ('turn_right', np.array([0., c_action_magnitude]))\n",
        "        ])\n",
        "\n",
        "        self.fully_connected_no_camera = ['attack', 'back', 'forward', 'jump', 'left', 'right', 'sprint']\n",
        "        self.camera_actions = ['turn_up', 'turn_down', 'turn_left', 'turn_right']\n",
        "        self.fully_connected = self.fully_connected_no_camera + self.camera_actions\n",
        "\n",
        "        # following action combinations are excluded:\n",
        "        self.exclude = [('forward', 'back'), ('left', 'right'), ('attack', 'jump'),\n",
        "                        ('turn_up', 'turn_down', 'turn_left', 'turn_right')]\n",
        "\n",
        "        # sprint only allowed when forward is used:\n",
        "        self.only_if = [('sprint', 'forward')]\n",
        "\n",
        "        # Maximal allowed mount of actions within one action:\n",
        "        self.remove_size = 3\n",
        "\n",
        "        # if more than 3 actions are present, actions are removed using this list until only 3 actions remain:\n",
        "        self.remove_first_list = ['sprint', 'left', 'right', 'back',\n",
        "                                  'turn_up', 'turn_down', 'turn_left', 'turn_right',\n",
        "                                  'attack', 'jump', 'forward']\n",
        "\n",
        "        self.fully_connected_list = list(product(range(2), repeat=len(self.fully_connected)))\n",
        "\n",
        "        remove = []\n",
        "        for el in self.fully_connected_list:\n",
        "            for tuple_ in self.exclude:\n",
        "                if sum([el[self.fully_connected.index(a)] for a in tuple_]) > 1:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            for a, b in self.only_if:\n",
        "                if el[self.fully_connected.index(a)] == 1 and el[self.fully_connected.index(b)] == 0:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            if sum(el) > self.remove_size:\n",
        "                if el not in remove:\n",
        "                    remove.append(el)\n",
        "\n",
        "        for r in remove:\n",
        "            self.fully_connected_list.remove(r)\n",
        "\n",
        "        self.action_list = []\n",
        "        for el in self.fully_connected_list:\n",
        "            new_action = copy.deepcopy(self.zero_action)\n",
        "            for key, value in zip(self.fully_connected, el):\n",
        "                if key in self.camera_actions:\n",
        "                    if value:\n",
        "                        new_action['camera'] = self.camera_dict[key]\n",
        "                else:\n",
        "                    new_action[key] = value\n",
        "            self.action_list.append(new_action)\n",
        "\n",
        "        self.num_action_ids_list = [len(self.action_list)]\n",
        "        self.act_continuous_size = 0\n",
        "\n",
        "    def get_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        a['camera'] += np.random.normal(0., 0.5, 2)\n",
        "        return a\n",
        "\n",
        "    def print_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        out = \"\"\n",
        "        for k, v in a.items():\n",
        "            if k != 'camera':\n",
        "                if v != 0:\n",
        "                    out += f'{k} '\n",
        "            else:\n",
        "                if (v != np.zeros(2)).any():\n",
        "                    out += k\n",
        "\n",
        "        print(out)\n",
        "\n",
        "    def get_id(self, action, batch_size):\n",
        "\n",
        "        coiso = np.zeros((batch_size,), dtype=int)\n",
        "        action = copy.deepcopy(action)\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            # discretize 'camera':\n",
        "            camera = action['camera'][i]\n",
        "            camera_action_amount = 0\n",
        "            if - self.c_action_magnitude / 2. < camera[0] < self.c_action_magnitude / 2.:\n",
        "                action['camera'][i][0] = 0.\n",
        "                if - self.c_action_magnitude / 2. < camera[1] < self.c_action_magnitude / 2.:\n",
        "                    action['camera'][i][1] = 0.\n",
        "                else:\n",
        "                    camera_action_amount = 1\n",
        "                    action['camera'][i][1] = self.c_action_magnitude * np.sign(camera[1])\n",
        "            else:\n",
        "                camera_action_amount = 1\n",
        "                action['camera'][i][0] = self.c_action_magnitude * np.sign(camera[0])\n",
        "\n",
        "                action['camera'][i][1] = 0.\n",
        "\n",
        "            # simplify action:\n",
        "            for tuple_ in self.exclude:\n",
        "                if len(tuple_) == 2:\n",
        "                    a, b = tuple_\n",
        "                    if action[a][i] and action[b][i]:\n",
        "                        action[b][i] = 0\n",
        "            for a, b in self.only_if:\n",
        "                if not action[b][i]:\n",
        "                    if action[a][i]:\n",
        "                        action[a][i] = 0\n",
        "            for a in self.remove_first_list:\n",
        "                if sum([action[key][i] for key in self.fully_connected_no_camera]) > \\\n",
        "                        (self.remove_size - camera_action_amount):\n",
        "                    if a in self.camera_actions:\n",
        "                        action['camera'][i] = np.array([0., 0.])\n",
        "                        camera_action_amount = 0\n",
        "                    else:\n",
        "                        action[a][i] = 0\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # set one_hot camera keys:\n",
        "            for key in self.camera_actions:\n",
        "                action[key] = [0 for x in range(batch_size)]\n",
        "            for key, val in self.camera_dict.items():\n",
        "                if (action['camera'][i] == val).all():\n",
        "                    action[key][i] = 1\n",
        "                    break\n",
        "\n",
        "            non_separate_values = tuple(action[key][i] for key in self.fully_connected)\n",
        "\n",
        "            coiso[i] = self.fully_connected_list.index(non_separate_values)\n",
        "        return coiso\n",
        "\n",
        "    def get_left_right_reversed_mapping(self):\n",
        "        action_mapping = []\n",
        "        for action in self.action_list:\n",
        "            reversed_action = copy.deepcopy(action)\n",
        "            if action['left'] == 1:\n",
        "                reversed_action['left'] = 0\n",
        "                reversed_action['right'] = 1\n",
        "                assert action['right'] == 0\n",
        "            if action['right'] == 1:\n",
        "                reversed_action['right'] = 0\n",
        "                reversed_action['left'] = 1\n",
        "                assert action['left'] == 0\n",
        "            if (action['camera'] == [0, -22.5]).all():\n",
        "                reversed_action['camera'][1] = 22.5\n",
        "            if (action['camera'] == [0, 22.5]).all():\n",
        "                reversed_action['camera'][1] = -22.5\n",
        "\n",
        "            rev_action_id = self.get_id(reversed_action)\n",
        "            action_mapping.append(rev_action_id)\n",
        "\n",
        "        return action_mapping\n",
        "\n",
        "manager = ActionManager()\n",
        "register_wrapper('amiranas', manager.get_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5tdiaUYGUi"
      },
      "source": [
        "## Baseline Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8dNacU-hYGUl"
      },
      "outputs": [],
      "source": [
        "def dataset_action_batch_to_actions(dataset_actions, batch_size, camera_margin=3):\n",
        "    \"\"\"\n",
        "    Turn a batch of actions from dataset (`batch_iter`) to a numpy\n",
        "    array that corresponds to batch of actions of ActionShaping wrapper (_actions).\n",
        "\n",
        "    Camera margin sets the threshold what is considered \"moving camera\".\n",
        "\n",
        "    Note: Hardcoded to work for actions in ActionShaping._actions, with \"intuitive\"\n",
        "        ordering of actions.\n",
        "        If you change ActionShaping._actions, remember to change this!\n",
        "\n",
        "    Array elements are integers corresponding to actions, or \"-1\"\n",
        "    for actions that did not have any corresponding discrete match.\n",
        "    \"\"\"\n",
        "    # There are dummy dimensions of shape one\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Moving camera is most important (horizontal first)\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 7\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 3\n",
        "            else:\n",
        "                actions[i] = 2\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 1\n",
        "        else:\n",
        "            # No reasonable mapping (would be no-op)\n",
        "            actions[i] = 0\n",
        "    return actions\n",
        "\n",
        "register_wrapper('baseline_notebook', dataset_action_batch_to_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "WhuJkgDYJLmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MINERL_DATA_ROOT=/home/minerl\n",
        "%env GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json"
      ],
      "metadata": {
        "id": "zwnzpW4IYRa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8acdae-547a-418c-9216-17b9f8515653"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MINERL_DATA_ROOT=/home/minerl\n",
            "env: GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m minerl.data.download --environment \"MineRLTreechop-v0\""
      ],
      "metadata": {
        "id": "GrbLl57EYS3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027551fd-90e0-470c-e22a-f601bd1f46db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl.data.download' found in sys.modules after import of package 'minerl.data', but prior to execution of 'minerl.data.download'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "\u001b[32m2022-11-06 02:55:53\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34m__main__[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m Downloading dataset for MineRLTreechop-v0 to /home/minerl\n",
            "\u001b[32m2022-11-06 02:55:53\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34m__main__[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m Starting download ...\n",
            "\u001b[32m2022-11-06 02:55:53\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34mroot[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m File already exists.\n",
            "\u001b[32m2022-11-06 02:55:53\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34mroot[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - downloaded /home/minerl/download/v4/MineRLTreechop-v0.tar\n",
            "\u001b[32m2022-11-06 02:55:53\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34mroot[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m Extracting downloaded files - this may take some time\n",
            "\u001b[32m2022-11-06 02:55:58\u001b[0m \u001b[35m8a014a6c0899\u001b[0m \u001b[34mroot[7718]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - extracted files to /home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "    # The path to your file to upload\n",
        "    # source_file_name = \"local/path/to/file\"\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    \n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n"
      ],
      "metadata": {
        "id": "O-eBZe1Ofo-z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "metadata": {
        "id": "MoCWq5GvJRmV"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom batch iter"
      ],
      "metadata": {
        "id": "YAuJcqFti8zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import minerl\n",
        "import os\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from minerl.data.util import multimap\n",
        "import random\n",
        "\n",
        "MINERL_DATA_ROOT = os.getenv('MINERL_DATA_ROOT')\n",
        "\n",
        "\n",
        "\n",
        "def stack(*args):\n",
        "    return np.stack(args)\n",
        "\n",
        "\n",
        "class BufferedBatchIter:\n",
        "    all_trajectories = None\n",
        "    \"\"\"\n",
        "    A class that maintains and exposes an iterator which loads trajectories into a\n",
        "    configurably-sized buffer, samples batches from that buffer, and refills the buffer\n",
        "    when necessary.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 data_pipeline,\n",
        "                 buffer_target_size=50000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_pipeline: A data pipeline object that you want to construct an iterator from\n",
        "            buffer_target_size: How large you'd like your data buffer to be (in units of timesteps)\n",
        "\n",
        "            Note that this is not an exact cap, since we don't know how large a trajectory will be\n",
        "            until we load it in. This implementation tries to maintain a buffer size by keeping\n",
        "            track of the average size of trajectories in this data pipeline, and loading a new\n",
        "            trajectory when the size of the buffer is more than <average_size> below the target\n",
        "        \"\"\"\n",
        "        self.data_pipeline = data_pipeline\n",
        "        self.data_buffer = []\n",
        "        self.buffer_target_size = buffer_target_size\n",
        "        self.traj_sizes = []\n",
        "        self.avg_traj_size = 0\n",
        "        if BufferedBatchIter.all_trajectories == None:\n",
        "            self.all_trajectories = self.data_pipeline.get_trajectory_names()\n",
        "            BufferedBatchIter.all_trajectories = deepcopy(self.all_trajectories)\n",
        "        else:\n",
        "            self.all_trajectories = BufferedBatchIter.all_trajectories\n",
        "        # available_trajectories is a dynamic, per-epoch list that will keep track of\n",
        "        # which trajectories we haven't yet used in a given epoch\n",
        "        self.available_trajectories = deepcopy(self.all_trajectories)\n",
        "        #random.shuffle(self.available_trajectories)\n",
        "\n",
        "    def optionally_fill_buffer(self):\n",
        "        \"\"\"\n",
        "        This method is run after every batch, but only actually executes a buffer\n",
        "        refill and re-shuffle if more data is needed\n",
        "        \"\"\"\n",
        "        buffer_updated = False\n",
        "\n",
        "        # Add trajectories to the buffer if the remaining space is\n",
        "        # greater than our anticipated trajectory size (in the form of the empirical average)\n",
        "        while (self.buffer_target_size - len(self.data_buffer)) > self.avg_traj_size:\n",
        "            if len(self.available_trajectories) == 0:\n",
        "                return\n",
        "            traj_to_load = self.available_trajectories.pop()\n",
        "            data_loader = self.data_pipeline.load_data(traj_to_load)\n",
        "            traj_len = 0\n",
        "            for data_tuple in data_loader:\n",
        "                traj_len += 1\n",
        "                self.data_buffer.append(data_tuple)\n",
        "\n",
        "            self.traj_sizes.append(traj_len)\n",
        "            self.avg_traj_size = np.mean(self.traj_sizes)\n",
        "            buffer_updated = True\n",
        "        #if buffer_updated:\n",
        "            #random.shuffle(self.data_buffer)\n",
        "\n",
        "    def get_batch(self, batch_size):\n",
        "        \"\"\"A simple utility method for constructing a return batch in the expected format\"\"\"\n",
        "        ret_dict_list = []\n",
        "        for _ in range(batch_size):\n",
        "            data_tuple = self.data_buffer.pop()\n",
        "            ret_dict = dict(obs=data_tuple[0],\n",
        "                            act=data_tuple[1],\n",
        "                            reward=data_tuple[2],\n",
        "                            next_obs=data_tuple[3],\n",
        "                            done=data_tuple[4])\n",
        "            ret_dict_list.append(ret_dict)\n",
        "        return multimap(stack, *ret_dict_list)\n",
        "\n",
        "    def buffered_batch_iter(self, batch_size, num_epochs=None, num_batches=None):\n",
        "        \"\"\"\n",
        "        The actual generator method that returns batches. You can specify either\n",
        "        a desired number of batches, or a desired number of epochs, but not both,\n",
        "        since they might conflict.\n",
        "\n",
        "        ** You must specify one or the other **\n",
        "\n",
        "        Args:\n",
        "            batch_size: The number of transitions/timesteps to be returned in each batch\n",
        "            num_epochs: Optional, how many full passes through all trajectories to return\n",
        "            num_batches: Optional, how many batches to return\n",
        "\n",
        "        \"\"\"\n",
        "        assert num_batches is not None or num_epochs is not None, \"One of num_epochs or \" \\\n",
        "                                                                  \"num_batches must be non-None\"\n",
        "        assert num_batches is None or num_epochs is None, \"You cannot specify both \" \\\n",
        "                                                          \"num_batches and num_epochs\"\n",
        "\n",
        "        epoch_count = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        while True:\n",
        "            # If we've hit the desired number of epochs\n",
        "            if num_epochs is not None and epoch_count >= num_epochs:\n",
        "                return\n",
        "            # If we've hit the desired number of batches\n",
        "            if num_batches is not None and batch_count >= num_batches:\n",
        "                return\n",
        "            # Refill the buffer if we need to\n",
        "            # (doing this before getting batch so it'll run on the first iteration)\n",
        "            self.optionally_fill_buffer()\n",
        "            ret_batch = self.get_batch(batch_size=batch_size)\n",
        "            batch_count += 1\n",
        "            if len(self.data_buffer) < batch_size:\n",
        "                assert len(self.available_trajectories) == 0, \"You've reached the end of your \" \\\n",
        "                                                              \"data buffer while still having \" \\\n",
        "                                                              \"trajectories available; \" \\\n",
        "                                                              \"something seems to have gone wrong\"\n",
        "                epoch_count += 1\n",
        "                self.available_trajectories = deepcopy(self.all_trajectories)\n",
        "                #random.shuffle(self.available_trajectories)\n",
        "\n",
        "            keys = ('obs', 'act', 'reward', 'next_obs', 'done')\n",
        "            yield tuple([ret_batch[key] for key in keys])\n"
      ],
      "metadata": {
        "id": "2PEKJZjpjAO6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Not that"
      ],
      "metadata": {
        "id": "qEfRyzD8jWqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_expert_data(wrapper, examples_per_file, dataset_dir):\n",
        "    wrap = wrappers[wrapper]\n",
        "\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = BufferedBatchIter(data, 30000)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(dataset_dir)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    state_buffer = []\n",
        "    action_buffer = []\n",
        "    reward_buffer = []\n",
        "    state_next_buffer = []\n",
        "    done_buffer = []\n",
        "\n",
        "    gamma = 0.99\n",
        "\n",
        "    filename = f'{i}.tfrecord'\n",
        "    filepath = f'{dataset_dir}/{filename}'\n",
        "    blobpath = f'tfrecords_nstep/{filename}'\n",
        "    writer = tf.io.TFRecordWriter(filepath)\n",
        "\n",
        "    examples = 0\n",
        "\n",
        "    for state, action, reward, state_next, done in iterator.buffered_batch_iter(examples_per_file, num_epochs=1):\n",
        "        state = state['pov'].squeeze().astype(np.float32) / 255\n",
        "        state_next = state_next['pov'].squeeze().astype(np.float32) / 255\n",
        "        action = wrap(action, examples_per_file).squeeze()\n",
        "\n",
        "        for nstep_state, nstep_action, nstep_reward, nstep_state_next, nstep_done in zip(state, action, reward, state_next, done):\n",
        "            state_buffer.append(nstep_state)\n",
        "            action_buffer.append(nstep_action)\n",
        "            reward_buffer.append(nstep_reward)\n",
        "            state_next_buffer.append(nstep_state_next)\n",
        "            done_buffer.append(nstep_done)\n",
        "\n",
        "            if len(reward_buffer) == 10:\n",
        "\n",
        "                nstep_reward_sum = 0\n",
        "                episode_ended = nstep_done\n",
        "                do_while = True\n",
        "\n",
        "                while episode_ended or do_while:\n",
        "                    for j in range(len(reward_buffer)):\n",
        "                        nstep_reward_sum += gamma ** j * reward_buffer[j]\n",
        "\n",
        "                    filename = f'{i}.tfrecord'\n",
        "                    filepath = f'{dataset_dir}/{filename}'\n",
        "                    blobpath = f'tfrecords_nstep/{filename}'\n",
        "\n",
        "                    example = encode_example(\n",
        "                        state_buffer[0],\n",
        "                        action_buffer[0],\n",
        "                        reward_buffer[0],\n",
        "                        state_next_buffer[0],\n",
        "                        done_buffer[0],\n",
        "                        nstep_state,\n",
        "                        nstep_action,\n",
        "                        nstep_reward,\n",
        "                        nstep_state_next,\n",
        "                        episode_ended\n",
        "                    )\n",
        "                    writer.write(example.SerializeToString())\n",
        "                    examples += 1\n",
        "\n",
        "                    if examples == examples_per_file:\n",
        "\n",
        "                        writer.close()\n",
        "\n",
        "                        upload_blob('minerl_data_records', filepath, blobpath)\n",
        "                        os.remove(filepath)\n",
        "\n",
        "                        examples = 0\n",
        "\n",
        "                        i += 1\n",
        "                        filename = f'{i}.tfrecord'\n",
        "                        filepath = f'{dataset_dir}/{filename}'\n",
        "                        blobpath = f'tfrecords_nstep/{filename}'\n",
        "                        writer = tf.io.TFRecordWriter(filepath)\n",
        "\n",
        "                    if done_buffer[0]:\n",
        "                        episode_ended = False\n",
        "\n",
        "                    state_buffer = state_buffer[1:]\n",
        "                    action_buffer = action_buffer[1:]\n",
        "                    reward_buffer = reward_buffer[1:]\n",
        "                    state_next_buffer = state_next_buffer[1:]\n",
        "                    done_buffer = done_buffer[1:]\n",
        "\n",
        "                    do_while = False\n"
      ],
      "metadata": {
        "id": "bFqbXyB8M6jh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listdir(dir):\n",
        "    return list(map(\n",
        "        lambda file: dir + '/' + file,\n",
        "        os.listdir(dir)\n",
        "    ))"
      ],
      "metadata": {
        "id": "ROT5pG0rSL9M"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            # .repeat()\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )\n",
        "\n",
        "def create_val_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )"
      ],
      "metadata": {
        "id": "Kv80oX7LSMgQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_example(state, action, reward, state_next, done, nstep_state, nstep_action, nstep_reward_sum, nstep_state_next, nstep_done):\n",
        "  feature = {\n",
        "      'state' : bytes_feature(tf.io.serialize_tensor(state)),\n",
        "      'action' : int64_feature(action),\n",
        "      'reward' : float_feature(reward),\n",
        "      'state_next' : bytes_feature(tf.io.serialize_tensor(state_next)),\n",
        "      'done' : int64_feature(done),\n",
        "      'nstep_state' : bytes_feature(tf.io.serialize_tensor(nstep_state)),\n",
        "      'nstep_action' : int64_feature(nstep_action),\n",
        "      'nstep_reward_sum' : float_feature(nstep_reward_sum),\n",
        "      'nstep_state_next' : bytes_feature(tf.io.serialize_tensor(nstep_state_next)),\n",
        "      'nstep_done' : int64_feature(nstep_done)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def decode_example(example):\n",
        "  feature_description = {\n",
        "    'state': tf.io.FixedLenFeature([], tf.string),\n",
        "    'action': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'reward' : tf.io.FixedLenFeature([], tf.float32),\n",
        "    'state_next' : tf.io.FixedLenFeature([], tf.string),\n",
        "    'done' : tf.io.FixedLenFeature([], tf.int64),\n",
        "    'nstep_state': tf.io.FixedLenFeature([], tf.string),\n",
        "    'nstep_action': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'nstep_reward_sum' : tf.io.FixedLenFeature([], tf.float32),\n",
        "    'nstep_state_next' : tf.io.FixedLenFeature([], tf.string),\n",
        "    'nstep_done' : tf.io.FixedLenFeature([], tf.int64)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "  state = tf.io.parse_tensor(example['state'], out_type=tf.float32)\n",
        "  state = tf.reshape(state, (64, 64, 3))\n",
        "\n",
        "  state_next = tf.io.parse_tensor(example['state_next'], out_type=tf.float32)\n",
        "  state_next = tf.reshape(state_next, (64, 64, 3))\n",
        "\n",
        "  nstep_state = tf.io.parse_tensor(example['nstep_state'], out_type=tf.float32)\n",
        "  nstep_state = tf.reshape(nstep_state, (64, 64, 3))\n",
        "\n",
        "  nstep_state_next = tf.io.parse_tensor(example['nstep_state_next'], out_type=tf.float32)\n",
        "  nstep_state_next = tf.reshape(nstep_state_next, (64, 64, 3))\n",
        "\n",
        "  return state, example['action'], example['reward'], state_next, example['done'], nstep_state, example['nstep_action'], example['nstep_reward_sum'], nstep_state_next, example['nstep_done']"
      ],
      "metadata": {
        "id": "jRKdNnHjRBjU"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfAkWunYGUZ"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loop"
      ],
      "metadata": {
        "id": "A2piAVS4fTFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from collections import namedtuple\n",
        "\n",
        "def val_step(model, loss_fn, state, target_q_values, updated_q_values, masks):\n",
        "    q_values = model(state)\n",
        "    q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "    lmc_loss = tf.reduce_mean(\n",
        "        tf.reduce_max(\n",
        "            tf.cast(\n",
        "                tf.equal(\n",
        "                    masks,\n",
        "                    0\n",
        "                ),\n",
        "                tf.float32\n",
        "            ) + target_q_values,\n",
        "            axis=1\n",
        "        ) - tf.reduce_sum(masks * target_q_values, axis=1)\n",
        "    )\n",
        "\n",
        "    loss = loss_fn(updated_q_values, q_action) + lmc_loss + sum(model.losses)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_step(model, loss_fn, optmizer, state, target_q_values, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "\n",
        "        lmc_loss = tf.reduce_mean(\n",
        "            tf.reduce_max(\n",
        "                tf.cast(\n",
        "                    tf.equal(\n",
        "                        masks,\n",
        "                        0\n",
        "                    ),\n",
        "                    tf.float32\n",
        "                ) + target_q_values,\n",
        "                axis=1\n",
        "            ) - tf.reduce_sum(masks * target_q_values, axis=1)\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(updated_q_values, q_action) + lmc_loss + sum(model.losses)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def fit(model, model_target, loss_fn, optimizer, dataset, val_dataset, epochs, steps, val_steps):\n",
        "\n",
        "    gamma = 0.99\n",
        "\n",
        "    History = namedtuple('History', 'history')\n",
        "    history = History(history={\n",
        "        'loss': [],\n",
        "        'val_loss': []\n",
        "    })\n",
        "\n",
        "    frame = 0\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        for step, (state, action, reward, state_next, done, nstep_state, nstep_action, nstep_reward_sum, nstep_state_next, nstep_done) in tqdm(enumerate(dataset), total=steps):\n",
        "            target_q_values = model_target(state)\n",
        "            future_rewards = model_target(state_next)\n",
        "\n",
        "            updated_q_values = reward + gamma * tf.reduce_max (\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "            updated_q_values = updated_q_values * tf.cast(1 - done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "            masks = tf.one_hot(action, 112)\n",
        "\n",
        "            train_loss += train_step(model, loss_fn, optimizer, state, target_q_values, updated_q_values, masks)\n",
        "\n",
        "            frame += 1\n",
        "            if frame % 1000 == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "\n",
        "        for step, (state, action, reward, state_next, done, nstep_state, nstep_action, nstep_reward_sum, nstep_state_next, nstep_done) in enumerate(val_dataset):\n",
        "            target_q_values = model_target(state)\n",
        "            future_rewards = model_target(state_next)\n",
        "\n",
        "            updated_q_values = reward + gamma * tf.reduce_max (\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "            updated_q_values = updated_q_values * tf.cast(1 - done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "            masks = tf.one_hot(action, 112)\n",
        "\n",
        "            val_loss += val_step(model, loss_fn, state, target_q_values, updated_q_values, masks)\n",
        "\n",
        "        history.history['loss'].append(train_loss / steps)\n",
        "        history.history['val_loss'].append(val_loss / val_steps)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "fxsyDC1tfWiH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWBZqHjZYGUb"
      },
      "source": [
        "## DQN Epsilon Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ESpX6wnwYGUc"
      },
      "outputs": [],
      "source": [
        "def train(model, model_target, env):\n",
        "\n",
        "    num_actions = 4\n",
        "\n",
        "    seed = 42\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    epsilon_min = 0.1\n",
        "    epsilon_max = 1.0\n",
        "    epsilon_interval = (\n",
        "        epsilon_max - epsilon_min\n",
        "    )\n",
        "    batch_size = 32\n",
        "    max_steps_per_episode = 10000\n",
        "\n",
        "    env.seed(seed)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "    loss_function = keras.losses.Huber()\n",
        "\n",
        "    action_history = []\n",
        "    state_history = []\n",
        "    state_next_history = []\n",
        "    rewards_history = []\n",
        "    done_history = []\n",
        "    episode_reward_history = []\n",
        "\n",
        "    frame_sample = []\n",
        "\n",
        "    running_reward = 0\n",
        "    episode_count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    epsilon_random_frames = 50000\n",
        "    epsilon_greedy_frames = 10000000\n",
        "\n",
        "    max_memory_length = 100000\n",
        "\n",
        "    update_after_actions = 4\n",
        "    update_target_network = 1000\n",
        "\n",
        "    while True:\n",
        "        state = np.array(env.reset())\n",
        "        episode_reward = 0\n",
        "\n",
        "        start = time.time()\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            end = time.time()\n",
        "            frame_sample.append(end - start)\n",
        "            if len(frame_sample) == 60 * 5:\n",
        "                coiso = np.mean(frame_sample)\n",
        "                print(f'FPS: {1 / coiso}')\n",
        "                frame_sample = []\n",
        "            start = time.time()\n",
        "\n",
        "            #env.render()\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
        "                action = np.random.choice(num_actions)\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "            \n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            state_next, reward, done, _ = env.step(action)\n",
        "            state_next = np.array(state_next)\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            action_history.append(action)\n",
        "            state_history.append(state)\n",
        "            state_next_history.append(state_next)\n",
        "            done_history.append(done)\n",
        "            rewards_history.append(reward)\n",
        "            state = state_next\n",
        "\n",
        "            if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "                \n",
        "                indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "                state_sample = np.array([state_history[i] for i in indices])\n",
        "                state_next_sample = np.array([state_next_history[i] for i in indices])\n",
        "                rewards_sample = np.array([rewards_history[i] for i in indices])\n",
        "                action_sample = np.array([action_history[i] for i in indices])\n",
        "                done_sample = tf.convert_to_tensor(\n",
        "                    [float(done_history[i]) for i in indices]\n",
        "                )\n",
        "\n",
        "                future_rewards = predict_target(model_target, state_next_sample)\n",
        "                updated_q_values = rewards_sample + gamma * tf.reduce_max (\n",
        "                    future_rewards, axis=1\n",
        "                )\n",
        "                updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "                masks = tf.one_hot(action_sample, num_actions)\n",
        "\n",
        "                backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks)\n",
        "\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "                template = 'running reward: {:.2f} at episode {}, frame count {}'\n",
        "                print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "            if len(rewards_history) > max_memory_length:\n",
        "                del rewards_history[:1]\n",
        "                del state_history[:1]\n",
        "                del state_next_history[:1]\n",
        "                del action_history[:1]\n",
        "                del done_history[:1]\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if len(episode_reward_history) > 100:\n",
        "                del episode_reward_history[:1]\n",
        "            running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "            episode_count += 1\n",
        "\n",
        "            if running_reward > 40:\n",
        "                print('Solved at episode {}!'.format(episode_count))\n",
        "                break\n",
        "\n",
        "@tf.function\n",
        "def predict_target(model_target, state_next_sample):\n",
        "    future_rewards = model_target(state_next_sample)\n",
        "    return future_rewards\n",
        "\n",
        "@tf.function\n",
        "def backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state_sample)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "        loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjH-s9ZYGUU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "def register_model(name, model):\n",
        "    models[name] = model"
      ],
      "metadata": {
        "id": "mrjqzbYOc9Q5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjlYz3CYGUW"
      },
      "source": [
        "## Deepmind Atari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "EagSZZ1jYGUW"
      },
      "outputs": [],
      "source": [
        "def deepmind_atari(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(32, 8, strides=4, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(inputs)\n",
        "    x = Conv2D(64, 4, strides=4, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(512, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    output = Dense(nb_outputs, activation='linear', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output)\n",
        "\n",
        "register_model('deepmind_atari', deepmind_atari)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtTS3OdYGUX"
      },
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "88KAQJ-jYGUY"
      },
      "outputs": [],
      "source": [
        "def xception(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = Rescaling(1.0 / 255)(inputs)\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    outputs = Dense(nb_outputs, activation='linear')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "register_model('xception', xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A26gdzdYGUl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WRAPPER = 'amiranas'\n",
        "MODEL = 'deepmind_atari'\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "EXAMPLES_PER_FILE = 2048\n",
        "\n",
        "CHECKPOINT = '/content/drive/MyDrive/weights/checkpoint'\n",
        "DATASET_DIR = '/home/minerl/tfrecords'"
      ],
      "metadata": {
        "id": "1rIDGfeUOyxV"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYOyClORkVBM",
        "outputId": "bceafe59-f281-4a3a-96b9-91ea78400aed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_expert_data(WRAPPER, EXAMPLES_PER_FILE, DATASET_DIR)"
      ],
      "metadata": {
        "id": "dMeoVc0POveU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_pattern = 'gs://minerl_data_records/tfrecords_nstep/*.tfrecord'\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "validation_split = 0.1\n",
        "split = len(filenames) - int(len(filenames) * validation_split)\n",
        "train_fns = filenames[:split]\n",
        "validation_fns = filenames[split:]\n",
        "\n",
        "dataset = create_dataset(train_fns, BATCH_SIZE)\n",
        "val_dataset = create_val_dataset(validation_fns, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "M8x0I3mCQ1mc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = models[MODEL]((64, 64, 3), 112)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer, loss_fn, metrics=[val_acc_metric])"
      ],
      "metadata": {
        "id": "J_GyEeck31hx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[MODEL]((64, 64, 3), 112)\n",
        "model_target = models[MODEL]((64, 64, 3), 112)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "loss_fn = keras.losses.Huber()"
      ],
      "metadata": {
        "id": "qA2UkaYWgcTQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(CHECKPOINT)"
      ],
      "metadata": {
        "id": "nGPLAxsatOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT, save_weights_only=True, save_best_only=True)"
      ],
      "metadata": {
        "id": "1rNJwmVVjOIx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for state, action, reward, state_next, done, nstep_state, nstep_action, nstep_reward_sum, nstep_state_next, nstep_done in dataset:\n",
        "    print(action)"
      ],
      "metadata": {
        "id": "yrDVCpAusClM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "76eda5cd-9f59-4d6d-dff6-13fcb2712aeb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  0 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82\n",
            " 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82 82\n",
            " 82 82 82 82 82 82 82 82  0  0  0  4  4  4  0  0], shape=(64,), dtype=int64)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4508e0c1f213>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_reward_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_state_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_done\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3012\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3013\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "validation_steps = len(validation_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "\n",
        "history = fit(model, model_target, loss_fn, optimizer, dataset, val_dataset, EPOCHS, steps_per_epoch, validation_steps)"
      ],
      "metadata": {
        "id": "UtyBsx4igJmG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "bac2b31cc730473492819588fad683cf",
            "2435dcd40b324055a9cb38e68eff0f88",
            "7c19d43e8e9944b4b8f9b10a1f9b39de",
            "4e2377b6341043f0a209b5bf4310738e",
            "18a21c5b2a194fc19d2842c61d4fb093",
            "e558633c1c034664b5ed0578e7a9dde0",
            "1161a3a18dab4e07a514c5782723175e",
            "4df8a0ea932a4375826deaf437204a7c",
            "05656c9818124e9682d768222504ec24",
            "dc129d01589f4eb389abe358a01fbb85",
            "d6080bc36b614df3be25cc0170aa287f",
            "3567756e359e478db757192ff176725e",
            "054e9d777c73443dbd5953b3187e75ba",
            "3c92307898c44668a17888d8088db259",
            "ffc15ba524f448b8995fe5a9fc1d29cb",
            "3c2698fe3ddd4bb5abfbf4779c92e76a",
            "a78de3d18241480589b5073ca5f64eaa",
            "7c8a2b6cee1948b5b3090cf2c97b8b64",
            "a108d32ea2bb43e09f0375e854b700e0",
            "91d97df66dee42429855444a554b2a03",
            "4a9ade89b83540f5b5ca4ee74801d8bb",
            "3f5fd85801784af4a4641d7530b771da"
          ]
        },
        "outputId": "04dd34f4-fb7e-49b1-8493-450c1a79f982"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bac2b31cc730473492819588fad683cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/6304.0 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3567756e359e478db757192ff176725e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-47b792507ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_fns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEXAMPLES_PER_FILE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-ada89dbf416d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, model_target, loss_fn, optimizer, dataset, val_dataset, epochs, steps, val_steps)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_reward_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_state_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnstep_done\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mtarget_q_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mfuture_rewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    764\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m           output_shapes=self._flat_output_shapes)\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3012\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   3013\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m         \"output_shapes\", output_shapes)\n\u001b[0m\u001b[1;32m   3015\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for state, action, reward, state_next, done in dataset.skip(50).take(20):\n",
        "    print(tf.argmax(model(state), axis=1))"
      ],
      "metadata": {
        "id": "2ySanku1eM3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for state, action, reward, state_next, done in dataset.take(20):\n",
        "    print(tf.cast(model(state)[0] * 100000, tf.int64))"
      ],
      "metadata": {
        "id": "0f_Tx8Y2gCM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "validation_steps = len(validation_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "\n",
        "history = model.fit(dataset, validation_data=val_dataset, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, epochs=EPOCHS, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "BzhhDNxs38Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manager = ActionManager()\n",
        "manager.get_action(0)"
      ],
      "metadata": {
        "id": "Mjrqtdb_ftcI",
        "outputId": "982f81e3-1841-49cc-be31-f3f8bfa34059",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('attack', 0),\n",
              "             ('back', 0),\n",
              "             ('camera', array([-0.60680673, -0.17630435])),\n",
              "             ('forward', 0),\n",
              "             ('jump', 0),\n",
              "             ('left', 0),\n",
              "             ('right', 0),\n",
              "             ('sneak', 0),\n",
              "             ('sprint', 0)])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "#display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ],
      "metadata": {
        "id": "mgSV7L5yBDPE",
        "outputId": "1c58a6c5-f81e-424a-81f8-1f1e43badfaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jQ0equmGYKbt",
        "-zuJdSSzX9yZ",
        "CtFFwJOuYGUe",
        "YAuJcqFti8zz",
        "gDfAkWunYGUZ",
        "A2piAVS4fTFo",
        "zWBZqHjZYGUb",
        "cGjH-s9ZYGUU",
        "cTjlYz3CYGUW",
        "FrtTS3OdYGUX"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bac2b31cc730473492819588fad683cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2435dcd40b324055a9cb38e68eff0f88",
              "IPY_MODEL_7c19d43e8e9944b4b8f9b10a1f9b39de",
              "IPY_MODEL_4e2377b6341043f0a209b5bf4310738e"
            ],
            "layout": "IPY_MODEL_18a21c5b2a194fc19d2842c61d4fb093"
          }
        },
        "2435dcd40b324055a9cb38e68eff0f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e558633c1c034664b5ed0578e7a9dde0",
            "placeholder": "",
            "style": "IPY_MODEL_1161a3a18dab4e07a514c5782723175e",
            "value": "  0%"
          }
        },
        "7c19d43e8e9944b4b8f9b10a1f9b39de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4df8a0ea932a4375826deaf437204a7c",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05656c9818124e9682d768222504ec24",
            "value": 0
          }
        },
        "4e2377b6341043f0a209b5bf4310738e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc129d01589f4eb389abe358a01fbb85",
            "placeholder": "",
            "style": "IPY_MODEL_d6080bc36b614df3be25cc0170aa287f",
            "value": " 0/30 [00:39&lt;?, ?it/s]"
          }
        },
        "18a21c5b2a194fc19d2842c61d4fb093": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e558633c1c034664b5ed0578e7a9dde0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1161a3a18dab4e07a514c5782723175e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4df8a0ea932a4375826deaf437204a7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05656c9818124e9682d768222504ec24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc129d01589f4eb389abe358a01fbb85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6080bc36b614df3be25cc0170aa287f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3567756e359e478db757192ff176725e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_054e9d777c73443dbd5953b3187e75ba",
              "IPY_MODEL_3c92307898c44668a17888d8088db259",
              "IPY_MODEL_ffc15ba524f448b8995fe5a9fc1d29cb"
            ],
            "layout": "IPY_MODEL_3c2698fe3ddd4bb5abfbf4779c92e76a"
          }
        },
        "054e9d777c73443dbd5953b3187e75ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a78de3d18241480589b5073ca5f64eaa",
            "placeholder": "",
            "style": "IPY_MODEL_7c8a2b6cee1948b5b3090cf2c97b8b64",
            "value": "  0%"
          }
        },
        "3c92307898c44668a17888d8088db259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a108d32ea2bb43e09f0375e854b700e0",
            "max": 6304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91d97df66dee42429855444a554b2a03",
            "value": 11
          }
        },
        "ffc15ba524f448b8995fe5a9fc1d29cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9ade89b83540f5b5ca4ee74801d8bb",
            "placeholder": "",
            "style": "IPY_MODEL_3f5fd85801784af4a4641d7530b771da",
            "value": " 11/6304.0 [00:39&lt;5:38:16,  3.23s/it]"
          }
        },
        "3c2698fe3ddd4bb5abfbf4779c92e76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78de3d18241480589b5073ca5f64eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c8a2b6cee1948b5b3090cf2c97b8b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a108d32ea2bb43e09f0375e854b700e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d97df66dee42429855444a554b2a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a9ade89b83540f5b5ca4ee74801d8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f5fd85801784af4a4641d7530b771da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}