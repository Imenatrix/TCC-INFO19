{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imenatrix/TCC-INFO19/blob/feature-parametrization/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jQ0equmGYKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk"
      ],
      "metadata": {
        "id": "YRB8g4TMYMC_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install minerl"
      ],
      "metadata": {
        "id": "kDkezv40YO5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFFwJOuYGUe"
      },
      "source": [
        "# Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrappers = {}\n",
        "\n",
        "def register_wrapper(name, wrapper):\n",
        "    wrappers[name] = wrapper"
      ],
      "metadata": {
        "id": "MVMjGEEkgSl7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTI-JMK6YGUf"
      },
      "source": [
        "## Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ANVPcDTdYGUf"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "from itertools import product\n",
        "\n",
        "\n",
        "class ActionManager:\n",
        "    \"\"\"Main minecraft action wrapper. Simplifies action space to 130 discrete actions\"\"\"\n",
        "\n",
        "    def __init__(self, c_action_magnitude=22.5):\n",
        "        self.c_action_magnitude = c_action_magnitude\n",
        "\n",
        "        self.zero_action = OrderedDict([('attack', 0),\n",
        "                                        ('back', 0),\n",
        "                                        ('camera', np.array([0., 0.])),\n",
        "                                        ('forward', 0),\n",
        "                                        ('jump', 0),\n",
        "                                        ('left', 0),\n",
        "                                        ('right', 0),\n",
        "                                        ('sneak', 0),\n",
        "                                        ('sprint', 0)])\n",
        "\n",
        "        # camera discretization:\n",
        "        self.camera_dict = OrderedDict([\n",
        "            ('turn_up', np.array([-c_action_magnitude, 0.])),\n",
        "            ('turn_down', np.array([c_action_magnitude, 0.])),\n",
        "            ('turn_left', np.array([0., -c_action_magnitude])),\n",
        "            ('turn_right', np.array([0., c_action_magnitude]))\n",
        "        ])\n",
        "\n",
        "        self.fully_connected_no_camera = ['attack', 'back', 'forward', 'jump', 'left', 'right', 'sprint']\n",
        "        self.camera_actions = ['turn_up', 'turn_down', 'turn_left', 'turn_right']\n",
        "        self.fully_connected = self.fully_connected_no_camera + self.camera_actions\n",
        "\n",
        "        # following action combinations are excluded:\n",
        "        self.exclude = [('forward', 'back'), ('left', 'right'), ('attack', 'jump'),\n",
        "                        ('turn_up', 'turn_down', 'turn_left', 'turn_right')]\n",
        "\n",
        "        # sprint only allowed when forward is used:\n",
        "        self.only_if = [('sprint', 'forward')]\n",
        "\n",
        "        # Maximal allowed mount of actions within one action:\n",
        "        self.remove_size = 3\n",
        "\n",
        "        # if more than 3 actions are present, actions are removed using this list until only 3 actions remain:\n",
        "        self.remove_first_list = ['sprint', 'left', 'right', 'back',\n",
        "                                  'turn_up', 'turn_down', 'turn_left', 'turn_right',\n",
        "                                  'attack', 'jump', 'forward']\n",
        "\n",
        "        self.fully_connected_list = list(product(range(2), repeat=len(self.fully_connected)))\n",
        "\n",
        "        remove = []\n",
        "        for el in self.fully_connected_list:\n",
        "            for tuple_ in self.exclude:\n",
        "                if sum([el[self.fully_connected.index(a)] for a in tuple_]) > 1:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            for a, b in self.only_if:\n",
        "                if el[self.fully_connected.index(a)] == 1 and el[self.fully_connected.index(b)] == 0:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            if sum(el) > self.remove_size:\n",
        "                if el not in remove:\n",
        "                    remove.append(el)\n",
        "\n",
        "        for r in remove:\n",
        "            self.fully_connected_list.remove(r)\n",
        "\n",
        "        self.action_list = []\n",
        "        for el in self.fully_connected_list:\n",
        "            new_action = copy.deepcopy(self.zero_action)\n",
        "            for key, value in zip(self.fully_connected, el):\n",
        "                if key in self.camera_actions:\n",
        "                    if value:\n",
        "                        new_action['camera'] = self.camera_dict[key]\n",
        "                else:\n",
        "                    new_action[key] = value\n",
        "            self.action_list.append(new_action)\n",
        "\n",
        "        self.num_action_ids_list = [len(self.action_list)]\n",
        "        self.act_continuous_size = 0\n",
        "\n",
        "    def get_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        a['camera'] += np.random.normal(0., 0.5, 2)\n",
        "        return a\n",
        "\n",
        "    def print_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        out = \"\"\n",
        "        for k, v in a.items():\n",
        "            if k != 'camera':\n",
        "                if v != 0:\n",
        "                    out += f'{k} '\n",
        "            else:\n",
        "                if (v != np.zeros(2)).any():\n",
        "                    out += k\n",
        "\n",
        "        print(out)\n",
        "\n",
        "    def get_id(self, action, batch_size):\n",
        "\n",
        "        coiso = np.zeros((batch_size,), dtype=int)\n",
        "        for i in range(batch_size):\n",
        "            action = copy.deepcopy(action)\n",
        "\n",
        "            # discretize 'camera':\n",
        "            camera = action['camera'][i]\n",
        "            camera_action_amount = 0\n",
        "            if - self.c_action_magnitude / 2. < camera[0] < self.c_action_magnitude / 2.:\n",
        "                action['camera'][i][0] = 0.\n",
        "                if - self.c_action_magnitude / 2. < camera[1] < self.c_action_magnitude / 2.:\n",
        "                    action['camera'][i][1] = 0.\n",
        "                else:\n",
        "                    camera_action_amount = 1\n",
        "                    action['camera'][i][1] = self.c_action_magnitude * np.sign(camera[1])\n",
        "            else:\n",
        "                camera_action_amount = 1\n",
        "                action['camera'][i][0] = self.c_action_magnitude * np.sign(camera[0])\n",
        "\n",
        "                action['camera'][i][1] = 0.\n",
        "\n",
        "            # simplify action:\n",
        "            for tuple_ in self.exclude:\n",
        "                if len(tuple_) == 2:\n",
        "                    a, b = tuple_\n",
        "                    if action[a][i] and action[b][i]:\n",
        "                        action[b][i] = 0\n",
        "            for a, b in self.only_if:\n",
        "                if not action[b][i]:\n",
        "                    if action[a][i]:\n",
        "                        action[a][i] = 0\n",
        "            for a in self.remove_first_list:\n",
        "                if sum([action[key][i] for key in self.fully_connected_no_camera]) > \\\n",
        "                        (self.remove_size - camera_action_amount):\n",
        "                    if a in self.camera_actions:\n",
        "                        action['camera'][i] = np.array([0., 0.])\n",
        "                        camera_action_amount = 0\n",
        "                    else:\n",
        "                        action[a][i] = 0\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # set one_hot camera keys:\n",
        "            for key in self.camera_actions:\n",
        "                action[key] = [0 for x in range(batch_size)]\n",
        "            for key, val in self.camera_dict.items():\n",
        "                if (action['camera'][i] == val).all():\n",
        "                    action[key][i] = 1\n",
        "                    break\n",
        "\n",
        "            non_separate_values = tuple(action[key][i] for key in self.fully_connected)\n",
        "\n",
        "            coiso[i] = self.fully_connected_list.index(non_separate_values)\n",
        "        return coiso\n",
        "\n",
        "    def get_left_right_reversed_mapping(self):\n",
        "        action_mapping = []\n",
        "        for action in self.action_list:\n",
        "            reversed_action = copy.deepcopy(action)\n",
        "            if action['left'] == 1:\n",
        "                reversed_action['left'] = 0\n",
        "                reversed_action['right'] = 1\n",
        "                assert action['right'] == 0\n",
        "            if action['right'] == 1:\n",
        "                reversed_action['right'] = 0\n",
        "                reversed_action['left'] = 1\n",
        "                assert action['left'] == 0\n",
        "            if (action['camera'] == [0, -22.5]).all():\n",
        "                reversed_action['camera'][1] = 22.5\n",
        "            if (action['camera'] == [0, 22.5]).all():\n",
        "                reversed_action['camera'][1] = -22.5\n",
        "\n",
        "            rev_action_id = self.get_id(reversed_action)\n",
        "            action_mapping.append(rev_action_id)\n",
        "\n",
        "        return action_mapping\n",
        "\n",
        "manager = ActionManager()\n",
        "register_wrapper('amiranas', manager.get_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5tdiaUYGUi"
      },
      "source": [
        "## Baseline Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "8dNacU-hYGUl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dataset_action_batch_to_actions(dataset_actions, batch_size, camera_margin=3):\n",
        "    \"\"\"\n",
        "    Turn a batch of actions from dataset (`batch_iter`) to a numpy\n",
        "    array that corresponds to batch of actions of ActionShaping wrapper (_actions).\n",
        "\n",
        "    Camera margin sets the threshold what is considered \"moving camera\".\n",
        "\n",
        "    Note: Hardcoded to work for actions in ActionShaping._actions, with \"intuitive\"\n",
        "        ordering of actions.\n",
        "        If you change ActionShaping._actions, remember to change this!\n",
        "\n",
        "    Array elements are integers corresponding to actions, or \"-1\"\n",
        "    for actions that did not have any corresponding discrete match.\n",
        "    \"\"\"\n",
        "    # There are dummy dimensions of shape one\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Moving camera is most important (horizontal first)\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 7\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 3\n",
        "            else:\n",
        "                actions[i] = 2\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 1\n",
        "        else:\n",
        "            # No reasonable mapping (would be no-op)\n",
        "            actions[i] = 0\n",
        "    return actions\n",
        "\n",
        "register_wrapper('baseline_notebook', dataset_action_batch_to_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "WhuJkgDYJLmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MINERL_DATA_ROOT=/home/minerl"
      ],
      "metadata": {
        "id": "zwnzpW4IYRa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29864f63-624c-4cf0-c263-7437d32b9056"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MINERL_DATA_ROOT=/home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m minerl.data.download --environment \"MineRLTreechop-v0\""
      ],
      "metadata": {
        "id": "GrbLl57EYS3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115e4dd9-b8fc-41cb-aa21-0ae4f781c513"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl.data.download' found in sys.modules after import of package 'minerl.data', but prior to execution of 'minerl.data.download'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "\u001b[32m2022-06-12 18:50:50\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34m__main__[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m Downloading dataset for MineRLTreechop-v0 to /home/minerl\n",
            "\u001b[32m2022-06-12 18:50:50\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34m__main__[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m Starting download ...\n",
            "\u001b[32m2022-06-12 18:50:50\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34mroot[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m File already exists.\n",
            "\u001b[32m2022-06-12 18:50:50\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34mroot[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - downloaded /home/minerl/download/v4/MineRLTreechop-v0.tar\n",
            "\u001b[32m2022-06-12 18:50:50\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34mroot[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m Extracting downloaded files - this may take some time\n",
            "\u001b[32m2022-06-12 18:51:01\u001b[0m \u001b[35mcb85c6a5ff1a\u001b[0m \u001b[34mroot[5074]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - extracted files to /home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def int64_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "metadata": {
        "id": "MoCWq5GvJRmV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_example(obs, action_id):\n",
        "  feature = {\n",
        "      'obs' : bytes_feature(tf.io.serialize_tensor(obs)),\n",
        "      'action_id' : int64_feature(action_id)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "#@tf.function\n",
        "def decode_example(example):\n",
        "  feature_description = {\n",
        "    \"obs\": tf.io.FixedLenFeature([], tf.string),\n",
        "    \"action_id\": tf.io.FixedLenFeature([], tf.int64)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, feature_description)\n",
        "  return tf.io.parse_tensor(example['obs'], out_type=tf.float32), example['action_id']"
      ],
      "metadata": {
        "id": "jRKdNnHjRBjU"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import minerl\n",
        "from minerl.data import BufferedBatchIter\n",
        "\n",
        "def preprocess_expert_data(wrapper, examples_per_file):\n",
        "    wrap = wrappers[wrapper]\n",
        "\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = BufferedBatchIter(data, 30000)\n",
        "\n",
        "    try:\n",
        "        os.makedirs('/home/minerl/tfrecords')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    i = 0\n",
        "    for current_state, action, reward, next_state, done in iterator.buffered_batch_iter(examples_per_file, num_epochs=1):\n",
        "        obs = current_state[\"pov\"].squeeze().astype(np.float32) / 255\n",
        "        action_id = wrap(action, examples_per_file).squeeze()\n",
        "        \n",
        "        with tf.io.TFRecordWriter(f'/home/minerl/tfrecords/{i}.tfrecord') as writer:\n",
        "            for x in range(examples_per_file):\n",
        "                example = encode_example(obs[x], action_id[x])\n",
        "                writer.write(example.SerializeToString())\n",
        "\n",
        "        i += 1\n"
      ],
      "metadata": {
        "id": "bFqbXyB8M6jh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfAkWunYGUZ"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWBZqHjZYGUb"
      },
      "source": [
        "## DQN Epsilon Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ESpX6wnwYGUc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import time\n",
        "\n",
        "def train(model, model_target, env):\n",
        "\n",
        "    num_actions = 4\n",
        "\n",
        "    seed = 42\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    epsilon_min = 0.1\n",
        "    epsilon_max = 1.0\n",
        "    epsilon_interval = (\n",
        "        epsilon_max - epsilon_min\n",
        "    )\n",
        "    batch_size = 32\n",
        "    max_steps_per_episode = 10000\n",
        "\n",
        "    env.seed(seed)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "    loss_function = keras.losses.Huber()\n",
        "\n",
        "    action_history = []\n",
        "    state_history = []\n",
        "    state_next_history = []\n",
        "    rewards_history = []\n",
        "    done_history = []\n",
        "    episode_reward_history = []\n",
        "\n",
        "    frame_sample = []\n",
        "\n",
        "    running_reward = 0\n",
        "    episode_count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    epsilon_random_frames = 50000\n",
        "    epsilon_greedy_frames = 10000000\n",
        "\n",
        "    max_memory_length = 100000\n",
        "\n",
        "    update_after_actions = 4\n",
        "    update_target_network = 1000\n",
        "\n",
        "    while True:\n",
        "        state = np.array(env.reset())\n",
        "        episode_reward = 0\n",
        "\n",
        "        start = time.time()\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            end = time.time()\n",
        "            frame_sample.append(end - start)\n",
        "            if len(frame_sample) == 60 * 5:\n",
        "                coiso = np.mean(frame_sample)\n",
        "                print(f'FPS: {1 / coiso}')\n",
        "                frame_sample = []\n",
        "            start = time.time()\n",
        "\n",
        "            #env.render()\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
        "                action = np.random.choice(num_actions)\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "            \n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            state_next, reward, done, _ = env.step(action)\n",
        "            state_next = np.array(state_next)\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            action_history.append(action)\n",
        "            state_history.append(state)\n",
        "            state_next_history.append(state_next)\n",
        "            done_history.append(done)\n",
        "            rewards_history.append(reward)\n",
        "            state = state_next\n",
        "\n",
        "            if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "                \n",
        "                indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "                state_sample = np.array([state_history[i] for i in indices])\n",
        "                state_next_sample = np.array([state_next_history[i] for i in indices])\n",
        "                rewards_sample = np.array([rewards_history[i] for i in indices])\n",
        "                action_sample = np.array([action_history[i] for i in indices])\n",
        "                done_sample = tf.convert_to_tensor(\n",
        "                    [float(done_history[i]) for i in indices]\n",
        "                )\n",
        "\n",
        "                future_rewards = predict_target(model_target, state_next_sample)\n",
        "                updated_q_values = rewards_sample + gamma * tf.reduce_max (\n",
        "                    future_rewards, axis=1\n",
        "                )\n",
        "                updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "                masks = tf.one_hot(action_sample, num_actions)\n",
        "\n",
        "                backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks)\n",
        "\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "                template = 'running reward: {:.2f} at episode {}, frame count {}'\n",
        "                print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "            if len(rewards_history) > max_memory_length:\n",
        "                del rewards_history[:1]\n",
        "                del state_history[:1]\n",
        "                del state_next_history[:1]\n",
        "                del action_history[:1]\n",
        "                del done_history[:1]\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if len(episode_reward_history) > 100:\n",
        "                del episode_reward_history[:1]\n",
        "            running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "            episode_count += 1\n",
        "\n",
        "            if running_reward > 40:\n",
        "                print('Solved at episode {}!'.format(episode_count))\n",
        "                break\n",
        "\n",
        "@tf.function\n",
        "def predict_target(model_target, state_next_sample):\n",
        "    future_rewards = model_target(state_next_sample)\n",
        "    return future_rewards\n",
        "\n",
        "@tf.function\n",
        "def backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state_sample)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "        loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjH-s9ZYGUU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "def register_model(name, model):\n",
        "    models[name] = model"
      ],
      "metadata": {
        "id": "mrjqzbYOc9Q5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjlYz3CYGUW"
      },
      "source": [
        "## Deepmind Atari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "EagSZZ1jYGUW"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense\n",
        "\n",
        "def deepmind_atari(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(32, 8, strides=4, activation='relu')(inputs)\n",
        "    x = Conv2D(64, 4, strides=4, activation='relu')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    output = Dense(nb_outputs, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output)\n",
        "\n",
        "register_model('deepmind_atari', deepmind_atari)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtTS3OdYGUX"
      },
      "source": [
        "## Modified Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "88KAQJ-jYGUY"
      },
      "outputs": [],
      "source": [
        "from keras import Model\n",
        "from keras.layers import Input, Conv2D, Flatten, Dense, Rescaling, BatchNormalization, Activation, SeparableConv2D, Dropout, MaxPooling2D, add\n",
        "\n",
        "def modified_xception(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = Rescaling(1.0 / 255)(inputs)\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    \n",
        "    outputs = Dense(nb_outputs, activation='linear')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "register_model('modified_xception', modified_xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A26gdzdYGUl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WRAPPER = 'amiranas'\n",
        "MODEL = 'modified_xception'"
      ],
      "metadata": {
        "id": "1rIDGfeUOyxV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def listdir(dir):\n",
        "    return list(map(\n",
        "        lambda file: dir + '/' + file,\n",
        "        os.listdir(dir)\n",
        "    ))"
      ],
      "metadata": {
        "id": "-uGjsbB82m4O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            .repeat()\n",
        "            .batch(batch_size, num_parallel_calls=AUTOTUNE)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )"
      ],
      "metadata": {
        "id": "uD3yvvD82Trn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_expert_data(WRAPPER, 256)"
      ],
      "metadata": {
        "id": "dMeoVc0POveU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = listdir('/home/minerl/tfrecords')\n",
        "dataset = create_dataset(filenames, 128)"
      ],
      "metadata": {
        "id": "M8x0I3mCQ1mc"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = models[MODEL]((64, 64, 3), 112)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer, loss_fn, metrics=[val_acc_metric])"
      ],
      "metadata": {
        "id": "J_GyEeck31hx"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/home/weights/treechop')"
      ],
      "metadata": {
        "id": "nGPLAxsatOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, steps_per_epoch=len(filenames) * 256 / 128, epochs=10)\n",
        "model.save_weights('/home/weights/treechop')"
      ],
      "metadata": {
        "id": "BzhhDNxs38Mm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "0550aa62-f7a0-489c-c766-254658100875"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 141/3512 [>.............................] - ETA: 4:39 - loss: 1.5257 - sparse_categorical_accuracy: 0.6075"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c04ed0978e0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/weights/treechop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}