{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imenatrix/TCC-INFO19/blob/feature-dqfd/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "jQ0equmGYKbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa\n",
        "!sudo apt-get purge openjdk-*\n",
        "!sudo apt-get install openjdk-8-jdk"
      ],
      "metadata": {
        "id": "YRB8g4TMYMC_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip3 install minerl"
      ],
      "metadata": {
        "id": "kDkezv40YO5h"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "-zuJdSSzX9yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from itertools import product\n",
        "from collections import OrderedDict\n",
        "from google.cloud import storage\n",
        "from google.colab import drive\n",
        "\n",
        "import minerl\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras import Model\n",
        "from keras.layers import *\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "FLc3fue_X9TE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519b2855-201d-4cf7-9534-37aba3d297a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except ValueError:\n",
        "    strategy = tf.distribute.get_strategy()"
      ],
      "metadata": {
        "id": "XJ4KnwlO2VA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFFwJOuYGUe"
      },
      "source": [
        "# Wrappers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wrappers = {}\n",
        "\n",
        "def register_wrapper(name, wrapper):\n",
        "    wrappers[name] = wrapper"
      ],
      "metadata": {
        "id": "MVMjGEEkgSl7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTI-JMK6YGUf"
      },
      "source": [
        "## Amiranas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ANVPcDTdYGUf"
      },
      "outputs": [],
      "source": [
        "class ActionManager:\n",
        "    \"\"\"Main minecraft action wrapper. Simplifies action space to 130 discrete actions\"\"\"\n",
        "\n",
        "    def __init__(self, c_action_magnitude=22.5):\n",
        "        self.c_action_magnitude = c_action_magnitude\n",
        "\n",
        "        self.zero_action = OrderedDict([('attack', 0),\n",
        "                                        ('back', 0),\n",
        "                                        ('camera', np.array([0., 0.])),\n",
        "                                        ('forward', 0),\n",
        "                                        ('jump', 0),\n",
        "                                        ('left', 0),\n",
        "                                        ('right', 0),\n",
        "                                        ('sneak', 0),\n",
        "                                        ('sprint', 0)])\n",
        "\n",
        "        # camera discretization:\n",
        "        self.camera_dict = OrderedDict([\n",
        "            ('turn_up', np.array([-c_action_magnitude, 0.])),\n",
        "            ('turn_down', np.array([c_action_magnitude, 0.])),\n",
        "            ('turn_left', np.array([0., -c_action_magnitude])),\n",
        "            ('turn_right', np.array([0., c_action_magnitude]))\n",
        "        ])\n",
        "\n",
        "        self.fully_connected_no_camera = ['attack', 'back', 'forward', 'jump', 'left', 'right', 'sprint']\n",
        "        self.camera_actions = ['turn_up', 'turn_down', 'turn_left', 'turn_right']\n",
        "        self.fully_connected = self.fully_connected_no_camera + self.camera_actions\n",
        "\n",
        "        # following action combinations are excluded:\n",
        "        self.exclude = [('forward', 'back'), ('left', 'right'), ('attack', 'jump'),\n",
        "                        ('turn_up', 'turn_down', 'turn_left', 'turn_right')]\n",
        "\n",
        "        # sprint only allowed when forward is used:\n",
        "        self.only_if = [('sprint', 'forward')]\n",
        "\n",
        "        # Maximal allowed mount of actions within one action:\n",
        "        self.remove_size = 3\n",
        "\n",
        "        # if more than 3 actions are present, actions are removed using this list until only 3 actions remain:\n",
        "        self.remove_first_list = ['sprint', 'left', 'right', 'back',\n",
        "                                  'turn_up', 'turn_down', 'turn_left', 'turn_right',\n",
        "                                  'attack', 'jump', 'forward']\n",
        "\n",
        "        self.fully_connected_list = list(product(range(2), repeat=len(self.fully_connected)))\n",
        "\n",
        "        remove = []\n",
        "        for el in self.fully_connected_list:\n",
        "            for tuple_ in self.exclude:\n",
        "                if sum([el[self.fully_connected.index(a)] for a in tuple_]) > 1:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            for a, b in self.only_if:\n",
        "                if el[self.fully_connected.index(a)] == 1 and el[self.fully_connected.index(b)] == 0:\n",
        "                    if el not in remove:\n",
        "                        remove.append(el)\n",
        "            if sum(el) > self.remove_size:\n",
        "                if el not in remove:\n",
        "                    remove.append(el)\n",
        "\n",
        "        for r in remove:\n",
        "            self.fully_connected_list.remove(r)\n",
        "\n",
        "        self.action_list = []\n",
        "        for el in self.fully_connected_list:\n",
        "            new_action = copy.deepcopy(self.zero_action)\n",
        "            for key, value in zip(self.fully_connected, el):\n",
        "                if key in self.camera_actions:\n",
        "                    if value:\n",
        "                        new_action['camera'] = self.camera_dict[key]\n",
        "                else:\n",
        "                    new_action[key] = value\n",
        "            self.action_list.append(new_action)\n",
        "\n",
        "        self.num_action_ids_list = [len(self.action_list)]\n",
        "        self.act_continuous_size = 0\n",
        "\n",
        "    def get_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        a['camera'] += np.random.normal(0., 0.5, 2)\n",
        "        return a\n",
        "\n",
        "    def print_action(self, id_):\n",
        "        a = copy.deepcopy(self.action_list[int(id_)])\n",
        "        out = \"\"\n",
        "        for k, v in a.items():\n",
        "            if k != 'camera':\n",
        "                if v != 0:\n",
        "                    out += f'{k} '\n",
        "            else:\n",
        "                if (v != np.zeros(2)).any():\n",
        "                    out += k\n",
        "\n",
        "        print(out)\n",
        "\n",
        "    def get_id(self, action, batch_size):\n",
        "\n",
        "        coiso = np.zeros((batch_size,), dtype=int)\n",
        "        action = copy.deepcopy(action)\n",
        "        for i in range(batch_size):\n",
        "\n",
        "            # discretize 'camera':\n",
        "            camera = action['camera'][i]\n",
        "            camera_action_amount = 0\n",
        "            if - self.c_action_magnitude / 2. < camera[0] < self.c_action_magnitude / 2.:\n",
        "                action['camera'][i][0] = 0.\n",
        "                if - self.c_action_magnitude / 2. < camera[1] < self.c_action_magnitude / 2.:\n",
        "                    action['camera'][i][1] = 0.\n",
        "                else:\n",
        "                    camera_action_amount = 1\n",
        "                    action['camera'][i][1] = self.c_action_magnitude * np.sign(camera[1])\n",
        "            else:\n",
        "                camera_action_amount = 1\n",
        "                action['camera'][i][0] = self.c_action_magnitude * np.sign(camera[0])\n",
        "\n",
        "                action['camera'][i][1] = 0.\n",
        "\n",
        "            # simplify action:\n",
        "            for tuple_ in self.exclude:\n",
        "                if len(tuple_) == 2:\n",
        "                    a, b = tuple_\n",
        "                    if action[a][i] and action[b][i]:\n",
        "                        action[b][i] = 0\n",
        "            for a, b in self.only_if:\n",
        "                if not action[b][i]:\n",
        "                    if action[a][i]:\n",
        "                        action[a][i] = 0\n",
        "            for a in self.remove_first_list:\n",
        "                if sum([action[key][i] for key in self.fully_connected_no_camera]) > \\\n",
        "                        (self.remove_size - camera_action_amount):\n",
        "                    if a in self.camera_actions:\n",
        "                        action['camera'][i] = np.array([0., 0.])\n",
        "                        camera_action_amount = 0\n",
        "                    else:\n",
        "                        action[a][i] = 0\n",
        "                else:\n",
        "                    break\n",
        "\n",
        "            # set one_hot camera keys:\n",
        "            for key in self.camera_actions:\n",
        "                action[key] = [0 for x in range(batch_size)]\n",
        "            for key, val in self.camera_dict.items():\n",
        "                if (action['camera'][i] == val).all():\n",
        "                    action[key][i] = 1\n",
        "                    break\n",
        "\n",
        "            non_separate_values = tuple(action[key][i] for key in self.fully_connected)\n",
        "\n",
        "            coiso[i] = self.fully_connected_list.index(non_separate_values)\n",
        "        return coiso\n",
        "\n",
        "    def get_left_right_reversed_mapping(self):\n",
        "        action_mapping = []\n",
        "        for action in self.action_list:\n",
        "            reversed_action = copy.deepcopy(action)\n",
        "            if action['left'] == 1:\n",
        "                reversed_action['left'] = 0\n",
        "                reversed_action['right'] = 1\n",
        "                assert action['right'] == 0\n",
        "            if action['right'] == 1:\n",
        "                reversed_action['right'] = 0\n",
        "                reversed_action['left'] = 1\n",
        "                assert action['left'] == 0\n",
        "            if (action['camera'] == [0, -22.5]).all():\n",
        "                reversed_action['camera'][1] = 22.5\n",
        "            if (action['camera'] == [0, 22.5]).all():\n",
        "                reversed_action['camera'][1] = -22.5\n",
        "\n",
        "            rev_action_id = self.get_id(reversed_action)\n",
        "            action_mapping.append(rev_action_id)\n",
        "\n",
        "        return action_mapping\n",
        "\n",
        "manager = ActionManager()\n",
        "register_wrapper('amiranas', manager.get_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW5tdiaUYGUi"
      },
      "source": [
        "## Baseline Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8dNacU-hYGUl"
      },
      "outputs": [],
      "source": [
        "def dataset_action_batch_to_actions(dataset_actions, batch_size, camera_margin=3):\n",
        "    \"\"\"\n",
        "    Turn a batch of actions from dataset (`batch_iter`) to a numpy\n",
        "    array that corresponds to batch of actions of ActionShaping wrapper (_actions).\n",
        "\n",
        "    Camera margin sets the threshold what is considered \"moving camera\".\n",
        "\n",
        "    Note: Hardcoded to work for actions in ActionShaping._actions, with \"intuitive\"\n",
        "        ordering of actions.\n",
        "        If you change ActionShaping._actions, remember to change this!\n",
        "\n",
        "    Array elements are integers corresponding to actions, or \"-1\"\n",
        "    for actions that did not have any corresponding discrete match.\n",
        "    \"\"\"\n",
        "    # There are dummy dimensions of shape one\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Moving camera is most important (horizontal first)\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 7\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 3\n",
        "            else:\n",
        "                actions[i] = 2\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 1\n",
        "        else:\n",
        "            # No reasonable mapping (would be no-op)\n",
        "            actions[i] = 0\n",
        "    return actions\n",
        "\n",
        "register_wrapper('baseline_notebook', dataset_action_batch_to_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "WhuJkgDYJLmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env MINERL_DATA_ROOT=/home/minerl\n",
        "%env GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json"
      ],
      "metadata": {
        "id": "zwnzpW4IYRa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3cd4ddd-3eeb-4a06-e2f6-c9a86d3f59b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: MINERL_DATA_ROOT=/home/minerl\n",
            "env: GOOGLE_APPLICATION_CREDENTIALS=/content/drive/MyDrive/key.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m minerl.data.download --environment \"MineRLTreechop-v0\""
      ],
      "metadata": {
        "id": "GrbLl57EYS3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737b6025-1df8-4828-ce81-b743cb7658a2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n",
            "/usr/lib/python3.7/runpy.py:125: RuntimeWarning: 'minerl.data.download' found in sys.modules after import of package 'minerl.data', but prior to execution of 'minerl.data.download'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "\u001b[32m2022-11-06 21:56:49\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34m__main__[3634]\u001b[0m \u001b[1;30mINFO\u001b[0m Downloading dataset for MineRLTreechop-v0 to /home/minerl\n",
            "\u001b[32m2022-11-06 21:56:49\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34m__main__[3634]\u001b[0m \u001b[1;30mINFO\u001b[0m Starting download ...\n",
            "\u001b[32m2022-11-06 21:56:49\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mChoosing mirror ...\u001b[0m\n",
            "\u001b[32m2022-11-06 21:56:50\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mPicked https://minerl-asia.s3.amazonaws.com/v4/MineRLTreechop-v0.tar ping=402.692ms\u001b[0m\n",
            "\u001b[32m2022-11-06 21:56:50\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mStarting download at 0.0MB\u001b[0m\n",
            "\u001b[32m2022-11-06 21:56:50\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mDEBUG\u001b[0m \u001b[32mFile size is 1510.7MB\u001b[0m\n",
            "Download: https://minerl-asia.s3.amazonaws.com/v4/MineRLTreechop-v0.tar: 100% 1511.0/1510.73792 [00:40<00:00, 37.67MB/s]\n",
            "\u001b[32m2022-11-06 21:57:30\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - downloaded /home/minerl/download/v4/MineRLTreechop-v0.tar\n",
            "\u001b[32m2022-11-06 21:57:30\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mINFO\u001b[0m Extracting downloaded files - this may take some time\n",
            "\u001b[32m2022-11-06 21:57:36\u001b[0m \u001b[35ma308de0fd209\u001b[0m \u001b[34mroot[3634]\u001b[0m \u001b[1;30mINFO\u001b[0m Success - extracted files to /home/minerl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "    # The path to your file to upload\n",
        "    # source_file_name = \"local/path/to/file\"\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    \n",
        "    blob.upload_from_filename(source_file_name)\n",
        "\n",
        "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n"
      ],
      "metadata": {
        "id": "O-eBZe1Ofo-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bytes_feature(value):\n",
        "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "  if isinstance(value, type(tf.constant(0))):\n",
        "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "def float_feature(value):\n",
        "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "def int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
      ],
      "metadata": {
        "id": "MoCWq5GvJRmV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import minerl\n",
        "import os\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "from minerl.data.util import multimap\n",
        "import random\n",
        "\n",
        "MINERL_DATA_ROOT = os.getenv('MINERL_DATA_ROOT')\n",
        "\n",
        "\n",
        "\n",
        "def stack(*args):\n",
        "    return np.stack(args)\n",
        "\n",
        "\n",
        "class BufferedBatchIter:\n",
        "    all_trajectories = None\n",
        "    \"\"\"\n",
        "    A class that maintains and exposes an iterator which loads trajectories into a\n",
        "    configurably-sized buffer, samples batches from that buffer, and refills the buffer\n",
        "    when necessary.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 data_pipeline,\n",
        "                 buffer_target_size=50000):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_pipeline: A data pipeline object that you want to construct an iterator from\n",
        "            buffer_target_size: How large you'd like your data buffer to be (in units of timesteps)\n",
        "\n",
        "            Note that this is not an exact cap, since we don't know how large a trajectory will be\n",
        "            until we load it in. This implementation tries to maintain a buffer size by keeping\n",
        "            track of the average size of trajectories in this data pipeline, and loading a new\n",
        "            trajectory when the size of the buffer is more than <average_size> below the target\n",
        "        \"\"\"\n",
        "        self.data_pipeline = data_pipeline\n",
        "        self.data_buffer = []\n",
        "        self.buffer_target_size = buffer_target_size\n",
        "        self.traj_sizes = []\n",
        "        self.avg_traj_size = 0\n",
        "        if BufferedBatchIter.all_trajectories == None:\n",
        "            self.all_trajectories = self.data_pipeline.get_trajectory_names()\n",
        "            BufferedBatchIter.all_trajectories = deepcopy(self.all_trajectories)\n",
        "        else:\n",
        "            self.all_trajectories = BufferedBatchIter.all_trajectories\n",
        "        # available_trajectories is a dynamic, per-epoch list that will keep track of\n",
        "        # which trajectories we haven't yet used in a given epoch\n",
        "        self.available_trajectories = deepcopy(self.all_trajectories)\n",
        "        #random.shuffle(self.available_trajectories)\n",
        "\n",
        "    def optionally_fill_buffer(self):\n",
        "        \"\"\"\n",
        "        This method is run after every batch, but only actually executes a buffer\n",
        "        refill and re-shuffle if more data is needed\n",
        "        \"\"\"\n",
        "        buffer_updated = False\n",
        "\n",
        "        # Add trajectories to the buffer if the remaining space is\n",
        "        # greater than our anticipated trajectory size (in the form of the empirical average)\n",
        "        while (self.buffer_target_size - len(self.data_buffer)) > self.avg_traj_size:\n",
        "            if len(self.available_trajectories) == 0:\n",
        "                return\n",
        "            traj_to_load = self.available_trajectories.pop()\n",
        "            data_loader = self.data_pipeline.load_data(traj_to_load)\n",
        "            traj_len = 0\n",
        "            for data_tuple in data_loader:\n",
        "                traj_len += 1\n",
        "                self.data_buffer.append(data_tuple)\n",
        "\n",
        "            self.traj_sizes.append(traj_len)\n",
        "            self.avg_traj_size = np.mean(self.traj_sizes)\n",
        "            buffer_updated = True\n",
        "        #if buffer_updated:\n",
        "            #random.shuffle(self.data_buffer)\n",
        "\n",
        "    def get_batch(self, batch_size):\n",
        "        \"\"\"A simple utility method for constructing a return batch in the expected format\"\"\"\n",
        "        ret_dict_list = []\n",
        "        for _ in range(batch_size):\n",
        "            data_tuple = self.data_buffer.pop()\n",
        "            ret_dict = dict(obs=data_tuple[0],\n",
        "                            act=data_tuple[1],\n",
        "                            reward=data_tuple[2],\n",
        "                            next_obs=data_tuple[3],\n",
        "                            done=data_tuple[4])\n",
        "            ret_dict_list.append(ret_dict)\n",
        "        return multimap(stack, *ret_dict_list)\n",
        "\n",
        "    def buffered_batch_iter(self, batch_size, num_epochs=None, num_batches=None):\n",
        "        \"\"\"\n",
        "        The actual generator method that returns batches. You can specify either\n",
        "        a desired number of batches, or a desired number of epochs, but not both,\n",
        "        since they might conflict.\n",
        "\n",
        "        ** You must specify one or the other **\n",
        "\n",
        "        Args:\n",
        "            batch_size: The number of transitions/timesteps to be returned in each batch\n",
        "            num_epochs: Optional, how many full passes through all trajectories to return\n",
        "            num_batches: Optional, how many batches to return\n",
        "\n",
        "        \"\"\"\n",
        "        assert num_batches is not None or num_epochs is not None, \"One of num_epochs or \" \\\n",
        "                                                                  \"num_batches must be non-None\"\n",
        "        assert num_batches is None or num_epochs is None, \"You cannot specify both \" \\\n",
        "                                                          \"num_batches and num_epochs\"\n",
        "\n",
        "        epoch_count = 0\n",
        "        batch_count = 0\n",
        "\n",
        "        while True:\n",
        "            # If we've hit the desired number of epochs\n",
        "            if num_epochs is not None and epoch_count >= num_epochs:\n",
        "                return\n",
        "            # If we've hit the desired number of batches\n",
        "            if num_batches is not None and batch_count >= num_batches:\n",
        "                return\n",
        "            # Refill the buffer if we need to\n",
        "            # (doing this before getting batch so it'll run on the first iteration)\n",
        "            self.optionally_fill_buffer()\n",
        "            ret_batch = self.get_batch(batch_size=batch_size)\n",
        "            batch_count += 1\n",
        "            if len(self.data_buffer) < batch_size:\n",
        "                assert len(self.available_trajectories) == 0, \"You've reached the end of your \" \\\n",
        "                                                              \"data buffer while still having \" \\\n",
        "                                                              \"trajectories available; \" \\\n",
        "                                                              \"something seems to have gone wrong\"\n",
        "                epoch_count += 1\n",
        "                self.available_trajectories = deepcopy(self.all_trajectories)\n",
        "                #random.shuffle(self.available_trajectories)\n",
        "\n",
        "            keys = ('obs', 'act', 'reward', 'next_obs', 'done')\n",
        "            yield tuple([ret_batch[key] for key in keys])\n"
      ],
      "metadata": {
        "id": "2PEKJZjpjAO6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_expert_data(wrapper, examples_per_file, dataset_dir):\n",
        "    wrap = wrappers[wrapper]\n",
        "\n",
        "    data = minerl.data.make('MineRLTreechop-v0')\n",
        "    iterator = BufferedBatchIter(data, 30000)\n",
        "\n",
        "    try:\n",
        "        os.makedirs(dataset_dir)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    state_buffer = []\n",
        "    action_buffer = []\n",
        "    reward_buffer = []\n",
        "    state_next_buffer = []\n",
        "    done_buffer = []\n",
        "\n",
        "    gamma = 0.99\n",
        "\n",
        "    filename = f'{i}.tfrecord'\n",
        "    filepath = f'{dataset_dir}/{filename}'\n",
        "    blobpath = f'tfrecords_nstep/{filename}'\n",
        "    writer = tf.io.TFRecordWriter(filepath)\n",
        "\n",
        "    examples = 0\n",
        "\n",
        "    for state, action, reward, state_next, done in iterator.buffered_batch_iter(examples_per_file, num_epochs=1):\n",
        "        state = state['pov'].squeeze().astype(np.float32) / 255\n",
        "        state_next = state_next['pov'].squeeze().astype(np.float32) / 255\n",
        "        action = wrap(action, examples_per_file).squeeze()\n",
        "\n",
        "        for nstep_state, nstep_action, nstep_reward, nstep_state_next, nstep_done in zip(state, action, reward, state_next, done):\n",
        "            state_buffer.append(nstep_state)\n",
        "            action_buffer.append(nstep_action)\n",
        "            reward_buffer.append(nstep_reward)\n",
        "            state_next_buffer.append(nstep_state_next)\n",
        "            done_buffer.append(nstep_done)\n",
        "\n",
        "            if len(reward_buffer) == 10:\n",
        "\n",
        "                nstep_reward_sum = 0\n",
        "                episode_ended = nstep_done\n",
        "                do_while = True\n",
        "\n",
        "                while episode_ended or do_while:\n",
        "                    for j in range(len(reward_buffer)):\n",
        "                        nstep_reward_sum += gamma ** j * reward_buffer[j]\n",
        "\n",
        "                    filename = f'{i}.tfrecord'\n",
        "                    filepath = f'{dataset_dir}/{filename}'\n",
        "                    blobpath = f'tfrecords_nstep/{filename}'\n",
        "\n",
        "                    example = encode_example(\n",
        "                        state_buffer[0],\n",
        "                        action_buffer[0],\n",
        "                        reward_buffer[0],\n",
        "                        state_next_buffer[0],\n",
        "                        done_buffer[0],\n",
        "                        nstep_reward_sum,\n",
        "                        nstep_state_next,\n",
        "                        episode_ended\n",
        "                    )\n",
        "                    writer.write(example.SerializeToString())\n",
        "                    examples += 1\n",
        "\n",
        "                    if examples == examples_per_file:\n",
        "\n",
        "                        writer.close()\n",
        "\n",
        "                        upload_blob('minerl_data_records', filepath, blobpath)\n",
        "                        os.remove(filepath)\n",
        "\n",
        "                        examples = 0\n",
        "\n",
        "                        i += 1\n",
        "\n",
        "                        if i == 2:\n",
        "                            return\n",
        "\n",
        "                        filename = f'{i}.tfrecord'\n",
        "                        filepath = f'{dataset_dir}/{filename}'\n",
        "                        blobpath = f'tfrecords_nstep/{filename}'\n",
        "                        writer = tf.io.TFRecordWriter(filepath)\n",
        "\n",
        "                    if done_buffer[0]:\n",
        "                        episode_ended = False\n",
        "\n",
        "                    state_buffer = state_buffer[1:]\n",
        "                    action_buffer = action_buffer[1:]\n",
        "                    reward_buffer = reward_buffer[1:]\n",
        "                    state_next_buffer = state_next_buffer[1:]\n",
        "                    done_buffer = done_buffer[1:]\n",
        "\n",
        "                    do_while = False\n"
      ],
      "metadata": {
        "id": "bFqbXyB8M6jh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listdir(dir):\n",
        "    return list(map(\n",
        "        lambda file: dir + '/' + file,\n",
        "        os.listdir(dir)\n",
        "    ))"
      ],
      "metadata": {
        "id": "ROT5pG0rSL9M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            # .repeat()\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )\n",
        "\n",
        "def create_val_dataset(filenames, batch_size):\n",
        "    AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "    ignore_order = tf.data.Options()\n",
        "    ignore_order.deterministic = False  # disable order, increase speed\n",
        "\n",
        "    return (\n",
        "        tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
        "            .with_options(ignore_order)\n",
        "            .map(decode_example, num_parallel_calls=AUTOTUNE)\n",
        "            .batch(batch_size)\n",
        "            .prefetch(AUTOTUNE)\n",
        "    )"
      ],
      "metadata": {
        "id": "Kv80oX7LSMgQ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_example(state, action, reward, state_next, done, nstep_reward_sum, nstep_state_next, nstep_done):\n",
        "  feature = {\n",
        "      'state' : bytes_feature(tf.io.serialize_tensor(state)),\n",
        "      'action' : int64_feature(action),\n",
        "      'reward' : float_feature(reward),\n",
        "      'state_next' : bytes_feature(tf.io.serialize_tensor(state_next)),\n",
        "      'done' : int64_feature(done),\n",
        "      'nstep_reward_sum' : float_feature(nstep_reward_sum),\n",
        "      'nstep_state_next' : bytes_feature(tf.io.serialize_tensor(nstep_state_next)),\n",
        "      'nstep_done' : int64_feature(nstep_done)\n",
        "  }\n",
        "  return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def decode_example(example):\n",
        "  feature_description = {\n",
        "    'state': tf.io.FixedLenFeature([], tf.string),\n",
        "    'action': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'reward' : tf.io.FixedLenFeature([], tf.float32),\n",
        "    'state_next' : tf.io.FixedLenFeature([], tf.string),\n",
        "    'done' : tf.io.FixedLenFeature([], tf.int64),\n",
        "    'nstep_reward_sum' : tf.io.FixedLenFeature([], tf.float32),\n",
        "    'nstep_state_next' : tf.io.FixedLenFeature([], tf.string),\n",
        "    'nstep_done' : tf.io.FixedLenFeature([], tf.int64)\n",
        "  }\n",
        "  example = tf.io.parse_single_example(example, feature_description)\n",
        "\n",
        "  state = tf.io.parse_tensor(example['state'], out_type=tf.float32)\n",
        "  state = tf.reshape(state, (64, 64, 3))\n",
        "\n",
        "  state_next = tf.io.parse_tensor(example['state_next'], out_type=tf.float32)\n",
        "  state_next = tf.reshape(state_next, (64, 64, 3))\n",
        "\n",
        "  nstep_state_next = tf.io.parse_tensor(example['nstep_state_next'], out_type=tf.float32)\n",
        "  nstep_state_next = tf.reshape(nstep_state_next, (64, 64, 3))\n",
        "\n",
        "  return state, example['action'], example['reward'], state_next, example['done'], example['nstep_reward_sum'], nstep_state_next, example['nstep_done']"
      ],
      "metadata": {
        "id": "jRKdNnHjRBjU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDfAkWunYGUZ"
      },
      "source": [
        "# Trainers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Loop"
      ],
      "metadata": {
        "id": "A2piAVS4fTFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "from collections import namedtuple\n",
        "\n",
        "def val_step(model, loss_fn, state, target_q_values, updated_q_values, updated_nstep_q_values, masks):\n",
        "    q_values = model(state)\n",
        "    q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "    lmc_loss = tf.reduce_mean(\n",
        "        tf.reduce_max(\n",
        "            tf.cast(\n",
        "                tf.equal(\n",
        "                    masks,\n",
        "                    0\n",
        "                ),\n",
        "                tf.float32\n",
        "            ) + target_q_values,\n",
        "            axis=1\n",
        "        ) - tf.reduce_sum(masks * target_q_values, axis=1)\n",
        "    )\n",
        "\n",
        "    loss = loss_fn(updated_q_values, q_action) + loss_fn(updated_nstep_q_values, q_action) + lmc_loss + sum(model.losses)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train_step(model, loss_fn, optmizer, state, target_q_values, updated_q_values, updated_nstep_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "\n",
        "        lmc_loss = tf.reduce_mean(\n",
        "            tf.reduce_max(\n",
        "                tf.cast(\n",
        "                    tf.equal(\n",
        "                        masks,\n",
        "                        0\n",
        "                    ),\n",
        "                    tf.float32\n",
        "                ) + target_q_values,\n",
        "                axis=1\n",
        "            ) - tf.reduce_sum(masks * target_q_values, axis=1)\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(updated_q_values, q_action) + loss_fn(updated_nstep_q_values, q_action) + lmc_loss + sum(model.losses)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "def fit(model, model_target, loss_fn, optimizer, dataset, val_dataset, epochs, steps, val_steps):\n",
        "\n",
        "    gamma = 0.99\n",
        "\n",
        "    History = namedtuple('History', 'history')\n",
        "    history = History(history={\n",
        "        'loss': [],\n",
        "        'val_loss': []\n",
        "    })\n",
        "\n",
        "    frame = 0\n",
        "\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        for step, (state, action, reward, state_next, done, nstep_reward_sum, nstep_state_next, nstep_done) in tqdm(enumerate(dataset), total=steps):\n",
        "            target_q_values = model_target(state)\n",
        "            future_rewards = model_target(state_next)\n",
        "            nstep_future_rewards = model_target(nstep_state_next)\n",
        "\n",
        "            updated_q_values = reward + gamma * tf.reduce_max (\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "            updated_q_values = updated_q_values * tf.cast(1 - done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "\n",
        "            updated_nstep_q_values = nstep_reward_sum + gamma ** 10 + tf.reduce_max (\n",
        "                nstep_future_rewards, axis=1\n",
        "            )\n",
        "            updated_nstep_q_values = updated_nstep_q_values * tf.cast(1 - nstep_done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "\n",
        "            masks = tf.one_hot(action, 112)\n",
        "\n",
        "            train_loss += train_step(model, loss_fn, optimizer, state, target_q_values, updated_q_values, updated_nstep_q_values, masks)\n",
        "\n",
        "            frame += 1\n",
        "            if frame % 1000 == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "\n",
        "        for step, (state, action, reward, state_next, done, nstep_reward_sum, nstep_state_next, nstep_done) in enumerate(val_dataset):\n",
        "            target_q_values = model_target(state)\n",
        "            future_rewards = model_target(state_next)\n",
        "\n",
        "            updated_q_values = reward + gamma * tf.reduce_max (\n",
        "                future_rewards, axis=1\n",
        "            )\n",
        "            updated_q_values = updated_q_values * tf.cast(1 - done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "\n",
        "            updated_nstep_q_values = nstep_reward_sum + gamma ** 10 + tf.reduce_max (\n",
        "                nstep_future_rewards, axis=1\n",
        "            )\n",
        "            updated_nstep_q_values = updated_nstep_q_values * tf.cast(1 - nstep_done, dtype=tf.float32) - tf.cast(done, dtype=tf.float32)\n",
        "\n",
        "            masks = tf.one_hot(action, 112)\n",
        "\n",
        "            val_loss += val_step(model, loss_fn, state, target_q_values, updated_q_values, updated_nstep_q_values, masks)\n",
        "\n",
        "        history.history['loss'].append(train_loss / steps)\n",
        "        history.history['val_loss'].append(val_loss / val_steps)\n",
        "    \n",
        "    return history"
      ],
      "metadata": {
        "id": "fxsyDC1tfWiH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWBZqHjZYGUb"
      },
      "source": [
        "## DQN Epsilon Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ESpX6wnwYGUc"
      },
      "outputs": [],
      "source": [
        "def train(model, model_target, env):\n",
        "\n",
        "    num_actions = 4\n",
        "\n",
        "    seed = 42\n",
        "    gamma = 0.99\n",
        "    epsilon = 1.0\n",
        "    epsilon_min = 0.1\n",
        "    epsilon_max = 1.0\n",
        "    epsilon_interval = (\n",
        "        epsilon_max - epsilon_min\n",
        "    )\n",
        "    batch_size = 32\n",
        "    max_steps_per_episode = 10000\n",
        "\n",
        "    env.seed(seed)\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
        "    loss_function = keras.losses.Huber()\n",
        "\n",
        "    action_history = []\n",
        "    state_history = []\n",
        "    state_next_history = []\n",
        "    rewards_history = []\n",
        "    done_history = []\n",
        "    episode_reward_history = []\n",
        "\n",
        "    frame_sample = []\n",
        "\n",
        "    running_reward = 0\n",
        "    episode_count = 0\n",
        "    frame_count = 0\n",
        "\n",
        "    epsilon_random_frames = 50000\n",
        "    epsilon_greedy_frames = 10000000\n",
        "\n",
        "    max_memory_length = 100000\n",
        "\n",
        "    update_after_actions = 4\n",
        "    update_target_network = 1000\n",
        "\n",
        "    while True:\n",
        "        state = np.array(env.reset())\n",
        "        episode_reward = 0\n",
        "\n",
        "        start = time.time()\n",
        "        for timestep in range(1, max_steps_per_episode):\n",
        "\n",
        "            end = time.time()\n",
        "            frame_sample.append(end - start)\n",
        "            if len(frame_sample) == 60 * 5:\n",
        "                coiso = np.mean(frame_sample)\n",
        "                print(f'FPS: {1 / coiso}')\n",
        "                frame_sample = []\n",
        "            start = time.time()\n",
        "\n",
        "            #env.render()\n",
        "            frame_count += 1\n",
        "\n",
        "            if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n",
        "                action = np.random.choice(num_actions)\n",
        "            else:\n",
        "                state_tensor = tf.convert_to_tensor(state)\n",
        "                state_tensor = tf.expand_dims(state_tensor, 0)\n",
        "                action_probs = model(state_tensor, training=False)\n",
        "                action = tf.argmax(action_probs[0]).numpy()\n",
        "            \n",
        "            epsilon -= epsilon_interval / epsilon_greedy_frames\n",
        "            epsilon = max(epsilon, epsilon_min)\n",
        "\n",
        "            state_next, reward, done, _ = env.step(action)\n",
        "            state_next = np.array(state_next)\n",
        "\n",
        "            episode_reward += reward\n",
        "\n",
        "            action_history.append(action)\n",
        "            state_history.append(state)\n",
        "            state_next_history.append(state_next)\n",
        "            done_history.append(done)\n",
        "            rewards_history.append(reward)\n",
        "            state = state_next\n",
        "\n",
        "            if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n",
        "                \n",
        "                indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
        "\n",
        "                state_sample = np.array([state_history[i] for i in indices])\n",
        "                state_next_sample = np.array([state_next_history[i] for i in indices])\n",
        "                rewards_sample = np.array([rewards_history[i] for i in indices])\n",
        "                action_sample = np.array([action_history[i] for i in indices])\n",
        "                done_sample = tf.convert_to_tensor(\n",
        "                    [float(done_history[i]) for i in indices]\n",
        "                )\n",
        "\n",
        "                future_rewards = predict_target(model_target, state_next_sample)\n",
        "                updated_q_values = rewards_sample + gamma * tf.reduce_max (\n",
        "                    future_rewards, axis=1\n",
        "                )\n",
        "                updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n",
        "\n",
        "                masks = tf.one_hot(action_sample, num_actions)\n",
        "\n",
        "                backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks)\n",
        "\n",
        "            if frame_count % update_target_network == 0:\n",
        "                model_target.set_weights(model.get_weights())\n",
        "                template = 'running reward: {:.2f} at episode {}, frame count {}'\n",
        "                print(template.format(running_reward, episode_count, frame_count))\n",
        "\n",
        "            if len(rewards_history) > max_memory_length:\n",
        "                del rewards_history[:1]\n",
        "                del state_history[:1]\n",
        "                del state_next_history[:1]\n",
        "                del action_history[:1]\n",
        "                del done_history[:1]\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            episode_reward_history.append(episode_reward)\n",
        "            if len(episode_reward_history) > 100:\n",
        "                del episode_reward_history[:1]\n",
        "            running_reward = np.mean(episode_reward_history)\n",
        "\n",
        "            episode_count += 1\n",
        "\n",
        "            if running_reward > 40:\n",
        "                print('Solved at episode {}!'.format(episode_count))\n",
        "                break\n",
        "\n",
        "@tf.function\n",
        "def predict_target(model_target, state_next_sample):\n",
        "    future_rewards = model_target(state_next_sample)\n",
        "    return future_rewards\n",
        "\n",
        "@tf.function\n",
        "def backpropagation(model, optimizer, loss_function, state_sample, updated_q_values, masks):\n",
        "    with tf.GradientTape() as tape:\n",
        "        q_values = model(state_sample)\n",
        "        q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
        "        loss = loss_function(updated_q_values, q_action)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGjH-s9ZYGUU"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {}\n",
        "\n",
        "def register_model(name, model):\n",
        "    models[name] = model"
      ],
      "metadata": {
        "id": "mrjqzbYOc9Q5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTjlYz3CYGUW"
      },
      "source": [
        "## Deepmind Atari"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EagSZZ1jYGUW"
      },
      "outputs": [],
      "source": [
        "def deepmind_atari(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    \n",
        "    x = Conv2D(32, 8, strides=4, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(inputs)\n",
        "    x = Conv2D(64, 4, strides=4, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    x = Conv2D(64, 3, strides=1, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    x = Dense(512, activation='relu', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "    output = Dense(nb_outputs, activation='linear', kernel_regularizer='l2', bias_regularizer='l2')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=output)\n",
        "\n",
        "register_model('deepmind_atari', deepmind_atari)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrtTS3OdYGUX"
      },
      "source": [
        "## Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "88KAQJ-jYGUY"
      },
      "outputs": [],
      "source": [
        "def xception(input_shape, nb_outputs):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Entry block\n",
        "    x = Rescaling(1.0 / 255)(inputs)\n",
        "    x = Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = Activation(\"relu\")(x)\n",
        "        x = SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        x = MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    \n",
        "    outputs = Dense(nb_outputs, activation='linear')(x)\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "register_model('xception', xception)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A26gdzdYGUl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WRAPPER = 'amiranas'\n",
        "MODEL = 'deepmind_atari'\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 64 * strategy.num_replicas_in_sync\n",
        "EXAMPLES_PER_FILE = 2048\n",
        "\n",
        "CHECKPOINT = '/content/drive/MyDrive/weights/checkpoint'\n",
        "DATASET_DIR = '/home/minerl/tfrecords'"
      ],
      "metadata": {
        "id": "1rIDGfeUOyxV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYOyClORkVBM",
        "outputId": "e1f3c1fa-9b87-4e17-ee65-f2b04f1a3e8e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_expert_data(WRAPPER, EXAMPLES_PER_FILE, DATASET_DIR)"
      ],
      "metadata": {
        "id": "dMeoVc0POveU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5a481f-30d2-48a0-c56c-76528423a281"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 2131/2131 [00:00<00:00, 80134.68it/s]\n",
            "100%|| 1985/1985 [00:00<00:00, 69839.39it/s]\n",
            "100%|| 3615/3615 [00:00<00:00, 12038.18it/s]\n",
            "100%|| 2477/2477 [00:00<00:00, 71603.86it/s]\n",
            "100%|| 2050/2050 [00:00<00:00, 67558.11it/s]\n",
            "100%|| 2792/2792 [00:00<00:00, 84097.53it/s]\n",
            "100%|| 1803/1803 [00:00<00:00, 71093.91it/s]\n",
            "100%|| 2495/2495 [00:00<00:00, 82288.46it/s]\n",
            "100%|| 1606/1606 [00:00<00:00, 76687.22it/s]\n",
            "100%|| 2557/2557 [00:00<00:00, 70903.31it/s]\n",
            "100%|| 2038/2038 [00:00<00:00, 55156.16it/s]\n",
            "100%|| 3097/3097 [00:00<00:00, 81802.07it/s]\n",
            "100%|| 1779/1779 [00:00<00:00, 83105.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /home/minerl/tfrecords/0.tfrecord uploaded to tfrecords_nstep/0.tfrecord.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 2216/2216 [00:00<00:00, 80512.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /home/minerl/tfrecords/1.tfrecord uploaded to tfrecords_nstep/1.tfrecord.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gcs_pattern = 'gs://minerl_data_records/tfrecords_nstep/*.tfrecord'\n",
        "filenames = tf.io.gfile.glob(gcs_pattern)\n",
        "validation_split = 0.1\n",
        "split = len(filenames) - int(len(filenames) * validation_split)\n",
        "train_fns = filenames[:split]\n",
        "validation_fns = filenames[split:]\n",
        "\n",
        "dataset = create_dataset(train_fns, BATCH_SIZE)\n",
        "val_dataset = create_val_dataset(validation_fns, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "M8x0I3mCQ1mc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    model = models[MODEL]((64, 64, 3), 112)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer, loss_fn, metrics=[val_acc_metric])"
      ],
      "metadata": {
        "id": "J_GyEeck31hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models[MODEL]((64, 64, 3), 112)\n",
        "model_target = models[MODEL]((64, 64, 3), 112)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00001)\n",
        "loss_fn = keras.losses.Huber()"
      ],
      "metadata": {
        "id": "qA2UkaYWgcTQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(CHECKPOINT)"
      ],
      "metadata": {
        "id": "nGPLAxsatOWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CHECKPOINT, save_weights_only=True, save_best_only=True)"
      ],
      "metadata": {
        "id": "1rNJwmVVjOIx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "validation_steps = len(validation_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "\n",
        "history = fit(model, model_target, loss_fn, optimizer, dataset, val_dataset, EPOCHS, steps_per_epoch, validation_steps)"
      ],
      "metadata": {
        "id": "UtyBsx4igJmG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "ad2fc61898534e7892fe0679283b8cc5",
            "077c3867be73485494e502ff40d4f17d",
            "486b6f9993a847e1a68b89695a026e5b",
            "6aef3ab9e4b94b5dbbe3443d0fd56385",
            "7844fbf402ea4de8a7480f1f6f28e0d8",
            "eff2f456642f41a6b131aee1eb126811",
            "5aa41c74a8ae47099696f9ab6972c7fa",
            "c84fd8ba160f4ed68cdd4d6ba4eb1a10",
            "5acca1df2c98463a834109b8aa044748",
            "4aa1963cbd3a4100a803e771e5de0b79",
            "fc88c1823e214d20914defecae0b5ec1",
            "dbed5bf68000471cb34911c6b3acbe10",
            "e5465950bdee4e79b26fe529581f1304",
            "772e6979155947edb38204197899a8e4",
            "be167b5301374fe6a5a828aefd93530f",
            "5312e9b925054669a71bbfce4f92f6fb",
            "820ff9ddb5c04cc1b06d1a14c88d1ae9",
            "afe129fb679a4029a77b1bfc0ae5f90e",
            "f8f1187a8465449882aff33072e84fd9",
            "f78b23a17c594968a76762f1bdd64d51",
            "e5e14f8e0fcc44ed9512a394a6bd4019",
            "7e70abb698fb422ea40641c4026b88e4"
          ]
        },
        "outputId": "7d5be562-bdca-4b5c-9081-0fa6f3f3542b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad2fc61898534e7892fe0679283b8cc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64.0 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dbed5bf68000471cb34911c6b3acbe10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-47b792507ea8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_fns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mEXAMPLES_PER_FILE\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-a77d10ebb610>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, model_target, loss_fn, optimizer, dataset, val_dataset, epochs, steps, val_steps)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mval_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = len(train_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "validation_steps = len(validation_fns) * EXAMPLES_PER_FILE / BATCH_SIZE\n",
        "\n",
        "history = model.fit(dataset, validation_data=val_dataset, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, epochs=EPOCHS, callbacks=[model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "BzhhDNxs38Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['training', 'validation'])\n",
        "\n",
        "plt.subplots(figsize=(10,10))\n",
        "plt.tight_layout()\n",
        "#display_training_curves(history.history['sparse_categorical_accuracy'], history.history['val_sparse_categorical_accuracy'], 'accuracy', 211)\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 212)"
      ],
      "metadata": {
        "id": "mgSV7L5yBDPE",
        "outputId": "6a8b0fb0-aea7-4293-dcd6-4475250d89c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs4AAAFxCAYAAABjmC4RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3yV5f3/8deVQUJICIGEHYYQIEKYYYngRgqKyrZq1bqKtmqt9mvt19r6037VWqpWxT3qYAjiKm5RQPYesvcmCYQkkJ3r98d1gAgZJ5BzTsb7+Xjkwcm5r/s+n6QW3uc61/25jLUWEREREREpW1CgCxARERERqQ4UnEVEREREvKDgLCIiIiLiBQVnEREREREvKDiLiIiIiHhBwVlERERExAsKziIi1Zwx5i1jzGNejt1ujLn0bK8jIlIbKTiLiIiIiHhBwVlERERExAsKziIifuBZIvGAMWaVMeaoMeZ1Y0wTY8znxphMY8w3xpiYYuOHG2PWGmPSjTHfG2MSix3rYYxZ5jlvChB+ymtdYYxZ4Tl3njGm6xnWfJsxZrMx5pAx5hNjTHPP88YY8y9jzEFjTIYxZrUxpovn2FBjzE+e2vYYY+4/o1+YiEgVpOAsIuI/I4HLgA7AlcDnwENAHO7v47sBjDEdgEnAvZ5jM4FPjTF1jDF1gI+Ad4CGwAee6+I5twfwBnAH0Ah4GfjEGBNWkUKNMRcD/weMAZoBO4DJnsODgUGenyPaMybNc+x14A5rbRTQBfiuIq8rIlKVKTiLiPjPv621B6y1e4A5wEJr7XJrbQ4wA+jhGTcW+K+19mtrbT7wNFAXOA/oB4QCz1hr862104DFxV7jduBla+1Ca22htfZtINdzXkVcB7xhrV1mrc0F/gT0N8a0AfKBKKATYKy166y1+zzn5QPnGmPqW2sPW2uXVfB1RUSqLAVnERH/OVDscXYJ30d6HjfHzfACYK0tAnYBLTzH9lhrbbFzdxR73Br4g2eZRroxJh2I95xXEafWkIWbVW5hrf0OeB54AThojHnFGFPfM3QkMBTYYYz5wRjTv4KvKyJSZSk4i4hUPXtxARhwa4px4XcPsA9o4XnuuFbFHu8CHrfWNij2FWGtnXSWNdTDLf3YA2Ctfc5a2ws4F7dk4wHP84uttVcBjXFLSqZW8HVFRKosBWcRkapnKjDMGHOJMSYU+ANuucU8YD5QANxtjAk1xowA+hQ791XgN8aYvp6b+OoZY4YZY6IqWMMk4GZjTHfP+ui/45aWbDfG9PZcPxQ4CuQARZ412NcZY6I9S0wygKKz+D2IiFQpCs4iIlWMtXYDcD3wbyAVdyPhldbaPGttHjACuAk4hFsP/WGxc5cAt+GWUhwGNnvGVrSGb4CHgem4We52wDjP4fq4gH4Yt5wjDfiH59gNwHZjTAbwG9xaaRGRGsH8fJmciIiIiIiURDPOIiIiIiJeUHAWEREREfGCgrOIiIiIiBcUnEVEREREvKDgLCIiIiLihZBAF1BRsbGxtk2bNoEuQ0RERERqqKVLl6Zaa+NOfb7aBec2bdqwZMmSQJchIiIiIjWUMWZHSc9rqYaIiIiIiBcUnEVEREREvKDgLCIiIiLihWq3xllERESkNsrPz2f37t3k5OQEupQaIzw8nJYtWxIaGurVeAVnERERkWpg9+7dREVF0aZNG4wxgS6n2rPWkpaWxu7du2nbtq1X52iphoiIiEg1kJOTQ6NGjRSaK4kxhkaNGlVoBl/BWURERKSaUGiuXBX9ffo0OBtjthtjVhtjVhhjTmu+bJznjDGbjTGrjDE9fVmPiIiIiJy59PR0XnzxxQqfN3ToUNLT08sc85e//IVvvvnmTEvzC3/MOF9kre1urU0u4dgvgATP1+3ARD/UIyIiIiJnoLTgXFBQUOZ5M2fOpEGDBmWOefTRR7n00kvPqj5fC/RSjauA/1hnAdDAGNMswDWJiIiISAkefPBBtmzZQvfu3enduzcDBw5k+PDhnHvuuQBcffXV9OrVi86dO/PKK6+cOK9Nmzakpqayfft2EhMTue222+jcuTODBw8mOzsbgJtuuolp06adGP/II4/Qs2dPkpKSWL9+PQApKSlcdtlldO7cmVtvvZXWrVuTmprqt5/f1101LPCVMcYCL1trXznleAtgV7Hvd3ue2+fjuirMWgtobZGIiIgE3t8+XctPezMq9ZrnNq/PI1d2LnPME088wZo1a1ixYgXff/89w4YNY82aNSe6Urzxxhs0bNiQ7OxsevfuzciRI2nUqNHPrrFp0yYmTZrEq6++ypgxY5g+fTrXX3/9aa8VGxvLsmXLePHFF3n66ad57bXX+Nvf/sbFF1/Mn/70J7744gtef/31yvsFeMHXM87nW2t74pZk3GWMGXQmFzHG3G6MWWKMWZKSklK5FXph5a50zn9yFit2lb02R0RERKQ26dOnz89auT333HN069aNfv36sWvXLjZt2nTaOW3btqV79+4A9OrVi+3bt5d47REjRpw2Zu7cuYwbNw6AIUOGEBMTU4k/Tfl8OuNsrd3j+fOgMWYG0AeYXWzIHiC+2PctPc+dep1XgFcAkpOTrc8KLkV8wwj2HslmzqZUerTy7/9AIiIiIqcqb2bYX+rVq3fi8ffff88333zD/PnziYiI4MILLyyx1VtYWNiJx8HBwSeWapQ2Ljg4uNw11P7isxlnY0w9Y0zU8cfAYGDNKcM+AX7l6a7RDzhira1yyzQa1qtDUotoZm/0/2y3iIiISFURFRVFZmZmiceOHDlCTEwMERERrF+/ngULFlT66w8YMICpU6cC8NVXX3H48OFKf42y+HLGuQkww7MmOAR431r7hTHmNwDW2peAmcBQYDNwDLjZh/WclUEJcUz8YQsZOfnUD/duW0YRERGRmqRRo0YMGDCALl26ULduXZo0aXLi2JAhQ3jppZdITEykY8eO9OvXr9Jf/5FHHuHaa6/lnXfeoX///jRt2pSoqKhKf53SmOM3vVUXycnJdsmS01pC+9zCrWmMfWUBL9/Qi8s7N/X764uIiEjttm7dOhITEwNdRkDl5uYSHBxMSEgI8+fPZ/z48axYseKsrlnS79UYs7SkVsq+7qpRY/RoFUO9OsHM2ZSi4CwiIiISADt37mTMmDEUFRVRp04dXn31Vb++voKzl+qEBNG/XSyzN/qvV6CIiIiInJSQkMDy5csD9vqB3gClWhnUIZadh46xI+1ooEsRERERET9TcK6AgQlxAMzepFlnERERkdpGwbkC2jSKoGVMXeaoLZ2IiIhIraPgXAHGGAZ1iGPeljTyC4sCXY6IiIiI+JGCcwUNSoglK7dA22+LiIiIlCMyMhKAvXv3MmrUqBLHXHjhhZTXaviZZ57h2LFjJ74fOnQo6en+z2IKzhXUv10sQQYt1xARERHxUvPmzZk2bdoZn39qcJ45cyYNGjSojNIqRMG5gqLrhtI9voFuEBQREZFa58EHH+SFF1448f1f//pXHnvsMS655BJ69uxJUlISH3/88Wnnbd++nS5dugCQnZ3NuHHjSExM5JprriE7O/vEuPHjx5OcnEznzp155JFHAHjuuefYu3cvF110ERdddBEAbdq0ITXVZbEJEybQpUsXunTpwjPPPHPi9RITE7ntttvo3LkzgwcP/tnrnCn1cT4DgzrE8dy3m0g/lkeDiDqBLkdERERqm88fhP2rK/eaTZPgF0+UOWTs2LHce++93HXXXQBMnTqVL7/8krvvvpv69euTmppKv379GD58OMaYEq8xceJEIiIiWLduHatWraJnz54njj3++OM0bNiQwsJCLrnkElatWsXdd9/NhAkTmDVrFrGxsT+71tKlS3nzzTdZuHAh1lr69u3LBRdcQExMDJs2bWLSpEm8+uqrjBkzhunTp3P99def1a9IM85nYGBCHEUWftycFuhSRERERPymR48eHDx4kL1797Jy5UpiYmJo2rQpDz30EF27duXSSy9lz549HDhwoNRrzJ49+0SA7dq1K127dj1xbOrUqfTs2ZMePXqwdu1afvrppzLrmTt3Ltdccw316tUjMjKSESNGMGfOHADatm1L9+7dAejVqxfbt28/y59eM85npFvLaKLCQ5izKYVhXZsFuhwRERGpbcqZGfal0aNHM23aNPbv38/YsWN57733SElJYenSpYSGhtKmTRtycnIqfN1t27bx9NNPs3jxYmJiYrjpppvO6DrHhYWFnXgcHBxcKUs1NON8BkKCgxjQLpbZG1Ow1ga6HBERERG/GTt2LJMnT2batGmMHj2aI0eO0LhxY0JDQ5k1axY7duwo8/xBgwbx/vvvA7BmzRpWrVoFQEZGBvXq1SM6OpoDBw7w+eefnzgnKiqKzMzM0641cOBAPvroI44dO8bRo0eZMWMGAwcOrMSf9uc043yGBnWI44u1+9mScpT2jSMDXY6IiIiIX3Tu3JnMzExatGhBs2bNuO6667jyyitJSkoiOTmZTp06lXn++PHjufnmm0lMTCQxMZFevXoB0K1bN3r06EGnTp2Ij49nwIABJ865/fbbGTJkCM2bN2fWrFknnu/Zsyc33XQTffr0AeDWW2+lR48elbIsoySmus2YJicn2/J6/fnDrkPHGPjULB658lxuHtA20OWIiIhIDbdu3ToSExMDXUaNU9Lv1Riz1FqbfOpYLdU4Q/ENI2gbW485aksnIiIiUisoOJ+FgQmxzN+SRm5BYaBLEREREREfU3A+C4MS4sjOL2TpjsOBLkVEREREfEzB+Sz0a9eIkCCj5RoiIiLiF9Xt3rSqrqK/TwXnsxAZFkLP1jHM2ZQS6FJERESkhgsPDyctLU3huZJYa0lLSyM8PNzrc9SO7iwNSojl6a82kpqVS2xkWPkniIiIiJyBli1bsnv3blJSNGFXWcLDw2nZsqXX4xWcz9KgDnE8/dVGftycylXdWwS6HBEREamhQkNDadtWLXADSUs1zlLn5tHERIQye6PWOYuIiIjUZArOZyk4yDCgfSxzNmn7bREREZGaTMG5EgxKiONgZi4bDpy+h7qIiIiI1AwKzpVgYIdYAOZouYaIiIhIjaXgXAmaRdcloXEks9WWTkRERKTGUnCuJAMT4li07RA5+dp+W0RERKQmUnCuJIM6xJJbUMSibYcCXYqIiIiI+ICCcyXp27YRdYKDtIugiIiISA2l4FxJ6tYJpnfbGOZs0g2CIiIiIjWRgnMlGpgQx/r9mRzMyAl0KSIiIiJSyRScK9GghDgAZmvWWURERKTGUXCuRJ2aRhEbGaZ1ziIiIiI1kIJzJQoKMgxMiGXuplSKirT9toiIiEhNouBcyQYmxJJ2NI+f9mUEuhQRERERqUQKzpXs/AS3/bZ2ERQRERGpWRScK1njqHASm9VnzkbdICgiIiJSk/g8OBtjgo0xy40xn5Vw7CZjTIoxZoXn61Zf1+MPgxJiWbLjEMfyCgJdioiIiIhUEn/MON8DrCvj+BRrbXfP12t+qMfnBibEkV9oWbhV22+LiIiI1BQ+Dc7GmJbAMKBGBGJvJbeJITw0iB82ap2ziIiISE3h6xnnZ4A/AkVljBlpjFlljJlmjIkvaYAx5nZjzBJjzJKUlACF0ZSNUJDn1dDw0GD6tm2kfs4iIiIiNYjPgrMx5grgoLV2aRnDPgXaWGu7Al8Db5c0yFr7irU22VqbHBcX54Nqy7FtDrzQG7Z85/UpAxNi2ZJylD3p2T4sTERERET8xZczzgOA4caY7cBk4GJjzLvFB1hr06y1uZ5vXwN6+bCeM9eqH9RtCKs/8PqUQR1cwJ+rWWcRERGRGsFnwdla+ydrbUtrbRtgHPCdtfb64mOMMc2KfTucsm8iDJzgUOh8NWyYCblZXp2S0DiSpvXDma22dCIiIiI1gt/7OBtjHjXGDPd8e7cxZq0xZiVwN3CTv+vxWtJoyD8GGz73argxnu23N6dSqO23RURERKo9vwRna+331torPI//Yq39xPP4T9baztbabtbai6y16/1RzxmJ7wf1W8LqqV6fMrBDHEey81m954gPCxMRERERf9DOgd4KCoKkkbD5Wzjq3fKL89vHYgzMUVs6ERERkWpPwbkiksaALYSfPvJqeMN6dUhqEc1s3SAoIiIiUu0pOFdEk84Qlwirp3l9ysCEWJbtTCczJ9+HhYmIiIiIryk4V4QxkDQKds6H9J1enTIwIY7CIsv8LWk+Lk5EREREfEnBuaKSRrk/vZx17tkqhnp1gpmzSW3pRERERKozBeeKimkD8X29Ds51QoLo366R1jmLiIiIVHMKzmciaTQcXAsH1no1fGBCHDvSjrEj7aiPCxMRERERX1FwPhPnXg0m2OtZ54EJsQBariEiIiJSjSk4n4nIOGh3kQvOtvxdAdvG1qNFg7rM0XINERERkWpLwflMJY2GIzth18JyhxpjGNQhjnmb08gvLPJDcSIiIiJS2RScz1SnYRBSF1Z/4NXwQQmxZOYWsHJXuo8LExERERFfUHA+U2FR0PEXsHYGFJa/ucl57WIJMjBb65xFREREqiUF57ORNBqOpcHW78sdGh0RSvf4BlrnLCIiIlJNKTifjfaXQngDr5drDEyIY+WudI4c0/bbIiIiItWNgvPZCKkDna+GdZ9BXvk9mgd1iKXIwo9btFxDREREpLpRcD5bSaMh/yhs+Lzcod1aNiAqPETLNURERESqIQXns9XqPIhq7tVmKCHBQQxoF8vsjalYL/o/i4iIiEjVoeB8toKCIGkkbP4ajh0qd/jADrHsSc9ma6q23xYRERGpThScK0PSaCgqgJ8+KnfooIQ4AOZs1HINERERkepEwbkyNO0KsR29Wq4R3zCCNo0imKN+ziIiIiLVioJzZTDGzTrv+BGO7C53+KAOcczfmkZegbbfFhEREakuFJwrS9JI9+ea6eUOHZgQx7G8QpbuOOzjokRERESksig4V5aG50CLZK82Q+l3TkNCgoza0omIiIhUIwrOlanrGNi/Gg6uL3NYVHgoPVvFaJ2ziIiISDWi4FyZOl8DJsirWedBHWJZs/cIaVm5fihMRERERM6WgnNlimwM51zognM5G5xc1Kkx1sLM1fv8UpqIiIiInB0F58qWNBrSd8DuJWUO69w8ms7N6zN58S4/FSYiIiIiZ0PBubJ1ugJCwr1arjGudzxr92awZs8RPxQmIiIiImdDwbmyhdeHDkNg7YdQWFDm0OHdWxAWEsTkxTv9VJyIiIiInCkFZ19IGg1HU2Db92UOi64byrCkZny8fC/ZeYX+qU1EREREzoiCsy8kXAZh0V5twT22dzyZuQW6SVBERESkilNw9oWQMDh3OKz7FPKzyxzap21D2sbWY4puEhQRERGp0hScfaXrGMjLgg2flznMGMPY3vEs2n6ILSlZfipORERERCpKwdlXWg+AqGZeLdcY0bMFIUGGqUs06ywiIiJSVSk4+0pQMHQZCZu+guzDZQ5tHBXOJYmNmb50N/mFRX4qUEREREQqQsHZl5JGQVE+/PRJuUPH9o4nNSuPb9cd9ENhIiIiIlJRCs6+1Kw7NGrv1WYogxLiaFo/nCnq6SwiIiJSJfk8OBtjgo0xy40xn5VwLMwYM8UYs9kYs9AY08bX9fiVMZA0BrbPhYy9ZQ4NCQ5idHJLftiYwt70sjtxiIiIiIj/+WPG+R5gXSnHbgEOW2vbA/8CnvRDPf6VNAqwsGZ6uUPHJMdTZGHa0t2+r0tEREREKsSnwdkY0xIYBrxWypCrgLc9j6cBlxhjjC9r8rtG7aB5T6+Wa8Q3jOD89rFMWbyLoiLrh+JERERExFu+nnF+BvgjUFqriBbALgBrbQFwBGjk45r8L2k07FsJKRvLHTq2dzx70rP5cUuqHwoTEREREW/5LDgbY64ADlprl1bCtW43xiwxxixJSUmphOr8rMsIMEGwpvyezoM7N6FBRCiTtZOgiIiISJXiyxnnAcBwY8x2YDJwsTHm3VPG7AHiAYwxIUA0kHbqhay1r1hrk621yXFxcT4s2UeimkLbQbBqKtiyl2CEhQQzokdLvlq7n0NH8/xUoIiIiIiUx2fB2Vr7J2ttS2ttG2Ac8J219vpThn0C3Oh5PMozpmYu7k0aDYe3wZ5l5Q4d2zue/ELLjOV7/FCYiIiIiHjD732cjTGPGmOGe759HWhkjNkM3Ac86O96/CbxSggO8+omwY5No+jRqgFTFu+kpr6PEBEREalu/BKcrbXfW2uv8Dz+i7X2E8/jHGvtaGtte2ttH2vtVn/UExDh0dBhsGtLV1RY7vCxyfFsPJDF8l3pfihORERERMqjnQP9KWkMHD0I234od+gV3ZoTUSeYKYt0k6CIiIhIVaDg7E8JgyGsPqwuv7tGZFgIV3Ztzqer9pKVW+CH4kRERESkLArO/hQaDonD4adPIL/8bbXH9onnWF4hn60se7tuEREREfE9BWd/SxoFeZmw6atyh/aIb0CHJpHq6SwiIiJSBSg4+1vbQRDZxKvuGsYYxvZuxYpd6azfn+GH4kRERESkNArO/hYUDF1GwsYvIbv8jhnX9GhBneAgpmjWWURERCSgFJwDIWkUFObBuk/LHdqwXh0Gd27CjOV7yC0ov42diIiIiPiGgnMgNO8JDc/xarkGwLjerUg/ls9Xaw/4uDARERERKY2CcyAY47bg3jYbMsrvmHFeu0a0jKmr5RoiIiIiAaTgHCjdrnUBesGL5Q4NCjKMSY5n7uZUdh065ofiRERERORUCs6B0rCtm3Ve/AYcTSt3+KheLQkyMHWJZp1FREREAkHBOZDOvw/yj8HCieUObd6gLhd0iOODJbspKCzyQ3EiIiIiUpyCcyA17gTnDoeFL3vVmm5s71bsz8hh9qYUPxQnIiIiIsUpOAfawPshNwMWv1ru0EsSGxMbWYfJi7RcQ0RERMTfFJwDrVlX6DAE5r8IuVllDg0NDmJkr5Z8u/4gBzNz/FSgiIiIiICCc9Uw8H7IPgRL3yx36NjkeAqLLNOX7vFDYSIiIiJynIJzVRDfG865EOb9G/Kzyxx6Tlwkfdo2ZOqSXVhr/VKeiIiIiCg4Vx2DHoCsA7D83XKHjusdz7bUoyzadsgPhYmIiIgIKDhXHa0HQKv+MPcZKMgrc+gvujQjKjxEOwmKiIiI+JGCc1VhDAy6HzJ2w8pJZQ6tWyeYq7o357+r93EkO99PBYqIiIjUbgrOVUm7S6B5D5g7AQoLyhw6rncrcguK+GSFbhIUERER8QcF56rEGBj0Rzi8HdZML3NolxbRdG5en8lariEiIiLiFwrOVU2HIdCkC8x5GorK3lp7XO941u7NYM2eI34qTkRERKT2UnCuaoKCYOAfIHUjrPukzKHDu7cgLCSIyYt3+qk4ERERkdpLwbkqOvcqaJQAs5+GMno1R9cNZVhSMz5evpfsvEI/FigiIiJS+yg4V0VBwW7W+cBq2PhlmUPH9o4nM7eAmav3+ak4ERERkdpJwbmqShoFDVrD7H+UOevcp21D2sbWY8oS3SQoIiIi4ksKzlVVcCic/3vYswS2fl/qMGMMY3vHs2jbIbamZPmvPhEREZFaRsG5Kuv+S4hq7tY6l2FEzxaEBBnNOouIiIj4kIJzVRYSBgPugR1zYce8Uoc1jgrnksTGTF+6m/zCslvYiYiIiMiZUXCu6nr+CurFlTvrPLZ3PKlZeXy77qCfChMRERGpXRScq7o6EdD/t7DlW9iztNRhgxLiaFo/nCnq6SwiIiLiEwrO1UHvWyC8Acz+Z6lDQoKDGJ3ckh82prAz7ZgfixMRERGpHRScq4OwKOh3J2z4L+xfU+qw6/u1pk5IEM98s9GPxYmIiIjUDgrO1UXf26FOFMwpfa1zk/rh3HReW2as2MP6/Rl+LE5ERESk5lNwri7qxkCf22DtR5BS+ozy+AvaERkWwtNfbvBjcSIiIiI1n1fB2RhzjzGmvnFeN8YsM8YM9nVxcor+d0FoXZg7odQh0RGh/OaCdnyz7iBLth/yY3EiIiIiNZu3M86/ttZmAIOBGOAG4ImyTjDGhBtjFhljVhpj1hpj/lbCmJuMMSnGmBWer1sr/BPUJvViIfnXsGoqHNpW6rCbB7QhLiqMp77YgC1ju24RERER8Z63wdl4/hwKvGOtXVvsudLkAhdba7sB3YEhxph+JYybYq3t7vl6zct6aq/+v4WgEPjxmVKHRNQJ4e5LEli0/RDfb0zxY3EiIiIiNZe3wXmpMeYrXHD+0hgTBZS5RZ11sjzfhnq+NP15tuo3g543wPL34MieUoeNTY6nVcMInvpiA0VF+rWLiIiInC1vg/MtwINAb2vtMVwIvrm8k4wxwcaYFcBB4Gtr7cISho00xqwyxkwzxsR7W3itNuAewMK850odUickiD8M7sC6fRl8umqv/2oTERERqaG8Dc79gQ3W2nRjzPXA/wJHyjvJWltore0OtAT6GGO6nDLkU6CNtbYr8DXwdknXMcbcboxZYoxZkpKipQc0aAXdxsHStyCr9C22r+zanE5No5jw9UbyC8v8gEBEREREyuFtcJ4IHDPGdAP+AGwB/uPti1hr04FZwJBTnk+z1uZ6vn0N6FXK+a9Ya5OttclxcXHevmzNdv59UJgH858vdUhQkOF/hnRiR9oxpize5cfiRERERGoeb4NzgXXtGa4CnrfWvgBElXWCMSbOGNPA87gucBmw/pQxzYp9OxxY523htV6jdtBlJCx+HY6V3nbuwo5x9GnTkGe/3UR2XqEfCxQRERGpWbwNzpnGmD/h2tD91xgThFvnXJZmwCxjzCpgMW6N82fGmEeNMcM9Y+72tKpbCdwN3FTxH6EWG/gHyMuChS+VOsQYwx+HdCQlM5c355Xewk5EREREyma86fNrjGkK/BJYbK2dY4xpBVxorfV6uUZlSU5OtkuWLPH3y1ZdU66HbbPh3tUQHl3qsFveWszi7YeY88eLiY4o7z2PiIiISO1ljFlqrU0+9XmvZpyttfuB94BoY8wVQE4gQrOUYOD9kHMEFpfdAvv+yzuSmVvAS7O3+KkwERERkZrF2y23xwCLgNHAGGChMWaULwsTLzXvDgmDYf4LkHe01GGJzepzdfcWvPnjNg5k5MhxZYoAACAASURBVPixQBEREZGawds1zn/G9XC+0Vr7K6AP8LDvypIKGfQAHEtz7enK8PtLO1BQaHnu203+qUtERESkBvE2OAdZa4s3DE6rwLnia/F9oO0g+PE5yC99NrlVowh+2bcVkxfvYltq6bPTIiIiInI6b8PvF8aYL40xNxljbgL+C8z0XVlSYYMegKz9sPydMof99uL21AkOYsLXG/1UmIiIiEjN4O3NgQ8ArwBdPV+vWGv/x5eFSQW1GQjxfeHHZ6Egt9RhjaPCueX8tny6ci9r95a7+aOIiIiIeHi93MJaO91ae5/na4Yvi5IzYAxc9BAc2QUzHyhz6G2DziG6bij/+HKDn4oTERERqf7KDM7GmExjTEYJX5nGmAx/FSleOudCtynKsrdhyZulDouuG8qdF7bj+w0pLNia5rfyRERERKqzMoOztTbKWlu/hK8oa219fxUpFXDRn6H9pW7WedeiUofdeF4bmtQP46kv1uPNJjgiIiIitZ06Y9Q0QcEw8jWIbgFTfwWZB0ocFh4azL2XdmDZznS+XXewxDEiIiIicpKCc01UNwbGvud2FPzgRijIK3HY6F4taRtbj398uYHCIs06i4iIiJRFwbmmatoFhv8bds6HLx8qcUhIcBB/GNyBDQcy+XjFHj8XKCIiIlK9KDjXZEmj4LzfweJXYfl7JQ4Z2qUZXVrUZ8LXG8ktKPRzgSIiIiLVh4JzTXfJX6HtBfDZ72HPstMOBwUZ/nh5J3YfzmbSwp3+r09ERESkmlBwrumCQ2DUmxDZBKbcAEdTTxsyMCGW/uc04vlZmzmaWxCAIkVERESqPgXn2qBeIxj7DhxLhQ9ugsKfh2NjDA8M6UhqVh5vzN0WmBpFREREqjgF59qieXe48lnYPge+eeS0wz1bxTD43Ca8Mnsrh46W3IVDREREpDZTcK5Nuo2DPnfA/Odh1QenHb7/8o4czStg4vebA1CciIiISNWm4FzbXP44tDoPPvkd7F/9s0MdmkQxomdL3p6/g73p2QEqUERERKRqUnCubYJDYczbbpOUydfBsUM/O3zvpQlg4blvNwWoQBEREZGqScG5Nops7G4WzNwH02+BopP9m1vGRHBdv1ZMXbKLzQezAlikiIiISNWi4FxbtUyGoU/Dlu/gu//3s0N3XdSeuqHBTPh6Q4CKExEREal6FJxrs143Qq+bYe6/YO1HJ56OjQzj1oHnMHP1flbtTg9ggSIiIiJVh4JzbfeLJ6Flb/joTji47sTTtw5sS0xEKP/4UrPOIiIiIqDgLCFhMOYdCIuEyb+EbDfDHBUeyl0XtWfOplR+3Hz6boMiIiIitY2Cs0D9ZjD6bUjfCR/eDkVFAFzfrzXNo8N56ov1FBXZABcpIiIiElgKzuK07g9DnoBNX8IPTwAQHhrMHwZ3ZOXuI7yzYEeACxQREREJLAVnOan3rdD9OvjhSVg/E4ARPVtwUcc4/u/zdWxJUXs6ERERqb0UnOUkY2DYBGjewy3ZSN2EMYYnR3YlPDSY+6aupKCwKNBVioiIiASEgrP8XGg4jH3X3TQ4+ZeQk0Hj+uE8dnUXVu5KZ+L3WwJdoYiIiEhAKDjL6aJbwui3IG0LfDQeioq4omtzhndrzrPfbmLNniOBrlBERETE7xScpWRtB8Lgx2D9ZzB3AgCPXtWZRpF1+P2UFeTkF5ZzAREREZGaRcFZStdvPCSNge8eg/X/pUFEHZ4a1Y1NB7P451faGEVERERqFwVnKZ0xMPw5aNETpt8Ke1dwQYc4ru/XitfmbmPB1rRAVygiIiLiNwrOUrbQujBuEkQ0gknjIGMvDw1NpFXDCO7/YCWZOfmBrlBERETELxScpXxRTeCXUyA3C94fS4TNYcKYbuxNz+axz9YFujoRERERv1BwFu806Qyj34QDa+DD2+gVH81vLmjHlCW7+OanA4GuTkRERMTnFJzFewmXwS+egg0z4eu/cO+lHUhsVp8HP1zNoaN5ga5ORERExKd8FpyNMeHGmEXGmJXGmLXGmL+VMCbMGDPFGLPZGLPQGNPGV/VIJelzG/T9Dcx/njor3mLCmG5kZOfz5xmrsdYGujoRERERn/HljHMucLG1thvQHRhijOl3yphbgMPW2vbAv4AnfViPVJbL/w4Jl8N/7yfx2BJ+f1kHPl+zn49X7A10ZSIiIiI+47PgbJ0sz7ehnq9TpySvAt72PJ4GXGKMMb6qSSpJUDCMeh0aJ8LUG7k9MY9erWN4+OM17DuSHejqRERERHzCp2ucjTHBxpgVwEHga2vtwlOGtAB2AVhrC4AjQKMSrnO7MWaJMWZJSkqKL0sWb4VFwbWTIbQuwZPG8MwVLSgssjzwwSqKirRkQ0RERGoenwZna22htbY70BLoY4zpcobXecVam2ytTY6Li6vcIuXMNYiHaydBVgrxX97CX4a0Ze7mVN5duCPQlYmIiIhUOr901bDWpgOzgCGnHNoDxAMYY0KAaEDb0VUnLXrBiFdg92LG7n2SCxJi+fvMdWxNySr/XBEREZFqxJddNeKMMQ08j+sClwHrTxn2CXCj5/Eo4Dur1gzVz7nD4dK/YtZM54UWXxIWEsx9U1dSUFgU6MpEREREKk2ID6/dDHjbGBOMC+hTrbWfGWMeBZZYaz8BXgfeMcZsBg4B43xYj/jSgHshbTORC/7Jm72eZMSP8bz0wxZ+e3FCoCsTEZFTWQu7F8OK9yH7EDRJgqZJ0LQL1G8Buk9fpESmuk3wJicn2yVLlgS6DClJQR68OwJ2LeSZ5k/z/JY4PrprAF1aRAe6MhERAcjYB6smu8CcuhFCIyCyCRzednJM3Rho0gWadnVBumkSxHaEkDqBq1vEz4wxS621yac9r+AslSr7MLx2GUXH0hiV/yhZ9VrxyW/PJzw0ONCViYjUTgW5sOFzWPEebP4GbBHE94Me10Hna1yXpNxMOPAT7F8FB9bA/tXu+wJPi9GgUIjrdHJWummSC9cRDQP7s4n4iIKz+E/aFnjtEo6FxNAv5UHGDerKQ0MTA12ViEjtsm+VC8urprrlGFHNods46H4dxLYv//yiQvf3efEwvX8NZO0/OaZ+y58H6aZJENMWgvzSe0DEZxScxb92zIO3h7MlIolfpN3LO7edT99zTmvRLSIileloGqz+AFa864JucB3oNAy6Xw/tLnIbWJ2trIOeGeliYTp1I9hCd7xOJHS4HC5+GBq2PfvXEwkABWfxv5WTYcYdfBZ8KU/WuZPP772AyDBf3o8qIlILFRbAlm9h+btuSUZRPjTrDj2uhy4j/bOcIj8bDq5zYXrPMvf3f1EB9L0DBt3v1k2LVCMKzhIY3z0Os5/iiYJrOdLzTv5vRNdAVyQiUjOkbHQzyyunuOUTEbHQdaxbu9ykc2Bry9gLsx6H5e9BeDRc8D/Q+9aqcYNhURFs+goWvwZtzofz7tbSEjmNgrMEhrUw7dfYtTP4Td49jP3VnVzcqUmgqxIRqZ5yMmDth252efdiMMFuWUT36yBhcNUIpsXtXw1fPQxbZ7m1z5f9DRKHB6bdXUGuW8Yy79+Qsh7CoiH3CHQcBtdMdAFfxEPBWQInP5uit64gb88qbgv+fzx7369pWK+K/eUuIlKVWQuz/wFzJrhOF3GdXFjuOhaiqvhkhLWw+Vv46n8hZR3E94XBj0N8b/+8fs4RWPImLJjoZuabJMGAu11HkcWvw1d/hgatYey70ORc/9Qk5Tv+yUDHUzed9g8FZwmsrIPkvXwx6RmZPNv2JR67cQhGDfZFRMpnLXz3GMx5Gs69Cs67B1r0rH6blBQWuKUl3z0ORw9C5xFw6SMQ08Y3r3dkDyx4EZa+DXmZcM6FMOAeOOein//udsyHD250LfmG/xuSRvmmHvFe5n6YcQds/R5u/BTaDvJ7CQrOEngH15H78iVszW/E1iunM6x3h0BXJCJS9c36O/zwJPS8Ea54pvqvx83NgnnPwY/PuU4cfW6v3BsID6x1yzFWf+DedHQZAef9Dpp1K/2czP3wwc2wcx70HQ+D/x8Eh1ZOPVIxG7+Ej8ZD3jH4xZPQ81cBeZOo4CxVQuGmb+G9UcwniWa/fo92reIDXZKISNX1/RPw/f9Bjxvgyueqf2guLmOvm31e8R7UbeBuIEy+5czWaVsL2+e4ML75a7cjYs8bod94iGnt3TUK8+Hrv7hZ6lb9YfRbENW04rXImcnPgW8egYUvueU0o16HuI4BK0fBWaqMQ3Neo/63D5BONMFXPUtMj6sCXZKISNXzw1OuM0X362D48zUrNBe3f7Vb/7z1+4rfQFhYAOs+gR+fhX0roF6ca4GXfMuZt+FbPQ0++Z3bUXH029C6/5ldR7yXsgGm3QIHVkPf38Clf4PQ8ICWpOAsVcrmFXMonHEnHc1O8s8dRegV/9DWrSIix81+Gr77f9DtWrjqhcrZuKQqO+0Gwn5w+ePQ8rTc4uQdda3u5j8P6TugUXvo/1v3+6qMwHXgJ5hyvbv24MdcmAvUmvIje9yMfJ16gXl9X7IWlr0Nnz8IdSLg6omuS0wVoOAsVc4PP+1mxaS/cFfwRwTXa4gZ9k9344uISG02ZwJ8+zfXMePqiTU/NBd36g2EXUbCJX85eQPh0VRY9AosetVtI96yj7vhr+PQyp+RzzkCM8bDhv9Cl1Ew/Dn/hdeCPDeTvvg12DkfMO7NQdMkaNbV/dm0G0TG+aceX8g+DJ/eAz997G7cvOblKrU0RsFZqqQpi3fy1oef8Wr0G7TM2QTnXg1Dn67efxmIiJypH59162yTRrsgUZtCc3G5mW698rx/n7yBMD/brYcuyHG9lwfcDa36+baOoiL48V+uq0lcJ9eyrlE7373ekT2w9C33dfSge8PQ81du/fX+1bBvFRzZeXJ8ZNNTwnRXt9ylqi/r2TEfpt/q2gNe/HCV3IRGwVmqrAlfb+TFb9fxdsf5DNj9ultXNvQfrlVRdWu3JCLVh7VweLtbG1tU6N64B4cErp55/3ZLFbqMhGteCWwtVUXxGwiDQ6HbOOj/O4jzc1emLbNg2q/dNuLXvASdhlXeta2FbbNh8auwfibYIreZTZ/boN0lpwfK7MOwfw3sX3UyTKesd28wAOpEQdMuJ4N00yRonAghYZVX85kqLHBtFX940vXOHvU6tOgV6KpKpOAsVZa1lgemrWLa0t28NDiCIZsfhb3LoNMVMGxC1W/uLyJVn7VwZBfsXQ57V3j+XA456SfHNE2CYf/y38Ycxc1/Ab58yIX3ka8rNJ/q8A7XKSOQn0am74KpN7j/bs6/Dy7+37P7RCAnA1ZOdssxUje4dnw9boDkX0PDthW7Vn6OWxt+PEjvXw0H1kBeljseFOJmzI+H6WZdoUWyf2/AS98FH97mlp50HQfDnnYTZVWUgrNUafmFRfz6rcXM25LGG7/qwQVpU90sQ2hd18ex61jNPouId6yFjD0/D8j7VsCxNHc8KAQanwvNe3i+urtg9uVDboaz141wySP+u2F5wUvwxf+4ThKj3lD/4KosPwc+/6O7oe2cC2HkG1CvUcWuceAnF5ZXTXHBtnkP6H2b6zcdWrfyai0qgsPbYN9KF6SPz1BnHXDHQyPcz5Aw2H1Ft6i81z7V2o/g07vdJzvDJkC3sb57rUqi4CxVXmZOPmNfXsCOtKNMuaM/XcIOwsd3wa6F0GEIXPEvqN880GWKSFWTse9kOD4elI+muGMm2BOSu50Myo07lzzTlpvp+iYvmOi6GFz2KHT7pW/XXi56FWbe7z5hG/2WQnN1sew/8N/7IbIxjHm7/OUGhfmw7lMXmHf8CMFhbklOn1v9v1Qh84D7VHfT125L6yO73PNNkqCDJ0S37F056+vzjsIXf3JvNFr0gpGvQcNzzv66fqDgLNXCgYwcRrw4j7zCImbceR4to8Ng4cvw7aMQXMe1J+pxvWafRSpbQS7sWeruam/QumrelFZUCEd2u/WcxZdcZO13x02Q+zj6eEBu1t2t9azoLN6BtfDZfbBrgdsIY9gEaHJu5f88i1+D//7B3eg2+q0z2/hDAmfPMpj6KzeDO/Rp90nFqTL2nbzZL2s/NGjlekz3uKHiM9W+YC0cXOcC9KavYOcCt1a6bgy0vxQSLof2l5zZpy/7V7t14amb4Px74aI/V6s3hgrOUm1sPJDJqInzaFw/nOm/OY/oiFBI2+Ia0u/40d0sceWz0EC7Dko1kLbFdUloPcC96QuvH+iKfi430/2jPv8FyNznnguu42aFGrWH2ARolOD5s71/li8cOwRpm90/uGmbIW2T+z2mbYHCXM8g43YVOx6Qm/dwIbmy2oUVFcHK9+Grh11bsv53wgUPQlhk5Vx/yRvw2e+hwy9gzH8Umquro2kw/RbYOsuF4aFPu5vwts91N/ut+8zd7Nf+UnezX/tLq+ab0uOyD8OW72DjV24HxmNp7g1pyz6e2ejLoUnnsievrHUTXl8/DHUbwoiX3ZKQakbBWaqVBVvT+NXri+jeqgH/+XUfwkOD3T9ki1+Db/7q/o88+FHodbNmn6Xq2jEPJv8S8o65wBdW37WW6nuHm3kKpKOpbmvbRa+4YNh2kJsJy8uC1I2Q6gmsh7ZBUf7J8yJiT4bo4qE6pk3FZpPyc9z6yxPhePPJsJx96OS4oBDXXis2wbUBa5QAsR3cTU6VFWLLcuyQ+ztn2dtQvwUMeQISrzy7v3eWvuX61yZcDmPfqRrdDuTMFRXCrL+7bhFNklznjZR1EN7AvVnufUu1WZ7wM0WFblZ905ew8Uu3RhqgfktIuMxtVNJ20M/frB5NhY/udOd0GOI276kXG5j6z5KCs1Q7n6zcy92TljOsazP+Pa4HQUGef6gOb3ezz9tmu//TDv/3yeb4IlXFysnw8W/df5vXTXUzOfNfhLUzAOtuBOv/W/93cDi8w+22tuwd1w838QoY8HtoWco6y8ICt3ta6iYXqNM2nQzVx9cRwykBt1iojmriXvPUcHxkl5uJOy6y6Snh2HOdBq2rRoeJXYvc8o0Dq90a0F88VfHOB+B+75/8FtpfBuPeU2iuSdbPdG+I6jfz3Ow30u2GV1Nk7HOz0Bu/dNuj52W5tdptB7o3gZGN3Y2T2elut8U+t1XriS0FZ6mWXv5hC//3+XpuH3QODw1NPHnAWjdr89XD7h/fS/8KvW+tcg3UpRay1s0+zX4K2gx0M4p1Y04eP7LbzfIueQtyj7ibcPrfBZ2u9G1APPAT/PgMrJ7mPrHpNhbOu+fs+uFmH3bLJ1I3emaOPaH60BYozDt9fGg9iG3vAnGj4wHb830Vbkt1QmGB+99u1uNuVnHg/W4TDm/D7/L33A3P7S6Gce/7txWYSGUqyHWfqG36ygXpQ1vc87EdXWeYpl0CW18lUHCWaslay18/Wcvb83fw1yvP5aYBp8zwpO9y7/C3fOvWkF49EWJaB6ZYkfwc+PhOWDPdfUQ77F+lr13NzYIV78OCF92ShehWbglHzxsgPLryatq5AOb+CzZ+4YJr8s3Q707ftp4qKoT0nS5MZx1w/59slOBuPKzGM1AnZOx1revWznChf+jT0O6iss9ZMQk+Gu/Wel47WaFZapa0La5vdPvLaswsu4KzVFuFRZbx7y7l63UHmHhdL4Z0OWUve2vdrlKfP+i+H/oPt7tUTfgHWqqPrBS3nnn3IvcJyIB7vftvsKgQNnzuAvSOH92uXz1vcCH6TJcgWetmgub+y202ULch9BvvPpXxV2/i2mDzt66V3KGt7mP5y//u3hycauUUmHEHnHOBJzRXYq9eEfEJBWep1rLzCvnlawv4aW8G79/Wj16tY04fdHiH+8dp53y3+9YV/1JIEP84uB7eHw1ZB2HEK3DuVWd2nT3LXIBeO8MtQUq80rMOuo935xcWwNoPYe4zcHAtRMfDeb9zs9+V1W1Cfi4/xy2BmTPBdSO5+H/dG5Tjy25WfQAzboc258O1U2rMbJxITafgLNVeWlYuIyfO40h2PtPHn8c5cSXcUV9UCD8+69aY1ouFq1906wlFfGXLdzD1RggJd7OJpd1kVxFH9ri1tEvfdB0vWiS7ddCJw0teB513zH3qMu85t0QiLtH1Te0yslr1Ta3W0rbAzAfcsrGmXd0b9/QdMP1Wt4zsl1P05kWkGlFwlhphR9pRRrw4j3phIXx453nERpZyU87eFfDh7ZC6Afr+xn10ro9HpbItedNtYBHXyQWjyu4tnpsFKye5WehDW90Mct87XEu78Gh3c97i19yWzcdSXa/Vgfe5O9x1o6z/WQs/feR2Ssvc75bqtOoP132g0CxSzSg4S42xYlc6416ZT8cmUUy6vR8RdUrpRJCfDV8/AotedsFmxKvQrKt/i5WaqajQbWoy/3l3M8yoN3y7sUlRobtzff4LsGMu1Il0u3lt/ta1hEoYDOf/3oU0re0PvNxM+OFJd/PyVS/4p9+0iFQqBWepUb7+6QB3vLOEizo25uUbehESXMbs2uZv4KO73A5IF/+vW/NZlXdukqot76j7NGP9Z65X65An/NtneO8KNwO94XO3AcGAe9xmICIiUmkUnKXGeWfBDh7+aA3X9W3FY1d3wZQ103bsEHx6N6z71K03vOalwO/cJtVPxj6YNBb2r3aBue8dga5IRER8oLTgrEVwUm3d0K814y9sx3sLdzLxhy1lD45oCGPegatehH2rYOIAt7NbNXvjKAG0bxW8erG7CezayQrNIiK1kIKzVGsPDO7IVd2b89QXG5ixfHfZg42BHtfB+LnQ+FzXum7azW42WqQsG76AN4a4/4Z+/YVbIiEiIrWOgrNUa0FBhqdGdaX/OY24/4NVTF9aTngGt6nEzTPh4ofd0o2JA2DLLJ/XKtWQtbBgIky+FmIT4LbvtJ5YRKQWU3CWai8sJJhXb0ym3zkN+cMHK3lj7rbyTwoKhkH3w63fuDve37natZDKz/F9wWfKWtevN2MfpGyAXYtg0zewehrsXxPo6mqewgK3K9wXD0LHoe7NVkm7womISK2hmwOlxsgtKOSeSSv4Yu1+7r64Pb+/rEPZNwwel3fMtRZb/KrbOGLkq76bVcw76rp75GS4jS1yjkBuscfFv057PgOK8ku/dqcr4MI/QdMuvqm9NsnJcMt4Nn8D590Nl/5NfZFFRGoRddWQWqGgsIg/z1jDlCW7uKFfa/42vDNBQV72td30DXx8p1vzfMnDbqtjb9rW5We7rZaPpkDWAfc466B7fPRgse8PQv7Rsq8VWs/1Aw6Pdl9hxR6f9nwD97hOPVj3ievxm5sBna+BCx6Exp28+7nl59J3wvtjIXUjDPsn9Lop0BWJiIif+T04G2Pigf8ATQALvGKtffaUMRcCHwPHP1v/0Fr7aFnXVXCW8lhreeLz9bw8eyvDuzXnn2O6EVpWn+fijqbBZ/d42tadDxc95DYzOOoJwlmecFw8JOdmlHytujEQ2QQiG0O9xp7HcRDRqFgYPh6EPcH4bLZHzj4M856HhS+5me2k0XDhg9Co3ZlfszYoyIV9K2HnfNi5ELbPAQyMeRvaXRTo6kREJAACEZybAc2stcuMMVHAUuBqa+1PxcZcCNxvrb3C2+sqOIu3Jn6/hSe/WM+FHeOYeF0v6tbxctMTa2HFe/D5/7hd2YoLi3ZB+PhXveOPm/z8uXpxEFKn8n8obxxNg3nPwqJXXSjsNg4u+KO7KVLcJwq7FrmgvGsh7FkGhbnuWMNzIL6f24UvrkNg6xQRkYAJ+FINY8zHwPPW2q+LPXchCs7iQ5MW7eTPM1bTs1UMr9/Um+i6FZjRPbIH9q9yIfh4IA4N912xlS3rIMx9Bha/BrYQelwPA++HBvGBrsx/rIVDW11APj6jnLrBHQsKgWbdoVU/iO/r/oxsHNh6RUSkSghocDbGtAFmA12stRnFnr8QmA7sBvbiQvTasq6l4CwVNXP1Pu6ZvJx2cZH855Y+NI6qRuG3MmTsgzn/hGVvu+973ggD74P6zQNbly8U5Lk3OzsXwK4FLigfPeiOhUe7gHw8JDfvCXUiAluviIhUSQELzsaYSOAH4HFr7YenHKsPFFlrs4wxQ4FnrbUJJVzjduB2gFatWvXasWOHT2uWmmfOphTueGcpcVFhvHtLX+Ib1sLAlL4L5jwNy98FEwy9b3FLEqrrLKu1rkPJnmUnQ/KepVCQ7Y7HtHHLLlr1hVb9IbajOmOIiIhXAhKcjTGhwGfAl9baCV6M3w4kW2tTSxujGWc5U8t3HuamNxcTFhLEO7f0pWPTqECXFBiHt8MP/4CVkyAkDPrcBufdA/UaBboyx1p3o2Pmfsja7/7M3AeZBzx/Hn/+wMm1yUEh0LSrm0k+vvRCPZdFROQMBeLmQAO8DRyy1t5bypimwAFrrTXG9AGmAa1tGUUpOMvZ2HggkxteX0hOfhFv3tybnq1iAl1S4KRtgR+ehFVTXUu7vr+B/ndBREPfvN7xQJxVLABnFgvGJ54vFoiLC4+GyKYuEEc1g6gm7s8mXaBFT/cziIiIVIJABOfzgTnAaqDI8/RDQCsAa+1LxpjfAuOBAiAbuM9aO6+s6yo4y9nadegYN7y+kAMZubx8Qy8GdYgLdEmBlbIBvn8C1n7o+kP3vwv6jXdBtThrIf9YyZu15ByBnPQyjnk2cylpA5ewaE8IPh6Im54ekCObaj2yiIj4TcC7alQWBWepDCmZufzqjUVsPpjJM2N7MKxrs//f3t1Hx1Xfdx5/f+d5pJFGD5ZsWbIMxkASbMDY4aFJGk7b9BB60pAG8tCnNDlttlu6S5I9p+n27G7T7sk2zdkloZvdJPQ0p9BlSwkhS5cNbQilDjQQsI2xsYltcJAtIUu2nkfSPP/2j3s1GskPjPHDHUmf1zlz5t7fvbr6Sb+5M5/7m9+9N+gqBW9oH/zzn3nXsE60QNc1J9/JsFw88zYiyZOvUV19A5fGjvlAnPLDsnqKRUSkzig4beDv5gAAFkxJREFUiywyMVvgt+97gR19Y3zxts386g29QVepPgy+5F2FY+rYGULw4pu3+ME4Eg+69iIiIudMwVnkFGbzJX7vgZ08deA4f3DLlfzr916GNzxfREREVqrTBWddm0lWtGQszL2/uY0PXruWL//DAf7s8Z+w1A4mRURE5OKIBF0BkaBFwyG+8pFraUlGufeHhxmfyfNfPrSZSFjHlSIiIjJPwVkECIWML/zyVbQ0xLjnyUNMzBa452NbSETDQVdNRERE6oS61ER8ZsZn33cFf/yBd/CP+4b41F+/QCb3JleREBERkRVDwVlkkU++61K+8tFr+PFPR7n96z/ipaPjQVdJRERE6oCCs8gpfGhLD3/1iW2MTuf50P/8F/7k/+5T77OIiMgKp+Ascho3X9nJD/7de/m1G9bz1z96nffdvZ0n9g8FXS0REREJiIKzyBk0J6L859s28fDv/gzNiSi/c/8OfvdvdnJsIht01UREROQiU3AWqcHW9a089m/fzR/cciVPHRjmF+7ezv3Pvk6prGs+i4iIrBQKziI1ioZD/N7NG/n+Z3+WLb0t/KdH9/Hhr/+IVwYng66aiIiIXAQKziJnaX17I/d/6nq++tFrOTo6wwf++zN86fGfMJsvBV01ERERuYAUnEXeAjPjti3d/OBz7+VXruvmG9tf4xe/up0fHjwedNVERETkAlFwFjkHrY0xvnz7NTz46RuJhkP85ree564HX+T4VC7oqomIiMh5puAsch7cuKGdx+96D3f9/OU8vvcYv3D3dh58/ghlnTwoIiKybCg4i5wn8UiYz77vCr5313u4ck0Tf/jIXj5273O8OjwVdNVERETkPFBwFjnPNnamePB3buTPP7yZA0NTvP+ep7n7iYNkCzp5UEREZClTcBa5AEIh46Pv7OUHn3svt27u4i+ePMSt9zzNs6+NBF01EREReYsUnEUuoI6mOPd8bAv3fep6CuUyH//L57jzgV08c+iExj+LiIgsMebc0vrw3rZtm9uxY0fQ1RA5a7P5El976hB/82wfk9ki3S1JPry1hzu29rCurSHo6omIiIjPzHY657adVK7gLHJxZQslvr9/iG/vOMozr57AObhpQzt3bOvh/Zu6SMbCQVdRRERkRVNwFqlDA+OzPLKzn4d39dM3MkMqHuED13Rx+9Z1XNfbgpkFXUUREZEVR8FZpI4553j+p6M8tKOf7+0dZLZQ4rKORu7Yto5f2dJNZ3Mi6CqKiIisGArOIktEJlfke3sGeWjHUXb0jREOGTdf0cEd23r4ubetJhbROb0iIiIXkoKzyBJ0+HiGh3f2851d/QxN5mhrjHHbtd3csa2Ht3c1B109ERGRZUnBWWQJK5bKPP3qCb694yhP7B+iUHJs7k5zx7YefvmatbQ0xIKuooiIyLKh4CyyTIxN53l09wAP7ehn/+AksXCIGy9r55qeNJu701zd08Lq5rhOLBQREXmLFJxFlqF9b0zw8M5+nn1thEPDGUr+TVU6muJc3Z1msx+mN/ek6WzSCYYiIiK1OF1wjgRRGRE5P65am+aqtWnAu8HK/sFJ9vaPs2dggr39E/zTgWHmjo3XNCfY3JNeEKjbU/EAay8iIrK0KDiLLBPJWJit61vZur61UjadK7LvjUn29I/z8sAEewYmeGL/UGV5d0uSq3vSbOpOc7UfpjVeWkRE5NQUnEWWscZ4hOsvbeP6S9sqZZPZAvsGJtk7MM6e/gn2Dkzw+MvHKst72xrY3JPm2p4WrlvfwlVr0ySiupuhiIiIgrPICtOciHLTZe3cdFl7pWx8Js/LA5PsGfB6pncfGef/7RkEIBYOcVV3M1t7W7lufSvX9bayJq3x0iIisvLo5EAROaXhqSy7+sZ58cgYO/vG2DMwQb5YBrwhHlt6W9jqB+l3rG0mGtaNWUREZHnQyYEiclY6mxLcsmkNt2xaA0C+WGb/4CQ7+8bYdWSMXX1jPOb3SscjIa7paWHL+pZKz/QqnXgoIiLLjHqcReQtG5yYZVffeCVM73tjgkLJe0/pbWvwe6RbuG59K1eubiKiXmmRZa9cduRLZZyDsnP+A5z/PFc2v9z7mYXrV61b9p57WpM6eVkuGl3HWUQuuGyhxMsDE36P9Dg7j4xxfCoHQEMs7F29w78c3qbuNJe2NxIK6UYtQZiYKfD6yDR9ozMcGZnm9ZEZjk/laE/FWJtOsiadYG1Lgq50krXpJM3JiG6qIwBkckUGx2cZGJ/ljfEsb4zP8sbErPc8nmVwYrZyAH0+mcHb1jRz44Y2btrQzg2XtpNuiJ7331MPnHPkimVm8yVyxTKrUjF1PFxkFz04m9k64H5gNeCAe51z9yxax4B7gFuBGeC3nHO7zrRdBWeRpcM5R//YLLuOjPHikXFe6h9n/xuT5Pyx0ql4hKvWNlcuibe5O80lCtPnhXOO4akcfSMzvD4yzZGRGfpGZ+gbmaZvZIaJ2cKC9Tub4qxuTjCSyTE0lavcTGdOQyxMVzrB2pYkXWkvUHelE3S1JFnrP6fiGv231BVLZYamcn4IrgrGflAenMie9NoJmXed+LUtSe/10ZIgnYwSMiNkEDLDqqZDhj9fvdxfFppbxxasC3BoaIpnD4+ws2+MXLGMGbx9TTM3XdbOjRvauf6StsCCtHOO45kch49PMz5TIFsoMVsoMZtf9Dw3XTWfLZSY8csqP1coUR3PYuEQGzoauXJNE1esnnukWNfaoPfLCySI4NwFdDnndplZE7ATuM05t79qnVuBf4MXnG8A7nHO3XCm7So4iyxtxVKZQ8MZ9vo3adk7MMH+wcnKiYdN8QhXdTdzdU9LJUyvb9OHw6kUS2UGxmfpmwvFJ+Z6kGfoG50mWyhX1g2HjO6WJOvbG7xHWyO97Q1c0t5Ib1sDydj8JQdLZcfwVLbSezg4nmVwwpt+YyLL4PgsxzM5Fn98NCUirE17wcnrqfbC1IaORjZ2pmhKLM/ewaXCOcf4TKESgOd6igerwvGxySyLjplIJ6NeKE7Ph+O1LQm6/enOpvhF7Q3NFUu8dHSCZ18b4bnDI+w8MkbeD9Lv6Grmpg1ekH7npW2kk+f3NVcqO/rHZnh1ODP/OJ7hteEMk9niaX/ODBqiYZKxMIlomIZYmGTUm07GvPlE1CtL+ssT/jrRcIijYzMcPDbFwaEMA+Ozle0mo2EuX53i8s4mrlyT4vLVTVy5uomudELfEJ2jwIdqmNmjwNecc09UlX0T+Gfn3N/68weAm51zg6fbjoKzyPJTKJU5NJTxb9Iyzt6BSV6pDtOJCJvWphf0TK9vb1i2HwzTuSInMjlOZHIcn8pXpk9kcpzw54f9XsFiVcpJREP0tjXQ29bIJX5A7m1vZH1bA92tyfN65ZN8sczQZFWgHp9/PjbphbGR6fyCn1nTnGBjZ4qNnSku60yxscObXpWKLdu2vJhm8sWqdpjvLR6cyFaGUlQfTAFEw8aa9HwI7m5Jegc9fjBeCt8kZAslXjo6zrOHvSC968g4+WKZkHl3V71xQ1slSDfXePCWLZT46Ynpk8Lx4RPTlfclgFWpOBs7vQPDjR0pNnSkaGuMecG4KhzHI6Hz9hqfyhY4NJzh0NAUB45lODg0xcGhKYb9YXHgdUBcvjrFlWua/FDdxOWrU3Sk4trXahRocDazS4AfApucc5NV5Y8BX3LOPePPPwl83jl32mSs4CyyMhRKZQ4OTVV6pfcOTPCTwSnyJe9DqzkRYVN3mp7WJO2pOO2NMVal4rQ1xmhPedOtDTFikeDHBTrnmMoVOTGV40SmKghP5TieOTkYzxZKp9xOa0OUVak4q1JxOprirGtLst4PxuvbG+lsitdVz3y2UKJ/bJbXjnvh47WqADKdn/8b08loJXjMBeuNnSm6W5J19fcEpVAqMzlbYGK2wIlMnsEJf9iEH5IH/OfxmYVDKMygIxWnqyVJ99y3AFU9x10tCVY11tdr5nzIFkrsPjpe6ZF+8cg4+ZIXpDd1p7lxQzs3bmjjnZe0UXac9Np89XiGo6MzlZ53M1jX2uAd8Pnfnniv16a6GmM9PpPn4FCGA0NTfu+09xirel20NkS5YrUXortbGipDtFY3x+lsTtCcCPZchlyxxIlMnuNTucrjlzZ3BfJ/Diw4m1kK2A580Tn3yKJlNQVnM/s08GmA3t7erX19fRe0ziJSn/JFP0z7QXrfwATHJrOMZPILel6rNScirErFaU/FaG+M05aKsaox5oXtVIw2P3C3N8ZoaYgR9kOEc47ZQolMrsh0rkQmW/Sni0zn56e98pI3na8u89ab+9m5wF/NjErg9x7+dNPC+Y4m74BguVwr2znH4ER2QW/eXHip7qWOR0JsmAvTVaF6fXvDkrubZbZQYnK2wGTWC8CVx0yBidkiE4uWTVatM5M/9YFUcyKyYOjEXE/xWj8gr25O1MWBY9CyhRK7jozx3OFRnjs8wm4/SJtx0jjiS1c1zn8jUulFblxyr7c5zjlOZPIcHJriwLEpDg17z6+eZmhJIhrygnRTgs7m+VC9ujlBZ9N8wD6bbyFKZcfotB+GM7kFodibz1bC8uLx8wCP3vkurlnXck7/h7cikOBsZlHgMeAfnXN3n2K5hmqIyDlzzjE5W2RkOsfIdJ6RjNezOzo3PZ1nNJP3lmfyjM3kTxrHCd5JTi0NMQrFMtP54inXOZVUPEJjPExjPOJNxyKkEpEF5e2NMToqgThe6R0PL7PevnM1Np2vBOnqR/W4ToBYJFT5/6biUVL+/7kxHiHl//+99phvl9Tc8kXTiaj3NXq57MgWvZO0ZvJVJ21Vndw1P19kNl9mplAk668/UyhVpmcL3sHUXPjNFU8+cKrWEAuTTkZJJ6M0+8/pZJTmxNx0hHRDlLbGuE7GPEfZQoldfWM8//ooiWiYjR1eUF7XmlxRV66YzhUZnsoxNJllaDLL8cq09zw8lePYRPaU34A1xsJemK6E6wStDTEmZgsnBeTR6dwp30sbY2E6muLzD7+TYK6zoLo8iHYJ4uRAA+4DRp1znznNOr8E/D7zJwf+hXPu+jNtV8FZRM5VqewYn8n7IXs+UI9kcozO5ImEQjT5wasSvhaE4fnnhmh42X3VXY9m8kUOH/fGnB4dnVnUu1+a/yZgwTcDp+6pXSwcMqJhO2n8by1ikVDlZK5kdH5cazLmvWbSySjphrkQHFkQiuceTYmoeoalLjnnyOSKDE3mGJ7MMjRVFawncwz788cms+SLZaJhmw++pwjAc9OrUnEa6/zAL4jg/G7gaWAvMPdu9EdAL4Bz7ht+uP4acAve5eg+eabxzaDgLCIitSmXHTOFRcNsckWmqqYzuRKZXIFCyS242sFcAF4wHwvTEI2QiIVoiEVIREIrqodS5HScc8zkSySXUUfCRb/ltj9u+Yz/Peel9jsvVB1ERGTlCoWsMixDRC4cM6v7HuTzRYfKIiIiIiI1UHAWEREREamBgrOIiIiISA0UnEVEREREaqDgLCIiIiJSAwVnEREREZEaKDiLiIiIiNRAwVlEREREpAYKziIiIiIiNVBwFhERERGpgYKziIiIiEgNFJxFRERERGpgzrmg63BWzOw40BfQr18FnAjod8ubU/vUP7VRfVP71D+1Uf1TG9W3WttnvXOuY3HhkgvOQTKzHc65bUHXQ05N7VP/1Eb1Te1T/9RG9U9tVN/OtX00VENEREREpAYKziIiIiIiNVBwPjv3Bl0BOSO1T/1TG9U3tU/9UxvVP7VRfTun9tEYZxERERGRGqjHWURERESkBgrONTCzW8zsgJm9amZ/GHR95GRm9rqZ7TWz3Wa2I+j6CJjZt8xs2MxeriprM7MnzOyQ/9waZB1XstO0zxfMbMDfj3ab2a1B1nGlM7N1ZvaUme03s31mdpdfrv2oDpyhfbQf1QkzS5jZ82b2kt9Gf+KXX2pmP/Zz3d+ZWazmbWqoxpmZWRg4CLwP6AdeAD7unNsfaMVkATN7HdjmnNO1M+uEmf0skAHud85t8su+DIw6577kH4S2Ouc+H2Q9V6rTtM8XgIxz7r8GWTfxmFkX0OWc22VmTcBO4Dbgt9B+FLgztM9H0H5UF8zMgEbnXMbMosAzwF3A54BHnHMPmtk3gJecc1+vZZvqcX5z1wOvOucOO+fywIPABwOuk0jdc879EBhdVPxB4D5/+j68DxkJwGnaR+qIc27QObfLn54CXgG60X5UF87QPlInnCfjz0b9hwN+DnjYLz+rfUjB+c11A0er5vvRjlGPHPB9M9tpZp8OujJyWqudc4P+9DFgdZCVkVP6fTPb4w/l0BCAOmFmlwBbgB+j/ajuLGof0H5UN8wsbGa7gWHgCeA1YNw5V/RXOatcp+Asy8W7nXPXAe8H7vS/hpY65rxxYhorVl++DlwGXAsMAv8t2OoIgJmlgO8An3HOTVYv034UvFO0j/ajOuKcKznnrgV68EYRvO1ctqfg/OYGgHVV8z1+mdQR59yA/zwMfBdv55D6M+SPC5wbHzgccH2kinNuyP+QKQN/ifajwPnjMr8DPOCce8Qv1n5UJ07VPtqP6pNzbhx4CrgJaDGziL/orHKdgvObewG43D8DMwZ8DPj7gOskVcys0T8xAzNrBH4RePnMPyUB+XvgE/70J4BHA6yLLDIXxnwfQvtRoPwTm/4KeMU5d3fVIu1HdeB07aP9qH6YWYeZtfjTSbwLPbyCF6Bv91c7q31IV9WogX8pma8CYeBbzrkvBlwlqWJmG/B6mQEiwP9WGwXPzP4WuBlYBQwBfwz8H+AhoBfoAz7inNMJagE4TfvcjPf1sgNeB/5V1VhaucjM7N3A08BeoOwX/xHeOFrtRwE7Q/t8HO1HdcHMrsY7+S+M11n8kHPuT/3c8CDQBrwI/LpzLlfTNhWcRURERETenIZqiIiIiIjUQMFZRERERKQGCs4iIiIiIjVQcBYRERERqYGCs4iIiIhIDRScRURWODO72cweC7oeIiL1TsFZRERERKQGCs4iIkuEmf26mT1vZrvN7JtmFjazjJl9xcz2mdmTZtbhr3utmT1nZnvM7Ltm1uqXbzSzH5jZS2a2y8wu8zefMrOHzewnZvaAf1c0ERGpouAsIrIEmNnbgY8C73LOXQuUgF8DGoEdzrmrgO14dwAEuB/4vHPuarw7m82VPwD8D+fcNcDPAHN3NNsCfAZ4B7ABeNcF/6NERJaYSNAVEBGRmvw8sBV4we8MTgLDeLf6/Tt/nf8FPGJmaaDFObfdL78P+LaZNQHdzrnvAjjnsgD+9p53zvX787uBS4BnLvyfJSKydCg4i4gsDQbc55z79wsKzf7jovXcW9x+rmq6hD4fREROoqEaIiJLw5PA7WbWCWBmbWa2Hu99/HZ/nV8FnnHOTQBjZvYev/w3gO3OuSmg38xu87cRN7OGi/pXiIgsYepREBFZApxz+83sPwDfN7MQUADuBKaB6/1lw3jjoAE+AXzDD8aHgU/65b8BfNPM/tTfxh0X8c8QEVnSzLm3+q2eiIgEzcwyzrlU0PUQEVkJNFRDRERERKQG6nEWEREREamBepxFRERERGqg4CwiIiIiUgMFZxERERGRGig4i4iIiIjUQMFZRERERKQGCs4iIiIiIjX4/xj4mhuGD+M4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jQ0equmGYKbt",
        "-zuJdSSzX9yZ",
        "CtFFwJOuYGUe",
        "YAuJcqFti8zz",
        "gDfAkWunYGUZ",
        "A2piAVS4fTFo",
        "zWBZqHjZYGUb",
        "cGjH-s9ZYGUU",
        "cTjlYz3CYGUW",
        "FrtTS3OdYGUX"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad2fc61898534e7892fe0679283b8cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_077c3867be73485494e502ff40d4f17d",
              "IPY_MODEL_486b6f9993a847e1a68b89695a026e5b",
              "IPY_MODEL_6aef3ab9e4b94b5dbbe3443d0fd56385"
            ],
            "layout": "IPY_MODEL_7844fbf402ea4de8a7480f1f6f28e0d8"
          }
        },
        "077c3867be73485494e502ff40d4f17d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eff2f456642f41a6b131aee1eb126811",
            "placeholder": "",
            "style": "IPY_MODEL_5aa41c74a8ae47099696f9ab6972c7fa",
            "value": "  0%"
          }
        },
        "486b6f9993a847e1a68b89695a026e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c84fd8ba160f4ed68cdd4d6ba4eb1a10",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5acca1df2c98463a834109b8aa044748",
            "value": 0
          }
        },
        "6aef3ab9e4b94b5dbbe3443d0fd56385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa1963cbd3a4100a803e771e5de0b79",
            "placeholder": "",
            "style": "IPY_MODEL_fc88c1823e214d20914defecae0b5ec1",
            "value": " 0/30 [02:47&lt;?, ?it/s]"
          }
        },
        "7844fbf402ea4de8a7480f1f6f28e0d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff2f456642f41a6b131aee1eb126811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa41c74a8ae47099696f9ab6972c7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c84fd8ba160f4ed68cdd4d6ba4eb1a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5acca1df2c98463a834109b8aa044748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4aa1963cbd3a4100a803e771e5de0b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc88c1823e214d20914defecae0b5ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbed5bf68000471cb34911c6b3acbe10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5465950bdee4e79b26fe529581f1304",
              "IPY_MODEL_772e6979155947edb38204197899a8e4",
              "IPY_MODEL_be167b5301374fe6a5a828aefd93530f"
            ],
            "layout": "IPY_MODEL_5312e9b925054669a71bbfce4f92f6fb"
          }
        },
        "e5465950bdee4e79b26fe529581f1304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_820ff9ddb5c04cc1b06d1a14c88d1ae9",
            "placeholder": "",
            "style": "IPY_MODEL_afe129fb679a4029a77b1bfc0ae5f90e",
            "value": "100%"
          }
        },
        "772e6979155947edb38204197899a8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f1187a8465449882aff33072e84fd9",
            "max": 64,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f78b23a17c594968a76762f1bdd64d51",
            "value": 64
          }
        },
        "be167b5301374fe6a5a828aefd93530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e14f8e0fcc44ed9512a394a6bd4019",
            "placeholder": "",
            "style": "IPY_MODEL_7e70abb698fb422ea40641c4026b88e4",
            "value": " 64/64.0 [02:47&lt;00:00,  2.74s/it]"
          }
        },
        "5312e9b925054669a71bbfce4f92f6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "820ff9ddb5c04cc1b06d1a14c88d1ae9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe129fb679a4029a77b1bfc0ae5f90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8f1187a8465449882aff33072e84fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78b23a17c594968a76762f1bdd64d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5e14f8e0fcc44ed9512a394a6bd4019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e70abb698fb422ea40641c4026b88e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}